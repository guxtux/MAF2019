\input{../Preambulos/preambulo_materiales}
\usepackage{apacite}
\title{Ortogonalización y completez \\[0.3em]  \large{Tema 3 - Bases completas y ortogonales}\vspace{-3ex}}
\author{M. en C. Gustavo Contreras Mayén}
\date{ }
\begin{document}
\vspace{-4cm}
\maketitle
\fontsize{14}{14}\selectfont
\tableofcontents
\newpage
%Notas Arken Capítulo 10 versión djvu
\section{Ortogonalización de Gram-Schmidt.}

Este método toma un conjunto de funciones (o vectores) no ortogonales linealmente dependientes y genera un conjunto ortogonal de funciones (o vectores) en un intervalo arbitrario con respecto a una función de peso arbitraria.
\par
Las funciones involucradas pueden ser reales o complejas, por conveniencia, asumiremos que las funciones son reales, la generalización para funciones complejas, no ofrece mayor dificultad.
\par
Veamos el caso de la normalización de funciones, que implica lo siguiente:
\begin{align*}
\int_{a}^{b} \varphi_{i}^{2} \, w \, \dd{x}  =  N_{i}^{2}
\end{align*}
revisemos que no se le ha puesto atención al valor de $N_{i}$. Ya que la ecuación básica 
\begin{align}
\mathcal{L} \, u(x) + \lambda \, w(x) \, u(x) = 0
\label{eq:ecuacion_10_08}
\end{align}
es lineal y homogénea, podemos multiplicar la solución por cualquier constante, de tal manera que sigue siendo solución. Por lo que podemos pedir que tal solución $\varphi_{i}(x)$ se multiplique por $N_{i}^{-1}$ y ahora la nueva $\varphi_{i}$ (normalizada) $\varphi_{i}$ satisface
\begin{align}
\int_{a}^{b} \varphi_{i}^{2} (x) \, w(x) \, \dd{x} = 1
\label{eq:ecuacion_10_39}
\end{align}
o en términos de una delta
\begin{align}
\int_{a}^{b} \varphi_{i}(x) , \varphi_{j} (x) \, w(x) \, \dd{x} = \delta_{ij}
\label{eq:ecuacion_10_40}
\end{align}
La ecuación (\ref{eq:ecuacion_10_39}) nos dice que hemos normalizado a la unidad; incluyendo la propiedad de ortogonalidad, tenemos la ecuación (\ref{eq:ecuacion_10_40}), las funciones que las satisfacen, se dice que son \textbf{ortonormales} (ortogonales y normalizadas), cabe señalar que existen otras formas de normalización, cada una de las funciones especiales de la Física Matemática se puede normalizar de distintas formas.
\par
Consideremos tres conjuntos de funciones:
\begin{enumerate}
\item Un conjunto original, linealmente independiente $u_{n}(x)$ con $n=0,1,2,\ldots$ \\
Las funciones podrían ser funciones propias degeneradas, pero no es necesario que se cumpla este punto.
\item Un conjunto ortogonal $\psi_{n}(x)$ que se va a construir.
\item Un conjunto de funciones $\varphi_{n}(x)$ que será normalizadas $\psi_{n}(x)$
\end{enumerate}
Tendremos las siguientes propiedades
\begin{center}
{\fontsize{12}{12}\selectfont
\renewcommand{\arraystretch}{1.5}%
\begin{tabular}{p{4.5cm} p{4.5cm} p{4.5cm}}
\hline
\makecell{$u_{n}(x)$} & \makecell{$\psi_{n}(x)$} & \makecell{$\varphi_{n}(x)$} \\ \hline
\makecell{linealmente \\ independiente} &    \makecell{linealmente \\ independiente} & \makecell{linealmente \\ independiente} \\ \hline
\makecell{no ortogonal} & \makecell{ortogonal} & \makecell{ortogonal} \\ \hline
\makecell{no normalizada} & \makecell{no normalizada} & \makecell{normalizada \\ (ortonormal)} 
\end{tabular}
}
\end{center}
\subsection{La técnica.}
La técnica de Gram-Schmidt consiste en tomar la n-ésima función $\psi$ ($\psi_{n}$) para ser $u_{n}(x)$ más un combinación lineal no conocida de la función $\varphi$ previa. El que haya una nueva $u_{n}(x)$ nos dará la garantía de que se mantenga la independencia lineal.
\par
El que $\psi_{n}(x)$ sea ortogonal para cada $\varphi$ previa, apenas nos da elementos para determinar los coeficientes desconocidos. Así cuando ya se determine $\psi_{n}$, se normaliza a la unidad, dejando $\varphi_{n}(x)$. Este procedimiento se repite para las $\psi_{n+1}(x)$.

Empezamos con $n = 0$, sea
\begin{align}
\psi_{0} = u_{0}(x)
\label{eq:ecuacion_10_41}
\end{align}
no nos preocupemos al no tener una $\varphi$ previa. Entonces normalizamos
\begin{align}
\varphi_{0}(x) = \dfrac{\psi_{0}(x)}{\left[ \displaystyle \int \psi_{0}^{2} \, w \, \dd{x} \right]^{1/2}}
\label{eq:ecuacion_10_42}
\end{align}
Para $n = 1$, tenemos
\begin{align}
\psi_{1}(x) = u_{1}(x) + a_{1,0} \, \varphi_{0}(x)
\label{eq:ecuacion_10_43}
\end{align}
Que requiere que $\psi_{1}(x)$ sea ortogonal a $\varphi_{0}(x)$ (en este punto, la normalización de $\psi_{1}(x)$ es irrelevante). La ortogonalidad nos conduce a
\begin{align}
\int \psi_{1} \, \varphi_{0} \, w \, \dd{x} = \int u_{1} \, \varphi_{0} \, w \, \dd{x} + a_{1,0} \int \varphi_{0}^{2} \, w \,  \dd{x} = 0
\label{eq:ecuacion_10_44}
\end{align}
Ya que $\varphi_{0}$ se normaliza a la unidad (ec. \ref{eq:ecuacion_10_42}), tenemos
\begin{align}
a_{1,0} = - \int u_{1} \, \varphi_{0} \, w \, \dd{x}
\label{eq:ecuacion_10_45}
\end{align}
fijando el valor de $a_{1, 0}$. Normalizando, definimos
\begin{align}
\varphi_{1} (x) = \dfrac{\psi_{1}(x)}{\left( \displaystyle \int \psi_{1}^{2} \, w \, \dd{x} \right)^{1/2}}
\label{eq:ecuacion_10_46}
\end{align}
Generalizando, resulta
\begin{align}
\varphi_{i}(x) = \dfrac{\psi_{i}(x)}{\left( \displaystyle \int \psi_{i}^{2}(x) \, w(x) \, \dd{x} \right)^{1/2}}
\label{eq:ecuacion_10_47}
\end{align}
donde
\begin{align}
\psi_{i}(x) = u_{i} + a_{1, 0} \, \varphi_{0} + a_{i, 1} \, \varphi_{1} + \ldots + a_{i, i-1} \, \varphi_{i-1}
\label{eq:ecuacion_10_48}
\end{align}
Los coeficientes $a_{i, j}$ están dados por
\begin{align}
a_{i, j} = - \int u_{i} \, \varphi_{j} \, w \, \dd{x}
\label{eq:ecuacion_10_49}
\end{align}
La ecuación (\ref{eq:ecuacion_10_49}) es para una normalización unitaria. Para otros tipos de normalización, se tiene que
\begin{align*}
\int_{a}^{b} \left[ \varphi_{j} (x) \right]^{2} \, w(x) \, \dd{x} =  N_{j}^{2}
\end{align*}
Entonces la ecuación (\ref{eq:ecuacion_10_47}) se reemplaza por
\begin{align}
\varphi_{i}(x) =  N_{i} \: \dfrac{\psi_{i}(x)}{\left( \displaystyle \int \psi_{i}^{2} \, w \, \dd{x} \right)^{1/2}}
\label{eq:ecuacion_10_47a}
\end{align}
y los términos $a_{i,j}$ resultan
\begin{align}
a_{i, j} = - \dfrac{ \displaystyle \int u_{i} \, \varphi_{j} \, w \, \dd{x}}{N_{j}^{2}}
\label{eq:ecuacion_10_49a}
\end{align}
Las ecuaciones (\ref{eq:ecuacion_10_48}) y (\ref{eq:ecuacion_10_49}) pueden escribirse en términos de operadores de proyección $P_{j}$. Si consideramos que $\varphi_{n}(x)$ forman un espacio vectorial lineal, la integral en la ecuación \ref{eq:ecuacion_10_49}) puede interpretarse como la proyección de $u_{i}$ en la \enquote{coordenada} $\varphi_{j}$ o la componente $j$-ésima de $u_{i}$. Con
\begin{align*}
P_{j} \, u_{i}(x) = \left[ \int u_{i}(t) \, \varphi_{j}(t) \, w(t) \dd{t} \right]\, \varphi_{j}(x)
\end{align*}
la ecuación (\ref{eq:ecuacion_10_48}) resulta ahora
\begin{align}
\psi_{i}(x) = \left\{ 1 - \sum_{j=1}^{i-1} P_{j} \right\} \, u_{i}(x)
\label{eq:ecuacion_10_48a}
\end{align}
Restando los $j-$-ésimos componentes: $j=1$ a $i-1$, resulta que $\psi_{i}(x)$ es ortogonal para todo $\varphi_{j}(x)$.
\par
 Cabe señalar que el procedimiento de Gram-Schmidt es una manera de construir un conjunto ortogonal o ortonormal, pero las funciones $\varphi_{i}(x)$ no son únicas. Existe un infinito de posibles conjuntos ortonormales para un intervalo dado y una función de peso dada.
\begin{ejemplo} \textbf{Ortogonalización de Gram-Schmidt para los polinomios de Legendre.}

Queremos generar un conjunto ortonormal a partir de las funciones 
\begin{align*}
u_{n}(x) = x^{n}, \hspace{1.5cm} n = 0, 1, 2, \ldots
\end{align*}
El intervalo es $-1 \leq x \leq 1$ y la función de peso es $w(x)=1$.
\par
De acuerdo a la técnica descrita de ortogonaliación de Gram-Schmidt
\begin{align}
u_{0} = 1 \hspace{1.5cm} \varphi_{0} =  \dfrac{1}{\sqrt{2}}
\label{eq:ecuacion_10_50}
\end{align}
Entonces
\begin{align}
\psi_{1}(x) = x + a_{1,0} \, \dfrac{1}{\sqrt{2}}
\label{eq:ecuacion_10_51}
\end{align}
donde
\begin{align}
a_{1, 0} = - \int_{-1}^{1} \dfrac{x}{\sqrt{2}} \, \dd{x} = 0
\label{eq:ecuacion_10_52}
\end{align}
por simetría. Normalizando $\psi_{1}$, obtenemos
\begin{align}
\varphi_{1}(x) = \sqrt{\dfrac{3}{2}} \, x
\label{eq:ecuacion_10_53}
\end{align}
Continuando el método de Gram-Schmidt, se define ahora
\begin{align}
\psi_{2} (x) = x^{2} +  a_{2, 0} \, \dfrac{1}{\sqrt{2}} +  a_{2, 1} \, \sqrt{\dfrac{3}{2}} \, x
\label{eq:ecuacion_10_54}
\end{align}
donde
\begin{align}
a_{2, 0} &= - \int_{-1}^{1} \dfrac{x^{2}}{\sqrt{2}} \, \dd{x} = - \dfrac{\sqrt{2}}{3} \label{eq:ecuacion_10_55} \\[1em] 
a_{2, 1} &= - \int_{-1}^{1} \sqrt{\dfrac{3}{2}} \, x^{3} \dd{x} = 0 \label{eq:ecuacion_10_56}
\end{align}
de nueva cuenta por simetría. Por tanto
\begin{align}
\psi_{2}(x) = x^{2} - \dfrac{1}{3}
\label{eq:ecuacion_10_57}
\end{align}
normalizando a la unidad, tenemos
\begin{align}
\varphi_{2} (x) = \sqrt{\dfrac{5}{2}} \, \dfrac{1}{2} \, (3 \, x^{2} - 1)
\label{eq:ecuacion_10_58}
\end{align}
La siguiente función $\varphi_{3}(x)$ es
\begin{align}
\varphi_{3} (x) = \sqrt{\dfrac{7}{2}} \, \dfrac{1}{2} \, (5 \, x^{3} - 3 \, x)
\label{eq:ecuacion_10_59}
\end{align}
Se puede demostrar que
\begin{align}
\varphi_{n}(x) = \sqrt{\dfrac{2 \, n + 1}{2}} \, P_{n}(x)
\label{eq:ecuacion_10_60}
\end{align}
donde $P_{n}$ es el polinomio de orden $n$ de Legendre.
\end{ejemplo}
\subsection{Ejercicio a cuenta.}
Cuentas con los siguientes elementos:
\begin{enumerate}
\item Un conjunto de funciones $\left\{ u_{n} (x) \right\} = \left\{ x^{n} \right\}, \mbox{ con } n = 1, 2, \ldots$
\item El intervalo $(0, \infty)$
\item Una función de peso $w(x) = x \, e^{-x}$
\end{enumerate}
Con el método de Gram-Schmidt construye las primeras \textbf{tres funciones ortonormales} del conjunto $u_{n}(x)$, con ese intervalo dado y función de peso dada.
\section{Polinomios ortogonales.}
\subsection{Conjunto de polinomios.}

El ejemplo anterior se ha elegido estrictamente para ilustrar el procedimiento de Gram-Schmidt. Aunque tiene la ventaja de introducir los polinomios de Legendre, las funciones iniciales $u_{n} = x^{n}$ no son funciones propias degeneradas y no son soluciones de la ecuación de Legendre. Son simplemente un conjunto de funciones que hemos reorganizado aquí para crear un conjunto ortonormal para el intervalo dado y la función de peso dada. El hecho de que hayamos obtenido los polinomios de Legendre no es una magia negra, sino una consecuencia directa de la elección de la función de peso y del intervalo.
\par
El uso de $u_{n} = x^{n}$ pero eligiendo otros intervalos y funciones de peso, nos conduce a otros conjuntos de polinomios ortogonales, como se muestra en la tabla (\ref{tabla:tabla_03}):
\begin{landscape}
\begin{table}[H]
\centering
{\renewcommand{\arraystretch}{1.5}%
%\resizebox{\textwidth}{!}{%
\begin{tabular}{p{5cm} c c p{10cm}}
\hline
\makecell{Polinomios} & Intervalo & $w(x)$ & \makecell{Normalización estándar} \\ \hline
Legendre & $ -1 \leq x \leq 1$ & $1$ & $\displaystyle \int_{-1}^{1} \left[ P_{n}(x) \right]^{2} \dd{x} = \dfrac{2}{2 \, n + 1} $ \\
Modificados de Legendre & $ 0 \leq x \leq 1$ & $1$ & $\displaystyle \int_{-1}^{1} \left[ P_{n}^{*}(x) \right]^{2} \dd{x} = \dfrac{2}{2 \, n + 1} $ \\
Chebyshev I & $-1 \leq x \leq 1$ & $(1 - x^{2})^{-1/2}$ & $\displaystyle \int_{-1}^{1} \dfrac{\left[ T_{n}(x) \right]^{2}}{(1 - x^{2})^{-1/2}} \dd{x} = \begin{cases} 
\displaystyle \frac{\pi}{2} & n \neq 0 \\
\pi & n = 0 \end{cases} $ \\
Modificados de Chebyshev I & $0 \leq x \leq 1$ & $[x (1 - x)]^{-1/2}$ & $\displaystyle \int_{-1}^{1} \dfrac{\left[ T_{n}^{*} (x) \right]^{2}}{[x (1 - x)]^{-1/2}} \dd{x} = \begin{cases} 
\displaystyle \frac{\pi}{2} & n > 0 \\
\pi & n = 0 \end{cases} $ \\
Chebyshev II & $-1 \leq x \leq 1$ & $(1 - x^{2})^{1/2}$ & $\displaystyle\int_{-1}^{1} [U_{n} (x)]^{2} \, (1 - x^{2})^{1/2} \, \dd x = \frac{\pi}{2}$ \\
Laguerre & $0 \leq x < \infty $ & $e^{-x}$ & $\displaystyle \int_{0}^{\infty} \left[ L_{n} (x) \right]^{2} \, e^{-x} \dd{x} =  1 $ \\
Asociados de Laguerre & $0 \leq x < \infty $ & $x^{k} \, e^{-x}$ & $\displaystyle \int_{0}^{\infty} \left[ L_{n}^{k} (x) \right]^{2} \, x^{k} \, e^{-x} \dd{x} = \dfrac{(n + k)!}{n!} $ \\
Hermite & $- \infty < x < \infty $ & $e^{-x^{2}}$ & $\displaystyle \int_{-\infty}^{\infty} \left[ H_{n} (x) \right]^{2} e^{-x^{2}} \dd{x} = 2^{n} \, \pi^{1/2} \, n! $
\end{tabular}}
\caption{Polinomios ortogonales generados por la ortogonalización de Gram-Schmidt de $u_{n}(x)= x^{n}$, con $n=0,1,2,\ldots$}
\label{tabla:tabla_03}
\end{table}
\end{landscape}
Una revisión de este proceso de ortogonalización revelará dos características arbitrarias:
\begin{enumerate}
\item Primero, como se enfatizó antes, no es necesario normalizar las funciones a la unidad. En el ejemplo que acabamos de dar, podríamos haber requerido
\begin{align}
\int_{-1}^{1} \varphi_{n} (x) \: \varphi_{m} (x) \, \dd{x} = \dfrac{2}{2 \, n +1} \, \delta_{nm}
\label{eq:ecuacion_10_61}
\end{align}
y el conjunto resultante habría el de los polinomios de Legendre.
\item Segundo, el signo de $\varphi_{n} (x)$ siempre es indeterminado. En el ejemplo, elegimos el signo al requerir que el coeficiente de mayor potencia de $x$ en el polinomio sea positivo. Para los polinomios de Laguerre, por otro lado, requeriríamos que el coeficiente de mayor potencia sea $(-1)^{n}/n!$
\end{enumerate}
\section{Completez de las funciones propias.}
La tercera propiedad importante de un operador Hermitiano es que las funciones propias forman un conjunto completo. Esta completez\footnote{Como tal, el término \enquote{completez} es un tecnicismo, aunque aceptado pero no es correcto en español. Siendo la expresión \enquote{completitud} válida, mientras que \enquote{compleción} es el término correcto, pero no es común encontrarla en los textos especializados tanto de matemática como de física en español. En matemáticas es normal la referencia como \enquote{cerradura} o \enquote{clausura}.} significa que cualquier función bien portada (al menos en partes pero continua) $F(x)$ se puede aproximar por una serie
\begin{align}
F(x) = \sum_{n=0}^{\infty} a_{n} \: \varphi_{n}(x) 
\label{eq:ecuacion_10_62}
\end{align}
con cualquier grado de precisión. Con mayor formalismo, el conjunto $\varphi_{n} (x)$ se dice completo, si el límite del error medio cuadrado se anula:
\begin{align}
\lim_{m \to \infty} \int_{a}^{b} \left[ F(x) - \sum_{n=0}^{m} a_{n} \: \varphi_{n} \right]^{2} \, w(x) \, \dd{x} = 0
\label{eq:ecuacion_10_63}
\end{align}
Técnicamente, esta es una integral de Lebesgue. No necesariamente el error es nulo en $[a,b]$, pero sólo la integral del error al cuadrado debe ser cero.
\par
La convergencia en la media (ec. \ref{eq:ecuacion_10_63}) debe compararse con la convergencia uniforme. La convergencia uniforme implica la convergencia en la media, pero de manera inversa no se garantiza, la convergencia en la media es menos restrictiva.
\par
En la ecuación (\ref{eq:ecuacion_10_63}) no es válida para funciones continuas en piezas, ya que hay un número finito de discontinuidades.
\par
 En la ecuación (\ref{eq:ecuacion_10_62}) la expasión de los coeficientes $a_{m}$ se determina por
\begin{align}
a_{m} = \int_{a}^{b} F(x) \, \varphi_{m}^{*} (x) \, w(x) \, \dd{x}
\label{eq:ecuacion_10_64}
\end{align}
Que se obtiene al multiplicar la ecuación (\ref{eq:ecuacion_10_62}) por $\varphi_{m}^{*} \, w(x)$ y luego se integra. De la ortogonalidad de las funciones propias $\varphi_{n}(x)$, solo el $m$-término sobrevive, por lo que la ortogonalidad es importante. La ecuación (\ref{eq:ecuacion_10_64}) puede compararse con el producto interno de vectores. En ocasiones los coeficientes $a_{m}$ son llamados \textbf{coeficientes generalizados de Fourier}.
\par
Para una función conocida $F(x)$, la ecuación (\ref{eq:ecuacion_10_64}) devuelve $a_{m}$ como una \textbf{integral definida} que siempre se puede evaluar, ya sea numéricamente si es que no es de manera analítica.
\par
En términos del álgebra lineal, tenemos un espacio lineal, un espacio de funciones. Las funciones linelamente independientes, ortonormales $\varphi_{n}(x)$ forman una base de ese espacio (infinito-dimensional). La ecuación (\ref{eq:ecuacion_10_62}) es un punto que nos dice que las funciones $\varphi_{n}(x)$ cubre ese espacio lineal. Con un producto punto definido por la ec. (\ref{eq:ecuacion_10_64}), el espacio lineal que tenemos, se convierte en un \textbf{espacio de Hilbert}.
\par
Por simplicidad, dejando la función de peso $w(x)=1$, la cerradura en forma de un operador para un conjunto discreto de funciones propias $\ket{\varphi_{i}}$ es
\begin{align*}
\boxed{\sum_{i} \ket{\varphi_{i}} \bra{\varphi_{i}} =  1}
\end{align*}
Multiplicando la relación de cerradura por $\ket{F}$. obtenemos la expansión de la función propia
\begin{align*}
\boxed{\ket{F} = \sum_{i} \ket{\varphi_{i}} \braket{\varphi_{i}}{F}}
\end{align*}
con el coeficiente generalizado de Fourier $a_{i} = \braket{\varphi_{i}}{F}$. De manera equivalente en una representación coordenada
\begin{align*}
\boxed{\sum_{i} \varphi_{i}^{*} (y) \: \varphi_{i} (x) = \delta (x - y)}
\end{align*}
implica que
\begin{align*}
F(x) = \int F(y) \: \delta (x - y) \, \dd{y} = \sum_{i} \varphi_{i} (x) \: \int \varphi_{i}^{*} (y) \: F(y) \, \dd{y}
\end{align*}
Sin pruebas, afirmamos que el espectro de un operador lineal $A$ que mapea un espacio de Hilbert $H$ en sí mismo puede dividirse en un espectro discreto (o puntual) con vectores propios de longitud finita, un espectro continuo para que la ecuación de valores propios $A \, v = \lambda \, v$ con $v$ en $H$ no tiene una inversa limitada única $(A - \lambda)^{-1}$ en un dominio denso de $H$ y un espectro residual donde $(A - \lambda)^{-1}$.
\subsection{Desigualdad de Bessel}
Si el conjunto de funciones $\varphi_{n} (x)$ no forma un conjunto completo, posiblemente sea por que no se han incluido el número infinito de elementos del conjunto completo, esto nos conduce a la \emph{desigualdad de Bessel}. Consideremos primero un caso finito. Sea $\vb{A}$ un vector de $n$ componentes
\begin{align}
\vb{A} = \vb{e}_{1} \, a_{1} + \vb{e}_{2} \, a_{2} + \ldots + \vb{e}_{n} \, a_{n} 
\label{eq:ecuacion_10_66}
\end{align}
en donde $\vb{e}_{i}$ es un vector unitario y $a_{i}$ es la correspondiente componente (proyección) de $\vb{A}$, esto es
\begin{align}
a_{i} = \vb{A} \cdot \vb{e}_{i}
\label{eq:ecuacion_10_67}
\end{align}
Entonces
\begin{align}
\left( \vb{A} - \sum_{i} \vb{e}_{i} \, a_{i} \right)^{2} \geq 0
\label{eq:ecuacion_10_68}
 \end{align}
Si sumamos todos los $n$ componentes, la suma se iguala a $\vb{A}$ por lo que la ecuación (\ref{eq:ecuacion_10_66}) se mantiene, pero si la suma, no incluye a todos los $n$ componentes, la desigualdad se mantiene. Pero si la suma no incluye todos los $n$ componentes, se presenta la desigualdad.
\par
Expandiendo la ecuación (\ref{eq:ecuacion_10_68}) y eligiendo los vectores unitarios para que satisfagan la relación de ortogonalidad
\begin{align}
\vb{e}_{i} \cdot \vb{e}_{j} =  \delta_{ij}
\label{eq:ecuacion_10_69}
\end{align}
tenemos que
\begin{align}
\vb{A}^{2} \geq \sum_{i} a_{i}^{2}
\label{eq:ecuacion_10_70}
\end{align}
Que es \underline{la desigualdad de Bessel}.
\par
Para funciones reales debemos de considerar la integral
\begin{align}
\int_{a}^{b} \left[ f(x) - \sum_{i} a_{i} \: \varphi_{i}(x) \right]^{2} \, w(x) \, \dd{x} \geq 0
\label{eq:ecuacion_10_71}
\end{align}
que es el análogo continuo de la ecuación (\ref{eq:ecuacion_10_68}), haciendo $n \to \infty$ y reemplazando la suma por la integración. Nuevamente, con el factor de peso $w(x) > 0 $, el integrando es no negativo. La integral se anula por la ecuación (\ref{eq:ecuacion_10_62}) si tenemos un conjunto completo. De otra forma, es positiva.

Si expandemos el término al cuadrado obtenemos
\begin{align}
\int_{a}^{b} [ f(x) ]^{2} \, w(x) \, \dd{x} - 2 \sum_{i} a_{i} \, \int_{a}^{b} f(x) \, \varphi (x) \, w(x) \, \dd{x} + \sum_{i} a_{i}^{2} \geq 0
\label{eq:ecuacion_10_72}
\end{align}
Usando la ecuación (\ref{eq:ecuacion_10_64}), tenemos
\begin{align}
\int_{a}^{b} [f(x)]^{2} \, w(x) \, \dd{x} \geq \sum_{i} a_{i}^{2}
\label{eq:ecuacion_10_73}
\end{align}
De aquí que la suma de los cuadrados de la expansión de los coeficientes $a_{i}$ es menor o igual que la integral de peso de $[f(x)]^{2}$, la igualdad se mantiene si y sólo si, la expansión es exacta, esto ocurre si el conjunto de soluciones $\varphi_{n}(x)$ es un conjunto completo.
\par
La desigualdad de Bessel tiene distintos usos, incluida la prueba de convergenia para las series de Fourier.
\subsection{Desigualdad de Schwarz.}
 La desigualdad de Schwarz se usa comúnmente y es similar a la desigualdad de Bessel. Consideremos la ecuación cuadrática con la incógnita $x$
 \begin{align}
\sum_{i=1}^{n} (a_{i} \, x + b_{i})^{2} = \sum_{i=1}^{n} a_{i}^{2} \left( x + \frac{b_{i}}{a_{i}} \right)^{2} = 0
\label{eq:ecuacion_10_74}
\end{align}
Con $a_{i}$, $b_{i}$ reales. Si $b_{i}/a_{i}$ es la constante $c$, independiente del índice $i$, la solución es $x= - c$. 
\par
Si $b_{i}/a_{i}$ no es constante en $i$, todos los términos no se anulan simultáneamente para un $x$ real, por lo que la solución debe de ser compleja. Expandiendo, tenemos que
\begin{align}
x^{2} \, \sum_{i}^{n} a_{i}^{2} + 2 \, x \, \sum_{i}^{n} a_{i} \, b_{i} + \sum_{i}^{n} b_{i}^{2} = 0
\label{eq:ecuacion_10_75}
\end{align}
como $x$ es complejo (o = $-b_{i}/a_{i}$), la fórmula cuadrática para $x$ conduce a 
\begin{align}
\left( \sum_{i=1}^{n} a_{i} \, b_{i} \right)^{2} \leq \left( \sum_{i=1}^{n} a_{i}^{2} \right) \, \left( \sum_{i=1}^{n} b_{i}^{2} \right)
\label{eq:ecuacion_10_76}
\end{align}
la igualdad se mantiene cuando $b_{i}/a_{i}$ es una constante independiente de $i$.
\par
Nuevamente, en términos de vectores, tenemos
\begin{align}
( \vb{a} \cdot \vb{b} )^{2} =  a^{2} \, b^{2} \, \cos^{2} \theta \leq a^{2} \, b^{2}
\label{eq:ecuacion_10_77}
\end{align}
donde $\theta$ es el ángulo entre $\vb{a}$ y $\vb{b}$.
\par
La desigualdad de Schwarz para funciones complejas tiene la expresión
\begin{align}
\boxed{
\Bigg\vert \int_{a}^{b} f^{*} (x) \, g(x) , \dd{x} \Bigg\vert^{2} \leq \int_{a}^{b} f^{*}(x) \, f(x) \, \dd{x} \int_{a}^{b} g^{*}(x) \, g(x) \, \dd{x}}
\label{eq:ecuacion_10_78}
\end{align}
La desigualdad se mantiene si y sólo si $g(x) = \alpha \, f(x)$, siendo $\alpha$ una constante. Para probar esta forma de la función de la desigualdad de Schwarz, consideremos la función compleja $\psi(x) = f(x) + \lambda \, g(x)$ con $\lambda$ una constante compleja, donde las funciones $f(x)$ y $g(x)$ son cualesquiera dos funciones de cuadrado integrable (para las cuales, las integrales del lado derecho existen). Multiplicando por el conjugado complejo y luego integrando, tenemos
\begin{align}
\begin{aligned}
\int_{a}^{b} \psi^{*} \, \psi \, \dd{x} &\equiv \int_{a}^{b} f^{*} \, f \, \dd{x} + \lambda \int_{a}^{b} f^{*} \, g \, \dd{x} + \lambda^{*} \int_{a}^{b} g^{*} \, f \, \dd{x} + \\
&+ \lambda \, \lambda^{*} \int_{a}^{b} g^{*} \, g \, \dd{x}  \geq 0
\end{aligned}
\label{eq:ecuacion_10_79}
\end{align}
El $\geq 0$ aparece ya que $\psi^{*} \, \psi$ es no negativo, el signo igual $(=)$ se mantiene sólo si $\psi (x)$ es idéntico a cero. Nótese que $\lambda$ y $\lambda^{*}$ son linealmente independientes, diferenciamos con respecto a uno de ellos, e igualamos la derivada a cero para minimizar $\displaystyle \int_{a}^{b} \psi^{*} \, \psi \dd{x}$:
\begin{align*}
\pdv{\lambda^{*}} \int_{a}^{b} \psi^{*} \, \psi \dd{x} = \int_{a}^{b} g^{*} \, f \dd{x}  + \lambda \int_{a}^{b} g^{*} g \dd{x} = 0
\end{align*}
que nos da
\begin{align}
\lambda = - \dfrac{\displaystyle \int_{a}^{b} g^{*} \, f \, \dd{x}}{\displaystyle \int_{a}^{b} g^{*} \, g \, \dd{x}}
\label{eq:ecuacion_10_80a}
\end{align}
tomando el conjugado complejo 
\begin{align}
\lambda^{*} = - \dfrac{\displaystyle \int_{a}^{b} f^{*} \, g \, \dd{x}}{\displaystyle \int_{a}^{b} g^{*} \, g \, \dd{x}}
\label{eq:ecuacion_80b}
\end{align}
sustituyendo esos valores de $\lambda$ y $\lambda^{*}$ en la ecuación (\ref{eq:ecuacion_10_79}), obtenemos la ecuación (\ref{eq:ecuacion_10_78}), \underline{la desigualdad de Schwarz}.
\par
En mecánica cuántica las funciones $f(x)$ y $g(x)$ podrían representar un estado o una configuración de un sistema físico, es decir, una combinación lineal de funciones de onda. Entonces la desigualdad e Shwarz garantiza que el producto punto $\displaystyle \int_{a}^{b} f^{*} \, g(x) \, \dd{x}$ existe. En algunos textos, la desigualdad de Schwarz es un paso para llegar al principio de incertidumbre de Heinsenberg.
\par
La notación de las funciones de las ecuaciones (\ref{eq:ecuacion_10_78}) y (\ref{eq:ecuacion_10_79}) es a veces incómoda; en mecánica cuántica es común utilizar la notación de Dirac. Con esta notación, se simplifica tanto el rango de integración $(a, b)$, como la función de peso $w(x) \geq 0$. La desigualdad de Schwarz ahora se representa
\begin{align}
\abs{\braket{f}{g}}^{2} \leq \braket{f}{f} \, \braket{g}{g}
\label{eq:ecuacion_10_78a}
\end{align}
Si $g(x)$ es una función propia normalizada, $\varphi_{i}(x)$, la ecuación (\ref{eq:ecuacion_10_78}) lleva a (donde $w(x)=1$)
\begin{align}
a_{i}^{*} \, a_{i} \leq \int_{a}^{b} f^{*}(x) \, f(x) \, \dd{x} 
\label{eq:ecuacion_10_81}
\end{align}
Un resultado que se sigue de la ecuación (\ref{eq:ecuacion_10_73}).
\subsection{Ejercicios a cuenta}
\begin{enumerate}
\item Demuestra que:
\begin{align*}
&\int_{-\infty}^{\infty} \left( t^{10} - t^{6} + 5 \, t^{4} - 5 \right) \, e^{-4} \dd{t} \leq \\
&\leq \sqrt{\int_{-\infty}^{\infty} \left( t^{4} - 1 \right)^{2} \, e^{-4} \dd{t}} \, \sqrt{\int_{-\infty}^{\infty} \left( t^{6} + 5 \right)^{2} \, e^{-4} \dd{t}}
\end{align*}
\item Determina las funciones que satisfacen la ecuación de valores propios
\begin{align*}
\hat{A} \, f(x) = \lambda \, f(x)
\end{align*}
cuando $\hat{A}$ es el operador que al aplicarse a una función, la eleva al cuadrado.
\end{enumerate}
\end{document}