\input{../preambulo_doc}
\title{Tema 2 - Separación de variables \\ {\large Matemáticas Avanzadas de la Física}\vspace{-1.5\baselineskip}}
\author{}
\date{ }
\begin{document}
\maketitle
\fontsize{14}{14}\selectfont
\section{Separación de variables.}
La idea de la técnica de separación de variables es suponer que la solución a la EDP $u (x, y, z)$ puede escribirse como
\begin{align*}
u (x, y ,z) =  X(x) \, Y(y) \, Z(z)
\end{align*}
que nos conduce a una EDO para cada una de las funciones $X(x) \, Y(y) \, Z(z)$.
\par
Estas EDO se resuelven y las soluciones \enquote{se unen} para dar la solución a la EDP. La \emph{validez de la solución} debe verificarse porque comenzamos con el supuesto de que las variables podrían separarse.
\par
Como primer ejemplo consideramos el caso de la ecuación de Laplace en dos variables. Veremos que las EDO resultantes son familiares y elementales de resolver.
\section{Tres problemas.}
Trabajaremos tres problemas con la ecuación de calor en estado estacionario, es decir, la temperatura en cada punto del espacio no varía con el tiempo. Recordemos que la ecuación de calor es
\begin{align}
\pdv{T}{t} = \alpha \, \pdv[2]{T}{x}, \hspace{1.5cm} \alpha = \dfrac{k}{\rho \, c}
\label{eq:ecuacion_001}    
\end{align}
donde $\rho$ es la densidad del material, $c$ es el calor específico y $k$ la conductividad térmica.
\par
La ecuación de calor que consideraremos es
\begin{align}
\laplacian{u} = 0
\label{eq:ecuacion_002}    
\end{align}
\subsection{Primer problema: Resolviendo la ecuación de Laplace en un rectángulo.}
La ecuación de Laplace en dos variables es
\begin{align}
\laplacian{u} (x, y) = \pdv[2]{u}{x} + \pdv[2]{u}{y} = 0
\label{eq:ecuacion_003}    
\end{align}
suponemos que tiene una solución del tipo
\begin{align}
u(x, y) = X(x) \, Y(y)
\label{eq:ecuacion_004}
\end{align}
Hacemos la diferenciación de la solución con respecto a $x$ e $y$, entonces tenemos
\begin{align*}
\pdv[2]{u}{x} = X^{\prime \prime} \, Y(y) \hspace{1.5cm} \pdv[2]{u}{y} = Y^{\prime \prime} \, X(x)
\end{align*}
que al sustituir en la ec. (\ref{eq:ecuacion_003}) resulta
\begin{align*}
X^{\prime \prime}(x) \, Y(y) + X(x) \, Y^{\prime \prime}(y) = 0
\end{align*}
Por lo que al dividir la expresión entre $X(x) \, Y(y)$
\begin{align*}
\dfrac{X^{\prime \prime}(x) \, Y(y)}{X(x) \, Y(y)} + \dfrac{X(x) \, Y^{\prime \prime}(y)}{X(x) \, Y(y)} = \dfrac{X^{\prime \prime}(x)}{X(x)} + \dfrac{Y^{\prime \prime}(y)}{Y(y)} = 0
\end{align*}
Así llegamos a
\begin{align}
- \dfrac{X^{\prime \prime}(x)}{X(x)} = \dfrac{Y^{\prime \prime}(y)}{Y(y)}
\label{eq:ecuacion_005}    
\end{align}
Vemos que el lado izquierdo de la ec. (\ref{eq:ecuacion_005}) es una función que sólo depende de $x$ y en el lado derecho la función sólo depende de $y$, para que esto ocurra, ambas expresiones deben de ser iguales a una constante, digamos $\lambda$, de tal manera que
\begin{align*}
- \dfrac{X^{\prime \prime}(x)}{X(x)} = \dfrac{Y^{\prime \prime}(y)}{Y(y)}
 = \lambda
\end{align*}
Por lo que ahora tenemos un sistema de dos EDO de primer orden
\begin{subequations}
\begin{align}
X^{\prime \prime} (x) + \lambda \, X(x) = 0 \label{eq:ecuacion_006a} \\
Y^{\prime \prime} (y) - \lambda \, Y(y) = 0 \label{eq:ecuacion_006b}
\end{align}
\end{subequations}
Revisemos los tres posibles casos:
\begin{enumerate}[label=\roman*)]
\item $\lambda = 0$
\item $\lambda > 0$
\item $\lambda < 0$
\end{enumerate}
Cuando $\lambda = 0$, entonces 
\begin{align*}
X^{\prime \prime}(x) &= 0 \\
X(x) &= A \, x + B
\end{align*}
y de la misma manera tendremos que $Y(y) = C \, y + D$.
\par
Los casos más interesantes que permiten condiciones de frontera no triviales son cuando $\lambda > 0$ y $\lambda < 0$.
\par
Supongamos que $\lambda > 0$, entonces la EDO $X^{\prime \prime} (x) + \lambda \, X(x) = 0 $ tiene por solución
\begin{align*}
X(x) = A \, \cos (\sqrt{\lambda} \, x) + B \, \sin (\sqrt{\lambda} \, x)
\end{align*}
mientras que la EDO $Y^{\prime \prime} (x) - \lambda \, X(x) = 0 $ tiene por solución
\begin{align*}
Y(y) = C \, \cosh (\sqrt{\lambda} \, x) + D \, \sinh (\sqrt{\lambda} \, x)
\end{align*}
\textbf{Ejercicio a cuenta: } Determina las soluciones para las dos EDO cuando $\lambda < 0$.
\par
Establezcamos las condiciones de frontera en un rectángulo como se muestra en la figura (\ref{fig:figura_ecalor_01})
\begin{figure}[H]
    \centering
    \includestandalone{Figuras/01_Separacion_Variables_Cuadrado}
    \caption{Rectángulo con dimensiones $0 \leq x \leq a$ y $0 \leq y \leq b$}
    \label{fig:figura_ecalor_01}
\end{figure}
Establecemos las siguientes condiciones de frontera
\begin{align*}
u(x, 0) = f_{1} (x), \hspace{0.5cm} 0 \leq x \leq a \hspace{1.75cm} u(x, b) = f_{2} (x), \hspace{0.5cm} 0 \leq x \leq a \\[0.5em]
u(0, y) = g_{1} (y), \hspace{0.5cm} 0 \leq y \leq b \hspace{1.75cm} u(a, y) = g_{2} (x), \hspace{0.5cm} 0 \leq y \leq b 
\end{align*}
La forma más sencilla de resolver el problema es considerar cuatro problemas $\laplacian{u}(x, y)$, con las CDF en tres de los lados siendo cero y el valor de la función dada en el cuarto lado, para luego resolver cada uno de los cuatro problemas y sumar las soluciones. El resultado será $\laplacian{u}(x, y)$ y se cumplirán las cuatro CDF. Uno de estos problemas con CDF, que ahora consideramos, será
\begin{align*}
\begin{gathered}
\laplacian{u}(x, y) = 0 \\
u(x, 0) = f_{1} (x), \hspace{0.5cm} 0 \leq x \leq a \hspace{1.75cm} u(x, b) = 0, \hspace{0.5cm} 0 \leq x \leq a \\[0.5em]
u(0, y) = 0, \hspace{0.5cm} 0 \leq y \leq b \hspace{1.75cm} u(a, y) = 0, \hspace{0.5cm} 0 \leq y \leq b
\end{gathered}
\end{align*}
Tenemos entonces que
\begin{align*}
X(x) = A \, \cos \left( \sqrt{\lambda} \, x \right) + B \, \sin \left( \sqrt{\lambda} \, x \right) \hspace{1cm} X(0) = 0, \hspace{0.5cm} X(a) = 0
\end{align*}
Entonces para la primera CDF $X(0) = 0$
\begin{align*}
0 &= A \, \cancelto{1}{\cos \sqrt{\lambda} \, 0} + B \, \cancelto{0}{\sin \sqrt{\lambda} \, 0} \\
\Rightarrow \hspace{0.5cm} X(0) &= A
\end{align*}
y para la segunda CDF $X(a) = 0$ y considerando que $A = 0$, se tiene que
\begin{align*}
0 =  B \, \sin \left( \sqrt{\lambda} \, a \right)
\end{align*}
Para permitir una solución no trivial, debe de ocurrir que $\sqrt{\lambda} \, a = n \, \pi$, para cualquier entero $n$ sea una raíz de la función seno, por lo que
\begin{align*}
\sqrt{\lambda_{n}} \, a &=  n \, \pi \\[0.5em]
\sqrt{\lambda_{n}} &= \dfrac{n \, \pi}{a} \\[0.5em]
\Rightarrow \hspace{0.5cm} \lambda_{n} &= \dfrac{n^{2} \, \pi^{2}}{a^{2}}
\end{align*}
que es un valor propio para el problema con CDF
\begin{align*}
X^{\prime \prime} (x) + \lambda \, X(x) = 0 \hspace{1.5cm} X(0) = 0 \hspace{0.5cm} X(a) = 0
\end{align*}
entonces tenemos que
\begin{align*}
X_{n} (x) = B \, \sin \left( \dfrac{n \, \pi \, x}{a} \right)
\end{align*}
es la correspondiente función propia.
\par
Ahora consideremos la segunda EDO
\begin{align}
Y^{\prime \prime} (y) - \lambda \,  Y(y) = 0, \hspace{1.5cm} Y(b) = 0
\label{eq:ecuacion_007}
\end{align}
Como ya calculamos el valor de $\lambda_{n}$, la ec. (\ref{eq:ecuacion_007}) puede escribirse como
\begin{align*}
Y^{\prime \prime} (y) -  \dfrac{n^{2} \, \pi^{2}}{a^{2}} \,  Y(y) = 0, \hspace{1.5cm} Y(b) = 0
\end{align*}
La solución es
\begin{align*}
Y_{n} (y) = C \, \cosh \left( \dfrac{n \, \pi \, y}{a} \right) + D \, \sinh \left( \dfrac{n \, \pi \, y}{a} \right)
\end{align*}
y la CDF $Y_{n}(b) = 0$ nos devuelve la solución
\begin{align*}
C \cosh \left( \dfrac{n \, \pi \, b}{a} \right) + D \, \sinh \left( \dfrac{n \, \pi \, b}{a} \right) = 0
\end{align*}
por lo que
\begin{align*}
D = - \dfrac{C \cosh \left( \dfrac{n \, \pi \, b}{a} \right)}{\sinh \left( \dfrac{n \, \pi \, b}{a} \right)} = - C \coth \left( \dfrac{n \, \pi \, b}{a} \right)
\end{align*}
y
\begin{align*}
Y_{n}(y) &= C_{n} \, \cosh \left( \dfrac{n \, \pi \, y}{a} \right) + D_{n} \, \sinh \left( \dfrac{n \, \pi \, y}{a} \right) \\
&= C_{n} \left[ \cosh \left( \dfrac{n \, \pi \, y}{a} \right) - \coth \left( \dfrac{n \, \pi \, b}{a} \right) \sinh \left( \dfrac{n \, \pi \, y}{a} \right) \right]
\end{align*}
Escribiendo de una manera más compacta la solución escribirse
\begin{align*}
Y_{n}(y) &= F_{n} \, \sinh \left( \dfrac{n \pi (b - y)}{a} \right)
\end{align*}
que es la función propia para la EDO
\begin{align*}
Y^{\prime \prime} (y) + \dfrac{n^{2} \, \pi^{2}}{a} \, Y(y) = 0, \hspace{1cm} Y(b) = 0
\end{align*}
Para la solución completa de la EDP tendremos
\begin{align*}
u_{n} (x, y) = X_{n} \, Y_{n} = \sin \left( \dfrac{n \, \pi \, x}{a} \right) \left[  \cosh \left( \dfrac{n \, \pi \, y}{a} \right) - \coth \left( \dfrac{n \, \pi \, b}{a} \right) \sinh \left( \dfrac{n \, \pi \, y}{a} \right) \right]
\end{align*}
o de la forma
\begin{align*}
u_{n} (x, y) = \sin \left( \dfrac{n \, \pi \, x}{a} \right) \, \sinh \left[ \dfrac{n \, \pi (b - y)}{a} \right]
\end{align*}
Como la EDP $\laplacian{u} = 0$ es lineal, podemos utilizar el principio de superposición para obtener
\begin{align*}
u (x, y) &= \sum_{n=1}^{\infty} c_{n} \, u_{n} (x, y) = \\
&= \sum_{n=1}^{\infty} c_{n} \, \sin \left( \dfrac{n \, \pi \, x}{a} \right) \left[  \cosh \left( \dfrac{n \, \pi \, y}{a} \right) - \coth \left( \dfrac{n \, \pi \, b}{a} \right) \sinh \left( \dfrac{n \, \pi \, y}{a} \right) \right] \\
&= \sum_{n=1}^{\infty} c_{n} \, \sin \left( \dfrac{n \, \pi \, x}{a} \right) \, \sinh \left[ \dfrac{n \, \pi (b - y)}{a} \right]
\end{align*}
Para especificar las constantes $c_{n}$, tenemos que considerar
\begin{align*}
f_{1} = u(x, 0) &= \sum_{n=1}^{\infty} c_{n} \, u_{n} (x, 0) \\[1em]
&= \sum_{n=1}^{\infty} c_{n} \, \sin \left( \dfrac{n \, \pi \, x}{a} \right) \, \sinh \left[ \dfrac{n \, \pi (b - 0)}{a} \right] \\[1em]
&= \sum_{n=1}^{\infty} c_{n} \, \sin \left( \dfrac{n \, \pi \, x}{a} \right) \, \sinh \left[ \dfrac{n \, \pi \, b}{a} \right]
\end{align*}
Al hacer
\begin{align*}
d_{n} = c_{n} \, \sinh \left[ \dfrac{n \, \pi \, b}{a} \right]
\end{align*}
obtenemos
\begin{align*}
f_{1} = u (x, 0) = \sum_{n=1}^{\infty} d_{n} \, \sin \left( \dfrac{n \, \pi \, x}{a} \right)
\end{align*}
que corresponde a la expansión en series de Fourier de $f_{1}$ en una serie de senos. Los coeficientes están dados entonces por
\begin{align*}
d_{n} = \dfrac{2}{a} \int_{0}^{a} f_{1} \, \sin  \left( \dfrac{n \, \pi \, x}{a} \right) \dd{x}
\end{align*}
por lo tanto
\begin{align*}
c_{n} = \dfrac{d_{n}}{\sinh \left[ \dfrac{n \, \pi \, b}{a} \right]} = \dfrac{\displaystyle \dfrac{2}{a} \int_{0}^{a} f_{1} \, \sin  \left( \dfrac{n \, \pi \, x}{a} \right) \dd{x}}{\sinh \left[ \dfrac{n \, \pi \, b}{a} \right]}
\end{align*}
así
\begin{align*}
u(x,y) &= \sum_{n=1}^{\infty} c_{n} \, u_{n} (x, y) = \\[0.5em]
&= \sum_{n=1}^{\infty} c_{n} \, \sin \left( \dfrac{n \, \pi \, x}{a} \right) \, \sinh \left[ \dfrac{n \, \pi (b - y)}{a} \right] \\[0.5em]
&= \sum_{n=1}^{\infty} \left[ \dfrac{\displaystyle \dfrac{2}{a} \int_{0}^{a} f_{1} \, \sin  \left( \dfrac{n \, \pi \, x}{a} \right) \dd{x}}{\sinh \left[ \dfrac{n \, \pi \, b}{a} \right]} \right] \, \sin \left( \dfrac{n \, \pi \, x}{a} \right) \, \sinh \left[ \dfrac{n \, \pi \, b}{a} \right]
\end{align*}
\textbf{Ejercicio a cuenta: } Demuestra que la solución a
\begin{align*}
\begin{gathered}
\laplacian{u}(x, y) = 0 \\
u(x, 0) = 0, \hspace{0.5cm} 0 \leq x \leq a \hspace{1.75cm} u(a, y) = 0, \hspace{0.5cm} 0 \leq x \leq a \\[0.5em]
u(0, y) = g_{1} (y), \hspace{0.5cm} 0 \leq y \leq b \hspace{1.75cm} u(a, y) = 0, \hspace{0.5cm} 0 \leq y \leq b
\end{gathered}
\end{align*}
es
\begin{align*}
u (x, u) &= \sum_{n=1}^{\infty} \left\{ \left[ \dfrac{2}{b} \int_{0}^{b} g_{1} (y) \, \sin \left( \dfrac{n \, \pi \, y}{b} \right) \dd{y} \right] \, \cosh \left( \dfrac{n \, \pi \, x}{b} \right) + \right. \\[1em]
&- \left. \left[ \dfrac{2}{b} \int_{0}^{b} g_{1} (y) \, \sin \left( \dfrac{n \, \pi \, y}{b} \right) \dd{y} \right] \, \coth \left( \dfrac{n \, \pi \, a}{b} \right) \, \sinh \left( \dfrac{n \, \pi \, x}{b} \right) \right\} \cp \\[1em]
&\cp \sinh \left( \dfrac{n \, \pi \, y}{b} \right)
\end{align*}
\subsection{Problema 2: Resolviendo la ecuación de Laplace en un cilindro.}
En este problema resolveremos la misma ecuación de Laplace en coordenadas polares o cilíndricas. En coordenadas cartesianas, las EDO que surgieron eran fáciles de resolver. Veremos que en las coordenadas cilíndricas y esféricas, no todas las EDO son tan agradables. Las soluciones a estas ODE más difíciles se denominan \emph{funciones de Bessel} y \emph{polinomios de Legendre}, respectivamente.
\par
En coordenadas cilíndricas sólo necesitamos las funciones de Bessel, comenzaremos ésta sección mostrando cómo surgen estas ecuaciones.
\subsection*{Un ejemplo de donde surge las funciones de Bessel.}
Consideremos la ecuación de calor
\begin{align*}
u_{t} = K \, \laplacian{u}
\end{align*}
La razón por la cual las ecuaciones que surgen de la separación de variables en coordenadas cilíndricas no es tan simple como en las coordenadas cartesianas se debe a la forma del laplaciano. En coordenadas cilíndricas, el laplaciano viene dado por
\begin{align*}
\laplacian{u} = u_{r r} + \dfrac{1}{r} \, u_{r} + \dfrac{1}{r^{2}} \, u_{\theta \theta} + u_{z z}
\end{align*}
Para simplificar las cuentas y con ello, demostrar la manera en la que se obtienen las funciones de Bessel, supondremos que $u$ es función sólo de $r, \theta$ y $t$, y no función de $z$.
\par
Entonces podemos suponer que la solución puede escribirse como
\begin{align*}
u (r, \theta, t) = R (r) \, \Theta (\theta) \, T (t)
\end{align*}
por lo que
\begin{align*}
u_{t} = K \, \laplacian{u}
\end{align*}
se puede expresar como
\begin{align*}
R (r) \, \Theta (\theta) \, T^{\prime} (t) = K \left[ R^{\prime \prime} (r) \Theta (\theta) T (t) + \dfrac{1}{r} R^{\prime} (r) \Theta (\theta) T (t) + \dfrac{1}{r^{2}} R (r) \Theta^{\prime \prime} (\theta) T (t) \right]
\end{align*}
dividiendo entre $K \, R (r) \, \Theta (\theta) \, T (t)$ se obtiene
\begin{align}
\dfrac{1}{K} \, \dfrac{T^{\prime} (t)}{T (t)} = \dfrac{R^{\prime \prime} (r)}{R (r)} + \dfrac{1}{r} \dfrac{R^{\prime} (r)}{R(r)} + \dfrac{1}{r^{2}} \dfrac{\Theta^{\prime \prime} (\theta)}{\Theta (\theta)}
\label{eq:ecuacion_008}
\end{align}
El lado izquierdo de la ec. (\ref{eq:ecuacion_008}) es una función sólo de $t$, mientras que el lado derecho es una función de $r$ y $\theta$, por lo que deben ser iguales a una constante: $- \lambda$, por lo que
\begin{align}
\dfrac{1}{K} \, \dfrac{T^{\prime} (t)}{T (t)} = - \lambda \hspace{1cm} \Rightarrow \hspace{1cm} T^{\prime} (t) + \lambda \, K \, T (t) = 0
\label{eq:ecuacion_009}
\end{align}
entonces
\begin{align*}
\dfrac{R^{\prime \prime} (r)}{R (r)} + \dfrac{1}{r} \, \dfrac{R^{\prime} (r)}{R(r)} + \dfrac{1}{r^{2}} \, \dfrac{\Theta^{\prime \prime} (\theta)}{\Theta (\theta)} = - \lambda
\end{align*}
de aquí resulta
\begin{align*}
\dfrac{R^{\prime \prime} (r)}{R (r)} + \dfrac{1}{r} \, \dfrac{R^{\prime} (r)}{R(r)} + \lambda = - \dfrac{1}{r^{2}} \, \dfrac{\Theta^{\prime \prime} (\theta)}{\Theta (\theta)} 
\end{align*}
o de manera equivalente
\begin{align}
r^{2} \, \left[ \dfrac{R^{\prime \prime} (r)}{R (r)} + \dfrac{1}{r} \, \dfrac{R^{\prime} (r)}{R(r)} + \lambda \right] = - \dfrac{\Theta^{\prime \prime} (\theta)}{\Theta (\theta)}
\label{eq:ecuacion_010}
\end{align}
El lado izquierdo de la ec. (\ref{eq:ecuacion_010}) es una función que depende sólo de $r$, mientras que la función del lado derecho es una función de $\theta$, por lo que ambas deben de ser iguales a una constante: $\mu$. Entonces, tenemos que un sistema de dos EDO, la primera:
\begin{align}
\Theta^{\prime \prime} (\theta) + \mu \, \Theta (\theta) = 0
\label{eq:ecuacion_011}
\end{align}
y la segunda:
\begin{align*}
r^{2} &\, \left[ \dfrac{R^{\prime \prime} (r)}{R (r)} + \dfrac{1}{r} \, \dfrac{R^{\prime} (r)}{R(r)} + \lambda \right] = \mu \\[0.5em]
&{} \dfrac{R^{\prime \prime} (r)}{R (r)} + \dfrac{1}{r} \, \dfrac{R^{\prime} (r)}{R(r)} + \lambda = \dfrac{\mu}{r^{2}}
\end{align*}
resulta entonces que
\begin{align}
R^{\prime \prime} (r) + \dfrac{1}{r} \, R^{\prime} (r) + \left( \lambda - \dfrac{\mu}{r^{2}} \right) R (r) = 0
\label{eq:ecuacion_012}
\end{align}
Entonces tenemos que para resolver la ecuación de valor en coordenadas polares, se deben de resolver las ecs. (\ref{eq:ecuacion_009}), (\ref{eq:ecuacion_011}) y (\ref{eq:ecuacion_012}). De éstas ecuaciones, sólo la ec. (\ref{eq:ecuacion_012}) requiere de una atención especial.
\par
La ecuación resultante es una \emph{ecuación de tipo Bessel}, que se obtuvo al utilizar el Laplaciano en coordenadas polares o cilíndricas. Con la ecuación de Laplace veremos que es de la forma
\begin{align*}
R^{\prime \prime} (r) + \dfrac{1}{r} \, R^{\prime} (r) - \left( m^{2} + \dfrac{n^{2}}{r^{2}} \right) \, R (r) = 0
\end{align*}
Cuando consideramos que la función $u$ también depende de la variable $z$ y la solución propuesta es
\begin{align*}
u(r, \theta, z, t) = R(r) \, \Theta (\theta) \, T(t) \, Z (z)
\end{align*}
la ecuación (\ref{eq:ecuacion_012}) habría sido la única EDO complicada que habría surgido.
\par
La ecuación (\ref{eq:ecuacion_012}) es una ecuación similar a la ecuación de Bessel. Con este tipo de expresión encontraremos una solución a tales ecuaciones y luego hacemos una transformación que nos permitirá resolver la ecuación anterior. (Dado que esta es una ecuación diferencial de segundo orden, hay dos soluciones, pero una presenta cierta característica en $r = 0$, en congruencia con la física del problema, ésta será una solución inadmisible.
\par
Una ecuación de Bessel es una ecuación de la forma
\begin{align*}
x^{2} \, y^{\prime \prime} +  x \, y^{\prime} (x) + (x^{2} - \nu^{2}) \, y(x) = 0 \hspace{1cm} 0 \leq x < \infty
\end{align*}
Para resolver este tipo de ecuación usaremos una serie de potencias.
\begin{enumerate}[label=\textbf{Paso \arabic*}.]
\item Suponemos que la ecuación tiene una solución de la forma
\begin{align*}
y = \sum_{n=0}^{\infty} a_{n} \, x^{n+\alpha}
\end{align*}
En el sentido de que la solución esté acotada en $x = 0$, se necesita que $\alpha \geq 0$.
\item Diferenciamos la solución para luego agrupar términos. Se tiene entonces que
\begin{align*}
y^{\prime} = \sum_{n=0}^{\infty} a_{n} \, (n + \alpha) \, x^{n+\alpha-1}
\end{align*}
por lo que
\begin{align*}
x \, y^{\prime} = \sum_{n=0}^{\infty} a_{n} \, (n + \alpha) \, x^{n+\alpha}
\end{align*}
Para la segunda derivada
\begin{align*}
y^{\prime \prime} = \sum_{n=0}^{\infty} a_{n} \, (n + \alpha) \, (n + \alpha - 1) \, x^{n+\alpha-2}
\end{align*}
entonces
\begin{align*}
x^{2} \, y^{\prime \prime} = \sum_{n=0}^{\infty} a_{n} \, (n + \alpha) \, (n + \alpha - 1) \, x^{n + \alpha}
\end{align*}
entonces al sustituir en la EDO2 con las expresiones anteriores, tenemos
\begin{align*}
x^{2} \, y^{\prime \prime} &+  x \, y^{\prime} (x) + (x^{2} - \nu^{2}) \, y(x) = \\
&= \sum_{n=0}^{\infty}  \left[ a_{n} \, (n + \alpha) \, (n + \alpha - 1) \, x^{n + \alpha} \right] + \left[ a_{n} \, (n + \alpha) \, x^{n+\alpha} \right] + \\
&+  \left[ (a_{n} \, x^{n + \alpha + 2}) - \nu^{2} \, a_{n} \, x^{n + \alpha} \right] = 0
\end{align*}
Esta expresión puede escribirse como
\begin{align*}
a_{0} &\left[ \alpha (\alpha - 1) + \alpha - \nu^{2} \right] \, x^{\alpha} + a_{1} \left[ (\alpha + 1) \, \alpha + (\alpha + 1) - \nu^{2} \right] \, x^{\alpha+1} + \\[0.5em]
&+ \sum_{n=2}^{\infty} \left\{ a_{n} \left[ (n + \alpha)((n + \alpha) - 1) + (n + \alpha) - \nu^{2} \right] + a_{n-2} \right\} \, x^{\alpha + n} \\[0.5em]
&= a_{0} (a^{2} - \nu^{2}) \, x^{\alpha} + a_{1} \left[ (\alpha + 1)^{2} - \nu^{2} \right] + \\[0.5em]
&+ \sum_{n=2}^{\infty} \left\{ \left[ (n + \alpha)^{2} - \nu^{2} \right] \, a_{n} + a_{n-2} \right\} \, x^{\alpha + n} = 0
\end{align*}
De acuerdo con el análisis de unicidad de la serie de potencias, los coeficientes de cada potencia de $x$ debe anularse.
\vspace{0.25em}
\hrule
\vspace{0.25em}
\textbf{Teorema de la unicidad. } Establece que la representación de la serie de potencias es \emph{única}.
\par
Si
\begin{align*}
f(x) &= \sum_{n=0}^{\infty} a_{n} \, x^{n}, \hspace{1cm} -R_{a} < x < R_{a} \\[0.5em]
&= \sum_{n=0}^{\infty} b_{n} \, x^{n}, \hspace{1cm} -R_{b} < x < R_{b}
\end{align*}
con intervalos traslapados, incluyendo el origen, de modo que
\begin{align*}
a_{n} = b_{n} \hspace{1.5cm} \forall n
\end{align*}
es decir, se suponen dos representaciones de serie de potencias (distintas) y luego se procede para demostrar que las dos son de hecho iguales.
A partir de la expresión inicial, se tiene que
\begin{align*}
\sum_{n=0}^{\infty} a_{n} \, x^{n} = \sum_{n=0}^{\infty} b_{n} \, x^{n}, \hspace{1cm} -R < x < R
\end{align*}
donde $R$ es el menor radio de convergencia de $R_{a}, R_{b}$. Estableciendo $x=0$ para eliminar todos los términos, exceptos los constantes, se obtiene
\begin{align*}
a_{0} = b_{0}
\end{align*}
Ahora bien, aprovechando la capacidad de diferenciación de la serie de potencias, se procede a diferenciar la expresión anterior, con lo cual se obtiene
\begin{align*}
\sum_{n=0}^{\infty}  n \, a_{n} \, x^{n-1} = \sum_{n=0}^{\infty} n \, b_{n} \, x^{n-1}
\end{align*}
Nuevamente hacemos $x = 0$ para aislar los nuevos términos constantes y se encuentra que
\begin{align*}
a_{1} = b_{1}
\end{align*}
Repetimos este procedimiento $n$ veces, se obtiene
\begin{align*}
a_{n} = b_{n}
\end{align*}
lo cual demuestra que las dos series coinciden. En consecuencia, la presentación de la serie de potencias es única.
\vspace{0.25em}
\hrule
\vspace{0.25em}
Entonces el coeficiente de $x^{\alpha}$ debe de anular, y esto nos devuelve la llamada \emph{ecuación de índices o ecuación indicial}, la cual determina el valor de $\alpha$.
\par
Si $\alpha \neq 0$, se tiene que
\begin{align*}
\alpha^{2} - \nu^{2} = 0
\end{align*}
por lo que $\alpha^{2} = \nu^{2}$. De esta manera
\begin{align*}
a_{1} \left[ (\alpha + 1)^{2} - \nu^{2} \right] &= a_{1} \left[ (\alpha + 1)^{2} - \alpha^{2} \right] =  \\
&= a_{1} \left[ 2 \, \alpha + 1 \right] = 0
\end{align*}
Esta es la solución acotada, entonces $\alpha$ es un valor no negativo y $a_{1} = 0$.
\item La relación de recurrencia es:
\begin{align*}
a_{n} \left[ (n + \alpha)((n + \alpha) - 1) + (n + \alpha) - \nu^{2} \right] +  a_{n-2} = 0
\end{align*}
o de manera equivalente
\begin{align*}
a_{n} \left[ (n + \alpha)((n + \alpha) - 1) + (n + \alpha) - \nu^{2} \right] = a_{n} \left[ (n + \alpha^{2} - \nu^{2}) \right] + a_{n-2} = 0
\end{align*}
sustituyendo $\nu$ para $\alpha$, tenemos
\begin{align*}
a_{n} \left[ (n + \nu^{2} - \nu^{2}) \right] = a_{n} \, n \, (n + 2 \, \nu) = - a_{n-2}
\end{align*}
para el coeficiente $a_{n}$
\begin{align*}
a_{n} = - \dfrac{a_{n-2}}{n \, (n + 2 \, \nu)}
\end{align*}
Como $a_{1} = 0$, entonces $a_{k} = 0$ para cualquier entero impar $k$.
\item Ahora daremos una descripción general para los coeficientes $a_{2k}$. Tenemos que
\begin{align*}
a_{2} &= - \dfrac{a_{0}}{2 (2 + 2 \, \nu)} \\
a_{4} &= - \dfrac{a_{2}}{4 (4 + 2 \, \nu)} = \dfrac{(-1)}{4 (4 + 2 \, \nu)} \, \dfrac{(-1) \, a_{0}}{2 (2 + 2 \, \nu)} \\
a_{6} &= \dfrac{a_{4}}{6 (6 + 2 \, \nu)} = - \dfrac{a_{0}}{2^{3} \, (1 \cdot 2 \cdot 3)(3 + \nu)(2 + \nu)(1 + \nu)} \\
&\vdots \\
a_{2k} &= \dfrac{(-1)^{k} \, a_{0}}{2^{2 \, k} \, (k!) \, (k + \nu)(k - 1 + \nu) \ldots (1 + \nu)}
\end{align*}
\end{enumerate}
Por lo que una de las soluciones a la ecuación de Bessel es
\begin{align*}
y_{1} (x) = a_{0} \, x^{\nu} \left[ 1 +  \sum_{k=1}^{\infty}  \dfrac{(-1)^{k} \, x^{2} \, k}{2^{2 \, k} \, (k!) \, (k + \nu)(k - 1 + \nu) \ldots (1 + \nu)} \right]
\end{align*}
Esta es una solución parqa cualquier valor de $v_{0}$, nótese que no hemos impuesto aún las CDF.
\par
Esta es la función de Bessel de primera clase de orden $\nu$, que definimos por $J_{\nu} (x)$. Si hacemos que $a_{0} = 1 / v! \, 2^{v}$, es posible expresar $J_{\nu} (x)$, como
\begin{align}
J_{\nu} (x) = \dfrac{(-1)^{k} \, x^{2 \, k + \nu}}{2^{2 \, k + \nu} \, (k!) \, (k + \nu)!} = \dfrac{(-1)^{k} \, \left( \dfrac{x}{2} \right)^{2 \, k + \nu}}{k! \, (k + \nu)!}
\label{eq:ecuacion_013}
\end{align}
Haciendo la prueba de la razón, esta serie converge para todo valor de $x$.
\par
En el caso de una ecuación de la forma
\begin{align*}
R^{\prime \prime} (r) + \dfrac{1}{r} \, R^{\prime} (r) - \left( m^{2} + \dfrac{n^{2}}{r^{2}} \right) \, R (r) = 0
\end{align*}
que corresponde al caso de la ecuación de Laplace, la solución es la \emph{función modificada de Bessel}, también conocida como la función de Bessel con un argumento imaginario: $I_{\nu} (x)$, que está definida como
\begin{align*}
I_{\nu} (x) = \dfrac{x^{\nu}}{2^{\nu} \, \nu!} \left[ 1 +  \sum_{k=1}^{\infty} \dfrac{x^{2 \, n}}{2^{2 \, n} \, (n!) \, (1 + \nu) \ldots (n +\nu)} \right]
\end{align*}
La función modificada de Bessel se obtiene al reemplazar $x$ con $i \, x$ en la ecuación de Bessel.
\par
La ecuación de Bessel es una ecuación de segundo orden, por lo que habrá dos soluciones independientes iniciales. Para nuestros propósitos, no nos preocuparemos con la segunda solución ya que diverge en $x = 0$. La discusión y derivación de la segunda solución se verá más adelante, pero la segunda solución es de la forma
\begin{align*}
y_{2} (x) = y_{1} (x) \, \ln \abs{x} + \abs{x}^{\nu} \, \sum_{n=1}^{\infty} b_{n} \, x^{n}
\end{align*}
Las dos ecuaciones con las que se inició la discusión del problema, son de la forma
\begin{align*}
y^{\prime \prime} (r)  + \dfrac{(d - 1)}{r} \, y^{\prime} (r)+ \left( \lambda - \dfrac{\mu}{r^{2}} \right) \, y(r) = 0
\end{align*}
Para coordenadas cilíndricas: $d = 2$ y $\mu = m^{2}$, mientras que para coordenadas esféricas, $d = 3$ y $\mu = k \, (k + 1)$.
\subsection{La solución a la ecuación de Bessel en coordendas cilíndricas.}
En nuestro análisis para la ecuación de calor en coordenadas cilíndricas mediante la técnica de separación de variables, llegamos a una expresión de la forma
\begin{align*}
r^{2} \, \dv[2]{R(r)}{r} + r \, \dv{R(r)}{r} + [ \lambda \, r^{2} - \mu ] \, R(r) = 0
\end{align*}
Para nuestro problema $\mu = n^{2}$ donde $n$ es un entero. Entonces, queremos resolver
\begin{align}
r^{2} \, \dv[2]{R(r)}{r} + r \, \dv{R(r)}{r} + [ \lambda \, r^{2} - n^{2} ] \, R(r) = 0
\label{eq:ecuacion_014}
\end{align}
La ec. (\ref{eq:ecuacion_014}) no es una ecuación de tipo Bessel, pero podemos transformarla en una forma de Bessel haciendo el cambio de variable $x = r \, \sqrt{\lambda}$, como se verá. Tenemos que:
\begin{align*}
\dv{R(r)}{r} &= \dv{R(r)}{x} \, \dv{x}{r} = \dv{R(r)}{x} \, \sqrt{\lambda} \hspace{1cm} \mbox{y} \\[0.5em]
\dv[2]{R(r)}{r} &= \dv[2]{R(x)}{x} \, \lambda
\end{align*}
por lo tanto
\begin{align*}
r^{2} \, \dv[2]{R(r)}{r} + r \, \dv{R(r)}{r} + [ \lambda \, r^{2} - n^{2} ] \, R(r) = 0
\end{align*}
Se transforma en
\begin{align}
\begin{aligned}
\left( \dfrac{x}{\sqrt{\lambda}} \right)^{2} \, &\lambda \, \dv[2]{R(x)}{x} + \left( \dfrac{x}{\sqrt{\lambda}} \right) \, \sqrt{\lambda} \, \dv{R(0 x)}{x} + \left[ \lambda \, \dfrac{x^{2}}{\lambda} - n^{2} \right] \, R(x) = \\[0.5em]
&= x^{2} \, \dv[2]{R(x)}{x} + x \, \dv{R(x)}{x} + [x^{2} - n^{2}] \, R(x) = 0
\end{aligned}
\label{eq:ecuacion_015}
\end{align}
La ec. (\ref{eq:ecuacion_015}) es una ecuación de tipo Bessel que tiene dos soluciones. La solución que está acotadea en $x = 0$ es la que normalmente presenta un mayor interés. Esa solución está dada por
\begin{align*}
R(x) = J_{n}(x) = J_{n} (r \, \sqrt{\lambda})
\end{align*}
Cualquier función de Bessel de primera clase tiene un conjunto infinito de raíces positivas.
\par
Sea $ \left\{ x_{nm} \right\}$ el conjunto de raíces positivas de $J_{n}$, es decir $J_{n}(x_{nm}) = 0$. En cualquier ecuación que involucre un cilindro, una de las CDF es tal que el valor de $R(r)$ en la superficie del cilindro es constante. Supongamos que el radio del cilindro es $a$ y que $R(a) = 0$. En el caso de que $R(a)$ sea diferente de una constante, la CDF se obtiene al hacer un reescalamiento. Podemos reescalar la longitud para hacer $a = 1$, que es lo más común. Entonces, en coordenadas cilíndricas, un problema de interés se presenta cuando
\begin{align}
x^{2} \, \dv[2]{R(x)}{x} + x \, \dv{R(x)}{x} + [x^{2} - n^{2}] \, R(x) = 0 \hspace{1.5cm} R(a) = 0
\label{eq:ecuacion_016}
\end{align}
La solución a la ec. (\ref{eq:ecuacion_016})) que es continua en $x = 0$ es
\begin{align*}
R(x) = J_{n} (x) = J_{n} (r \, \sqrt{\lambda})
\end{align*}
y la CDF requiere que se cumpla $J_{n}(a) = 0$. Como tenemos que $J_{n}(x_{nm}) = 0$, si hacemos
\begin{align*}
R_{m}(r) = J_{n} \left( x_{nm} \, \dfrac{r}{a} \right)
\end{align*}
entonces
\begin{align*}
R_{m} (a) = J_{n} \left( x_{nm} \, \dfrac{a}{a} \right) = J_{n} (x_{nm}) = 0
\end{align*}
por tanto
\begin{align*}
R_{m} (r) = J_{n} \left( x_{nm} \, \dfrac{r}{a} \right)
\end{align*}
es una función propia del problema con CI dada por la ec. (\ref{eq:ecuacion_016}). El valor propio para $R_{m}(r)$ es $\left( \dfrac{x_{nm}}{a} \right)^{2}$.
\par
Como veremos más adelante, la ecuación de tipo Bessel (\ref{eq:ecuacion_016}) es del tipo \emph{Sturm-Liouville} con una función de peso $\omega (x) = x$, y las funciones propias son completas, esto es, si $f(x)$ es una función en el intervalo $[0, a]$, para la cual
\begin{align*}
\int_{0}^{a} x \, \bqty{ f(x) }^{2} \dd{x} < \infty
\end{align*}
entonces se tiene que
\begin{align*}
f(x) = \sum_{m=0}^{\infty} b_{m} \, J_{nm} \left( x_{nm} \, \dfrac{x}{a} \right)
\end{align*}
donde los coeficientes $b_{m}$ son
\begin{align*}
b_{m} = \dfrac{\displaystyle \int_{0}^{a} f(x) \, x \, J_{n} \left( x_{nm} \, \dfrac{x}{a} \right) \dd{x}}{\displaystyle \int_{0}^{a} x \, \left[ J_{n} \left( x_{nm} \, \dfrac{x}{a} \right) \right]^{2} \dd{x}}
\end{align*}
\subsection{Resolviendo la ecuación de Laplace en coordenadas cilíndricas mediante la separación de variables.}
En coordenadas cilíndricas la ecuación de Laplace es
\begin{align*}
\laplacian{u} (r, \theta, z) = u_{rr} + \dfrac{1}{r} \, u_{r} + \dfrac{1}{r^{2}} \, u_{\theta \theta} + u_{z z} = 0
\end{align*}
Usaremos las siguientes CDF
\begin{align*}
\begin{gathered}
u_{rr} + \dfrac{1}{r} \, u_{r} + \dfrac{1}{r^{2}} \, u_{\theta \theta} + u_{z z} = 0 \hspace{1.5cm} 0 < r < a, \hspace{1cm} 0 < z < b \\
u(r, \theta, 0) = u(r, \theta, b) = 0, \hspace{1cm} u(a, \theta, z) = f(\theta, z)
\end{gathered}
\end{align*}
Suponemos que existe una solución de la forma
\begin{align*}
u(r, \theta, z) = R(r) \, \Theta (\theta) \, Z(z) 
\end{align*}
por tanto
\begin{align*}
\laplacian{u} (r,\theta, z) &= R^{\prime \prime} (r) \, \Theta (\theta) \, Z (z) + \dfrac{1}{r} \, R (r)^{\prime} \, \Theta (\theta) \, Z (z) + \\
&+ \dfrac{1}{r^{2}} \, R (r) \, \Theta^{\prime \prime} (\theta) \, Z (z) + R(r) \, \Theta (\theta) \, Z^{\prime \prime} (z) = 0
\end{align*}
al dividir entre $R(r) \, \Theta (\theta) \, Z(z)$ tenemos
\begin{align*}
\dfrac{R^{\prime \prime}(r)}{R(r)} + \dfrac{1}{r} \, \dfrac{R^{\prime} (r)}{R (r)} + \dfrac{1}{r^{2}} \, \dfrac{\Theta^{\prime \prime} (\theta)}{\Theta (\theta)} + \dfrac{Z^{\prime \prime}(z)}{Z(z)} = 0
\end{align*}
ordenando los términos
\begin{align}
\dfrac{R^{\prime \prime}(r)}{R(r)} + \dfrac{1}{r} \, \dfrac{R^{\prime} (r)}{R (r)} + \dfrac{1}{r^{2}} \, \dfrac{\Theta^{\prime \prime} (\theta)}{\Theta (\theta)} = - \dfrac{Z^{\prime}{\prime}(z)}{Z(z)}
\label{eq:ecuacion_017}
\end{align}
El lado izquierdo de la ec. (\ref{eq:ecuacion_017}) es una función de $r$ y $\theta$, mientras que del lado derecho tenemos una función que sólo depende de $z$, por lo que ambas deben ser igual a una constante: $C$, por cuestiones de congruencia con la física del problema, $C$ debe de ser una constante positiva, así pues
\begin{align*}
- \dfrac{Z^{\prime}{\prime}(z)}{Z(z)} = C
\end{align*}
por tanto
\begin{align*}
Z^{\prime \prime} + C \, Z (z) = 0
\end{align*}
Entonces la solución a esta EDO es
\begin{align*}
Z (z) = A \, \cos (\sqrt{C} \, z) + B \, \sin (\sqrt{C} \, z)
\end{align*}
y de la CDF $Z(0) = 0$, se tiene que
\begin{align*}
A = 0, \hspace{2cm} Z(b) = 0
\end{align*}
así pues
\begin{align*}
\sqrt{C} = \dfrac{n \, \pi}{b} \hspace{1cm} \text{y} \hspace{1cm} C = \left( \dfrac{n \, \pi \, z}{b} \right)^{2}
\end{align*}
Por lo que
\begin{align*}
Z_{n} (z) = \sin \left( \dfrac{n \, \pi \, z}{b} \right)
\end{align*}
Tenemos entonces que
\begin{align*}
\dfrac{R^{\prime \prime}(r)}{R(r)} + \dfrac{1}{r} \, \dfrac{R^{\prime} (r)}{R (r)} + \dfrac{1}{r^{2}} \, \dfrac{\Theta^{\prime \prime} (\theta)}{\Theta (\theta)} = C
\end{align*}
por lo que
\begin{align*}
r^{2} \left( \dfrac{R^{\prime \prime}(r)}{R(r)} + \dfrac{1}{r} \, \dfrac{R^{\prime} (r)}{R (r)}  - C\right) = - \dfrac{\Theta^{\prime \prime} (\theta)}{\Theta (\theta)}
\end{align*}
encontramos que del lado izquierdo de la igualdad, tenemos una expresión que depende sólo de la variable $r$, mientras que del lado derecho, la dependencia es sólo en la varibale $\theta$, por lo que ambas expresiones son iguales a una constante $D$, así
\begin{align*}
- \dfrac{\Theta^{\prime \prime} (\theta)}{\Theta (\theta)} = D
\end{align*}
entonces tenemos el sistema de dos EDO, la ecuación en $\theta$
\begin{align*}
\Theta^{\prime \prime} (\theta) + D \, \Theta (\theta) = 0
\end{align*}
y la ecuación en $r$
\begin{align}
r^{2} \left( \dfrac{R^{\prime \prime}(r)}{R(r)} + \dfrac{1}{r} \, \dfrac{R^{\prime} (r)}{R (r)}  - C\right) = D
\label{eq:ecuacion_018}
\end{align}
Las condiciones de periodicidad
\begin{align*}
\Theta (\pi) &= \Theta (- \pi) \\[0.5em]
\Theta^{\prime} (\pi) &= \Theta^{\prime} (- \pi)
\end{align*}
necesitan que $D > 0$. Hacemos $D = m^{2}$ y tendremos
\begin{align*}
r^{2} \left( \dfrac{R^{\prime \prime}(r)}{R(r)} + \dfrac{1}{r} \, \dfrac{R^{\prime} (r)}{R (r)}  - C\right) = D \\[0.25em]
\dfrac{R^{\prime \prime}(r)}{R(r)} + \dfrac{1}{r} \, \dfrac{R^{\prime} (r)}{R (r)}  - C - \dfrac{D}{r^{2}} = 0
\end{align*}
luego entonces
\begin{align*}
R (r) &+ \dfrac{1}{r} \, R^{\prime} (r) - \left( C + \dfrac{D}{r^{2}} \right) \, R(r) = \\[0.5em]
&= R (r) + \dfrac{1}{r} \, R^{\prime} (r) - \left[ \left( \dfrac{n \, \pi}{b} \right)^{2} + \dfrac{m^{2}}{r^{2}} \right] \, R(r) = 0
\end{align*}
Para simplificar la notación, hacemos $b = \pi$, para obtener ahora
\begin{align*}
R (r) &+ \dfrac{1}{r} \, R^{\prime} (r) - \left( n^{2} + \dfrac{m^{2}}{r^{2}} \right) \, R (r) = 0
\end{align*}
Podemos recapitular, hemos obtenido un sistema de 3 EDO que tendrán que resolverse:
\begin{align}
\begin{gathered}
Z^{\prime \prime} + n^{2} \, Z (z) = 0 \hspace{1.5cm} Z(0) = Z(\pi) = 0 \\[0.5em]
\Theta^{\prime \prime} (\theta) + m^{2} \, \Theta (\theta) = 0 \hspace{1.5cm} \Theta (\pi) = \Theta (- \pi) \mbox{ y }
\Theta^{\prime} (\pi) = \Theta^{\prime} (- \pi) \\[0.5em]
R (r) + \dfrac{1}{r} \, R^{\prime} (r) - \left( n^{2} + \dfrac{m^{2}}{r^{2}} \right) \, R (r) = 0
\end{gathered}
\label{eq:ecuacion_019}
\end{align}
Nótese que la EDO para $r$ no tiene CDF. En cambio, necesitamos que la solución esté acotada en $r = 0$.
\par
Para resolver la ec. para $r$ usaremos la función de Bessel modificada. Tendremos entonces las soluciones para las EDO:
\begin{align*}
Z_{n} (z) = a_{n} \, \sin (n \, z)
\end{align*}
La ecuación
\begin{align*}
\Theta^{\prime \prime} (\theta) + m^{2} \, \Theta (\theta) = 0
\end{align*}
tiene solamente las condiciones de continuidad para $\Theta (\pi) = \Theta (- \pi), \Theta^{\prime} (\pi) = \Theta^{\prime} (- \pi)$, entonces
\begin{align*}
\Theta_{m} (\theta) = b_{m} \, \cos (m \, \theta) + c_{m} \, \sin (m \, \theta)
\end{align*}
La ecuación
\begin{align*}
R (r) + \dfrac{1}{r} \, R^{\prime} (r) - \left( n^{2} + \dfrac{m^{2}}{r^{2}} \right) \, R (r) = 0
\end{align*}
tiene por solución: $A_{mn} \, I_{m} ( n \, r)$. Escogemos $A_{mn} = 1 / I_{m \, a}$ para que de esta forma
\begin{align*}
R_{mn} (r) = A_{mn} \, I_{m} ( n \, r) = \dfrac{I_{m} (n \, r)}{I_{m} (n \, a)}
\end{align*}
por tanto
\begin{align*}
R_{mn} (a) = \dfrac{I_{m} (n \, a)}{I_{m} (n \, a)} = 1
\end{align*}
Entonces la solución completa para la ecuación de Laplace en coordenadas cilíndricas a partir de la separación de variables es
\begin{align*}
u_{mn} (r, \theta, z) &= R_{mn} \, \Theta_{m} (\theta) \, Z(z) = \\[0.5em]
&= A_{mn} \, I_{m} ( n \, r) \left[ b_{m} \, \cos (m \, \theta) + c_{m} \, \sin (m \, \theta) \right] \, a_{n} \, \sin ( n \, z) = \\[0.5em]
&= \dfrac{1}{I_{m} (n \, a)} \, I_{m} (n \, r) \, \left[ b_{m} \, \cos (m \, \theta) + c_{m} \, \sin (m \, \theta) \right] \, a_{n} \, \sin ( n \, z)
\end{align*}
Las constantes se pueden combinar para escribirse
\begin{align*}
u_{mn} (r, \theta, z) = \dfrac{1}{I_{m} (n \, a)} \, I_{m} (n \, r) \, \sin (n \, z) \, \left[ d_{mn} \, \cos (m \, \theta) + e_{nm} \, \sin (m \, \theta) \right]
\end{align*}
Usando el principio de superposición tenemos entonces que la solución es
\begin{align*}
u (r, \theta, z) &= \dfrac{1}{2} \sum_{n=1}^{\infty} d_{n0} \, \dfrac{1}{I_{0} (n \, a)} \, I_{0} (n \, r) + \\[0.5em]
&+ \sum_{m,n=1}^{\infty} \dfrac{1}{I_{m} (n \, a)} \, I_{m} (n \, r) \, \sin (n \, z) \, \left[ d_{mn} \, \cos (m \, \theta) + e_{nm} \, \sin (m \, \theta) \right]
\end{align*}
Ocupamos la CDF $u(a, \theta, z) = f(\theta, z)$ para obtener
\begin{align*}
u(a, \theta, z) &= f(\theta, z) = \dfrac{1}{2} \sum_{n=1}^{\infty} d_{n0} \, \dfrac{1}{I_{0} (n \, a)} \, I_{0} (n \, a) + \\[0.5em]
&+ \sum_{m,n=1}^{\infty} \dfrac{1}{I_{m} (n \, a)} \, I_{m} (n \, a) \, \sin (n \, z) \, \left[ d_{mn} \, \cos (m \, \theta) + e_{nm} \, \sin (m \, \theta) \right] = \\[0.5em]
&= \dfrac{1}{2} \sum_{n=1}^{\infty} d_{n0} + \sum_{m,n=1}^{\infty} \sin (n \, z) \, \left[ d_{mn} \, \cos (m \, \theta) + e_{nm} \, \sin (m \, \theta) \right]
\end{align*}
Entonces los coeficientes $d_{nm}$ y $e_{nm}$, son correspondientemente
\begin{align*}
d_{nm} = \dfrac{1}{\pi} \, \dfrac{2}{\pi} \int_{z=0}^{\pi} \left[ \int_{\theta=0}^{2 \pi} f(\theta, z) \, \cos (m \, \theta) \dd{\theta} \right] \, \sin (n \, z) \dd{z}
\end{align*}
y
\begin{align*}
e_{nm} = \dfrac{1}{\pi} \, \dfrac{2}{\pi} \int_{z=0}^{\pi} \left[ \int_{\theta=0}^{2 \pi} f(\theta, z) \, \sin (m \, \theta) \dd{\theta} \right] \, \sin (n \, z) \dd{z}
\end{align*}
Vemos que la coordenada $z$ puede ser problemática. Algunos autores resuelven el problema sólo en coordenadas polares. Si no se establece una CDF en $Z (z)$, el signo de la constante de separación $C$, no se puede asignar.
\section{Problema 3: Resolviendo la ecuación de Laplace en coordenadas esféricas.}
En el ejercicio anterior usamos la separación de variables para resolver la EDP expresada en coordenadas cilíndricas en las que apareció el Laplaciano. Vimos que entre las EDO que surgieron había una ecuación de Bessel (o, al menos, una similar a la tipo Bessel). En este problema, seguiremos un enfoque similar, excepto que trabajaremos en coordenadas esféricas. Veremos que, además de una ecuación de Bessel, encontramos una ecuación diferencial llamada \emph{ecuación de Legendre}.
\par
Las ecuaciones de Legendre surgen cuando se resuelve una EDP en coordenadas esféricas que usan el Laplaciano. 
\par
En coordenadas esféricas, el laplaciano es
\begin{align*}
\laplacian{u} (r, \theta, \varphi) = \dfrac{1}{r^{2}} \, \pdv[2]{r} (r^{2} \, u_{r}) + \dfrac{1}{r^{2} \, \sin \theta} \, \pdv{\theta} (\sin \theta \, u_{\theta}) + \dfrac{1}{r^{2} \, \sin \theta} \, u_{\varphi \varphi}
\end{align*}
Veamos que
\begin{align*}
\pdv{\theta}(\sin \theta \, u_{\theta}) = \cos \theta \, u_{\theta} + \sin \theta \, u_{\theta \theta}
\end{align*}
y que
\begin{align*}
\dfrac{1}{r^{2}} \, \pdv{r} (r^{2} \, u_{r}) = \dfrac{1}{r^{2}} \, (2 \,r \, u_{r} + r^{2} \, u_{rr} ) = \dfrac{2}{r} \, u_{r} + u_{r r}
\end{align*}
entonces tenemos que
\begin{align}
&\laplacian{u} (r, \theta, \varphi) = \dfrac{1}{r^{2}} \pdv{r}(r^{2} \, u_{r}) + \dfrac{1}{r^{2} \, \sin \theta} \, \pdv{\theta} (\sin \theta \, u_{\theta}) + \dfrac{1}{r^{2} \ \sin \theta} \, u_{\theta \theta} = \nonumber \\[0.5em]
&= \left[ \dfrac{2}{r} \, u_{r} + u_{r r} \right] + \dfrac{1}{r^{2} \, \sin \theta} \left( \cos \theta \, u_{\theta} + \sin \theta \, u_{\theta \theta} \right) + \dfrac{1}{r^{2} \, \sin \theta} \, u_{\theta \theta} \label{eq:ecuacion_020} \\[0.5em]
&= \left[ \dfrac{2}{r} \, u_{r} + u_{r r} \right] + \dfrac{1}{r^{2}} \, \left( \cot \theta \, u_{\theta} + u_{\theta \theta} + \dfrac{u_{\theta \theta}}{\sin^{2} \theta} \right) \nonumber
\end{align}
Entonces suponemos que existe una solución de la forma
\begin{align*}
u (r, \theta, \varphi) = R(r)\, \Theta (\theta) \, \Phi (\varphi)
\end{align*}
Entonces la ec. $\laplacian{u} = 0$ se puede escribir como
\begin{align*}
\dfrac{\laplacian{u} (r, \theta, \varphi)}{u} = \dfrac{2}{r} \, \dfrac{R^{\prime}}{R} + \dfrac{R^{\prime \prime}}{R} + \dfrac{1}{r^{2}} \, \left( \cot \theta \, \dfrac{\Theta^{\prime}}{\Theta} + \dfrac{\Theta^{\prime \prime}}{\Theta} + \dfrac{1}{\sin^{2} \theta} \, \dfrac{\Phi^{\prime \prime}}{\Phi} \right) = 0  
\end{align*}
De donde obtenemos
\begin{align*}
\dfrac{2}{r} \, \dfrac{R^{\prime}}{R} + \dfrac{R^{\prime \prime}}{R} = - \dfrac{1}{r^{2}} \, \left( \cot \theta \, \dfrac{\Theta^{\prime}}{\Theta} + \dfrac{\Theta^{\prime \prime}}{\Theta} + \dfrac{1}{\sin^{2} \theta} \, \dfrac{\Phi^{\prime \prime}}{\Phi} \right)
\end{align*}
por tanto
\begin{align}
- r^{2} \left( \dfrac{2}{r} \, \dfrac{R^{\prime}}{R} + \dfrac{R^{\prime \prime}}{R} \right) = \cot \theta \, \dfrac{\Theta^{\prime}}{\Theta} + \dfrac{\Theta^{\prime \prime}}{\Theta} + \dfrac{1}{\sin^{2} \theta} \, \dfrac{\Phi^{\prime \prime}}{\Phi}
\label{eq:ecuacion_021}
\end{align}
Tenemos que la expresión que está al lado izquierdo de la igualdad depende sólo de $r$ mientras que la del lado derecho, depende tanto de $\theta$ como de $\varphi$, para que se cumpla esto, deben de ser iguales a una constante, que dejaremos como negativa: $- \mu$:
\begin{align}
\cot \theta \, \dfrac{\Theta^{\prime}}{\Theta} + \dfrac{\Theta^{\prime \prime}}{\Theta} + \dfrac{1}{\sin^{2} \theta} \, \dfrac{\Phi^{\prime \prime}}{\Phi} = - \mu
\label{eq:ecuacion_022}
\end{align}
además se tiene que
\begin{align}
r^{2} \left( \dfrac{2}{r} \, \dfrac{R^{\prime}}{R} + \dfrac{R^{\prime \prime}}{R} \right) = \mu
\label{eq:ecuacion_023}    
\end{align}
Multiplicando la ec. (\ref{eq:ecuacion_021}) por $\sin^{2} \theta$ obtenemos
\begin{align*}
\sin^{2} \theta \, \cot \theta \, \dfrac{\Theta^{\prime}}{\Theta} + \sin^{2} \theta \dfrac{\Theta^{\prime \prime}}{\Theta} + \dfrac{\Phi^{\prime \prime}}{\Phi} = - \mu \, \sin^{2} \theta
\end{align*}
así
\begin{align}
\sin^{2} \theta \, \cot \theta \, \dfrac{\Theta^{\prime}}{\Theta} + \sin^{2} \theta \dfrac{\Theta^{\prime \prime}}{\Theta} + \mu \, \sin^{2} \theta = - \dfrac{\Phi^{\prime \prime}}{\Phi}
\label{eq:ecuacion_024}    
\end{align}
El lado izquierdo de la ec. (\ref{eq:ecuacion_023}) es una función que depende sólo de $\theta$ y la función del lado derecho depende sólo de $\varphi$, por lo que la constante de separación será $\nu$. Veremos que $\nu > 0$, tenemos que
\begin{align*}
- \dfrac{\Phi^{\prime \prime}}{\Phi} &= \nu \\
\Rightarrow \hspace{0.5cm} \Phi^{\prime \prime} + \nu \, \Phi &= 0
\end{align*}
La periodicidad de $\Phi$ nos obliga a considerar que $\nu > 0$. Hacemos $m^{2} = \nu$, por lo que
\begin{align}
\Phi^{\prime \prime} + m^{2} \, \Phi &= 0
\label{eq:ecuacion_025}
\end{align}
También tenemos que
\begin{align*}
\sin^{2} \theta \, \cot \theta \, \dfrac{\Theta^{\prime}}{\Theta} + \sin^{2} \theta \dfrac{\Theta^{\prime \prime}}{\Theta} + \mu \, \sin^{2} \theta = m^{2}
\end{align*}
multiplicando por $\Theta / \sin ^{2} \theta$, obtenemos
\begin{align*}
\cot \theta \, \Theta^{\prime} + \Theta^{\prime \prime} + \mu \, \Theta = \dfrac{m^{2} \, \Theta}{\sin^{2} \theta}
\end{align*}
o de manera equivalente
\begin{align}
\Theta^{\prime \prime} + \cot \theta \, \Theta^{\prime} + \left( \mu + \dfrac{m^{2}}{\sin^{2} \theta} \right) \, \Theta = 0
\label{eq:ecuacion_026}
\end{align}
De la ec. (\ref{eq:ecuacion_023}) para $r$, tenemos que
\begin{align*}
r^{2} \left( \dfrac{2}{r} \, \dfrac{R^{\prime}}{R} + \dfrac{R^{\prime \prime}}{R} \right) = \mu
\end{align*}
tenemos que
\begin{align*}
\dfrac{1}{R} \, \left( R^{\prime \prime} + \dfrac{2}{r} \, R^{\prime} \right) = \dfrac{\mu}{r^{2}}
\end{align*}
por lo que
\begin{align*}
R^{\prime \prime} + \dfrac{2}{r} \, R^{\prime} - \dfrac{\mu}{r^{2}} \, R = 0
\end{align*}
Si hacemos $\mu = \ell (\ell + 1)$, entonces tendremos
\begin{align*}
R^{\prime \prime} + \dfrac{2}{r} \, R^{\prime} - \dfrac{\ell (\ell + 1)}{r^{2}} \, R = 0
\end{align*}
que es equivalente a
\begin{align}
r^{2} \, R^{\prime \prime} +  2 \, r \, R^{\prime} - \ell (\ell + 1) \, R = 0
\label{eq:ecuacion_027}    
\end{align}

\end{document}