\input{../preambulo_doc}
\title{Tema 2 - Separación de variables \\ {\large Matemáticas Avanzadas de la Física}\vspace{-1.5\baselineskip}}
\author{}
\date{ }
\begin{document}
\maketitle
\fontsize{14}{14}\selectfont
\section{Separación de variables.}
La idea de la técnica de separación de variables es suponer que la solución a la EDP $u (x, y, z)$ puede escribirse como
\begin{align*}
u (x, y ,z) =  X(x) \, Y(y) \, Z(z)
\end{align*}
que nos conduce a una EDO para cada una de las funciones $X(x) \, Y(y) \, Z(z)$.
\par
Estas EDO se resuelven y las soluciones \enquote{se unen} para dar la solución a la EDP. La \emph{validez de la solución} debe verificarse porque comenzamos con el supuesto de que las variables podrían separarse.
\par
Como primer ejemplo consideramos el caso de la ecuación de Laplace en dos variables. Veremos que las EDO resultantes son familiares y elementales de resolver.
\section{Tres problemas.}
Trabajaremos tres problemas con la ecuación de calor en estado estacionario, es decir, la temperatura en cada punto del espacio no varía con el tiempo. Recordemos que la ecuación de calor es
\begin{align}
\pdv{T}{t} = \alpha \, \pdv[2]{T}{x}, \hspace{1.5cm} \alpha = \dfrac{k}{\rho \, c}
\label{eq:ecuacion_001}    
\end{align}
donde $\rho$ es la densidad del material, $c$ es el calor específico y $k$ la conductividad térmica.
\par
La ecuación de calor que consideraremos es
\begin{align}
\laplacian{u} = 0
\label{eq:ecuacion_002}    
\end{align}
\subsection{Primer problema: Resolviendo la ecuación de Laplace en un rectángulo.}
La ecuación de Laplace en dos variables es
\begin{align}
\laplacian{u} (x, y) = \pdv[2]{u}{x} + \pdv[2]{u}{y} = 0
\label{eq:ecuacion_003}    
\end{align}
suponemos que tiene una solución del tipo
\begin{align}
u(x, y) = X(x) \, Y(y)
\label{eq:ecuacion_004}
\end{align}
Hacemos la diferenciación de la solución con respecto a $x$ e $y$, entonces tenemos
\begin{align*}
\pdv[2]{u}{x} = X^{\prime \prime} \, Y(y) \hspace{1.5cm} \pdv[2]{u}{y} = Y^{\prime \prime} \, X(x)
\end{align*}
que al sustituir en la ec. (\ref{eq:ecuacion_003}) resulta
\begin{align*}
X^{\prime \prime}(x) \, Y(y) + X(x) \, Y^{\prime \prime}(y) = 0
\end{align*}
Por lo que al dividir la expresión entre $X(x) \, Y(y)$
\begin{align*}
\dfrac{X^{\prime \prime}(x) \, Y(y)}{X(x) \, Y(y)} + \dfrac{X(x) \, Y^{\prime \prime}(y)}{X(x) \, Y(y)} = \dfrac{X^{\prime \prime}(x)}{X(x)} + \dfrac{Y^{\prime \prime}(y)}{Y(y)} = 0
\end{align*}
Así llegamos a
\begin{align}
- \dfrac{X^{\prime \prime}(x)}{X(x)} = \dfrac{Y^{\prime \prime}(y)}{Y(y)}
\label{eq:ecuacion_005}    
\end{align}
Vemos que el lado izquierdo de la ec. (\ref{eq:ecuacion_005}) es una función que sólo depende de $x$ y en el lado derecho la función sólo depende de $y$, para que esto ocurra, ambas expresiones deben de ser iguales a una constante, digamos $\lambda$, de tal manera que
\begin{align*}
- \dfrac{X^{\prime \prime}(x)}{X(x)} = \dfrac{Y^{\prime \prime}(y)}{Y(y)}
 = \lambda
\end{align*}
Por lo que ahora tenemos un sistema de dos EDO de primer orden
\begin{subequations}
\begin{align}
X^{\prime \prime} (x) + \lambda \, X(x) = 0 \label{eq:ecuacion_006a} \\
Y^{\prime \prime} (y) - \lambda \, Y(y) = 0 \label{eq:ecuacion_006b}
\end{align}
\end{subequations}
Revisemos los tres posibles casos:
\begin{enumerate}[label=\roman*)]
\item $\lambda = 0$
\item $\lambda > 0$
\item $\lambda < 0$
\end{enumerate}
Cuando $\lambda = 0$, entonces 
\begin{align*}
X^{\prime \prime}(x) &= 0 \\
X(x) &= A \, x + B
\end{align*}
y de la misma manera tendremos que $Y(y) = C \, y + D$.
\par
Los casos más interesantes que permiten condiciones de frontera no triviales son cuando $\lambda > 0$ y $\lambda < 0$.
\par
Supongamos que $\lambda > 0$, entonces la EDO $X^{\prime \prime} (x) + \lambda \, X(x) = 0 $ tiene por solución
\begin{align*}
X(x) = A \, \cos (\sqrt{\lambda} \, x) + B \, \sin (\sqrt{\lambda} \, x)
\end{align*}
mientras que la EDO $Y^{\prime \prime} (x) - \lambda \, X(x) = 0 $ tiene por solución
\begin{align*}
Y(y) = C \, \cosh (\sqrt{\lambda} \, x) + D \, \sinh (\sqrt{\lambda} \, x)
\end{align*}
\textbf{Ejercicio a cuenta: } Determina las soluciones para las dos EDO cuando $\lambda < 0$.
\par
Establezcamos las condiciones de frontera en un rectángulo como se muestra en la figura (\ref{fig:figura_ecalor_01})
\begin{figure}[H]
    \centering
    \includestandalone{Figuras/01_Separacion_Variables_Cuadrado}
    \caption{Rectángulo con dimensiones $0 \leq x \leq a$ y $0 \leq y \leq b$}
    \label{fig:figura_ecalor_01}
\end{figure}
Establecemos las siguientes condiciones de frontera
\begin{align*}
u(x, 0) = f_{1} (x), \hspace{0.5cm} 0 \leq x \leq a \hspace{1.75cm} u(x, b) = f_{2} (x), \hspace{0.5cm} 0 \leq x \leq a \\[0.5em]
u(0, y) = g_{1} (y), \hspace{0.5cm} 0 \leq y \leq b \hspace{1.75cm} u(a, y) = g_{2} (x), \hspace{0.5cm} 0 \leq y \leq b 
\end{align*}
La forma más sencilla de resolver el problema es considerar cuatro problemas $\laplacian{u}(x, y)$, con las CDF en tres de los lados siendo cero y el valor de la función dada en el cuarto lado, para luego resolver cada uno de los cuatro problemas y sumar las soluciones. El resultado será $\laplacian{u}(x, y)$ y se cumplirán las cuatro CDF. Uno de estos problemas con CDF, que ahora consideramos, será
\begin{align*}
\begin{gathered}
\laplacian{u}(x, y) = 0 \\
u(x, 0) = f_{1} (x), \hspace{0.5cm} 0 \leq x \leq a \hspace{1.75cm} u(x, b) = 0, \hspace{0.5cm} 0 \leq x \leq a \\[0.5em]
u(0, y) = 0, \hspace{0.5cm} 0 \leq y \leq b \hspace{1.75cm} u(a, y) = 0, \hspace{0.5cm} 0 \leq y \leq b
\end{gathered}
\end{align*}
Tenemos entonces que
\begin{align*}
X(x) = A \, \cos \left( \sqrt{\lambda} \, x \right) + B \, \sin \left( \sqrt{\lambda} \, x \right) \hspace{1cm} X(0) = 0, \hspace{0.5cm} X(a) = 0
\end{align*}
Entonces para la primera CDF $X(0) = 0$
\begin{align*}
0 &= A \, \cancelto{1}{\cos \sqrt{\lambda} \, 0} + B \, \cancelto{0}{\sin \sqrt{\lambda} \, 0} \\
\Rightarrow \hspace{0.5cm} X(0) &= A
\end{align*}
y para la segunda CDF $X(a) = 0$ y considerando que $A = 0$, se tiene que
\begin{align*}
0 =  B \, \sin \left( \sqrt{\lambda} \, a \right)
\end{align*}
Para permitir una solución no trivial, debe de ocurrir que $\sqrt{\lambda} \, a = n \, \pi$, para cualquier entero $n$ sea una raíz de la función seno, por lo que
\begin{align*}
\sqrt{\lambda_{n}} \, a &=  n \, \pi \\[0.5em]
\sqrt{\lambda_{n}} &= \dfrac{n \, \pi}{a} \\[0.5em]
\Rightarrow \hspace{0.5cm} \lambda_{n} &= \dfrac{n^{2} \, \pi^{2}}{a^{2}}
\end{align*}
que es un valor propio para el problema con CDF
\begin{align*}
X^{\prime \prime} (x) + \lambda \, X(x) = 0 \hspace{1.5cm} X(0) = 0 \hspace{0.5cm} X(a) = 0
\end{align*}
entonces tenemos que
\begin{align*}
X_{n} (x) = B \, \sin \left( \dfrac{n \, \pi \, x}{a} \right)
\end{align*}
es la correspondiente función propia.
\par
Ahora consideremos la segunda EDO
\begin{align}
Y^{\prime \prime} (y) - \lambda \,  Y(y) = 0, \hspace{1.5cm} Y(b) = 0
\label{eq:ecuacion_007}
\end{align}
Como ya calculamos el valor de $\lambda_{n}$, la ec. (\ref{eq:ecuacion_007}) puede escribirse como
\begin{align*}
Y^{\prime \prime} (y) -  \dfrac{n^{2} \, \pi^{2}}{a^{2}} \,  Y(y) = 0, \hspace{1.5cm} Y(b) = 0
\end{align*}
La solución es
\begin{align*}
Y_{n} (y) = C \, \cosh \left( \dfrac{n \, \pi \, y}{a} \right) + D \, \sinh \left( \dfrac{n \, \pi \, y}{a} \right)
\end{align*}
y la CDF $Y_{n}(b) = 0$ nos devuelve la solución
\begin{align*}
C \cosh \left( \dfrac{n \, \pi \, b}{a} \right) + D \, \sinh \left( \dfrac{n \, \pi \, b}{a} \right) = 0
\end{align*}
por lo que
\begin{align*}
D = - \dfrac{C \cosh \left( \dfrac{n \, \pi \, b}{a} \right)}{\sinh \left( \dfrac{n \, \pi \, b}{a} \right)} = - C \coth \left( \dfrac{n \, \pi \, b}{a} \right)
\end{align*}
y
\begin{align*}
Y_{n}(y) &= C_{n} \, \cosh \left( \dfrac{n \, \pi \, y}{a} \right) + D_{n} \, \sinh \left( \dfrac{n \, \pi \, y}{a} \right) \\
&= C_{n} \left[ \cosh \left( \dfrac{n \, \pi \, y}{a} \right) - \coth \left( \dfrac{n \, \pi \, b}{a} \right) \sinh \left( \dfrac{n \, \pi \, y}{a} \right) \right]
\end{align*}
Escribiendo de una manera más compacta la solución escribirse
\begin{align*}
Y_{n}(y) &= F_{n} \, \sinh \left( \dfrac{n \pi (b - y)}{a} \right)
\end{align*}
que es la función propia para la EDO
\begin{align*}
Y^{\prime \prime} (y) + \dfrac{n^{2} \, \pi^{2}}{a} \, Y(y) = 0, \hspace{1cm} Y(b) = 0
\end{align*}
Para la solución completa de la EDP tendremos
\begin{align*}
u_{n} (x, y) = X_{n} \, Y_{n} = \sin \left( \dfrac{n \, \pi \, x}{a} \right) \left[  \cosh \left( \dfrac{n \, \pi \, y}{a} \right) - \coth \left( \dfrac{n \, \pi \, b}{a} \right) \sinh \left( \dfrac{n \, \pi \, y}{a} \right) \right]
\end{align*}
o de la forma
\begin{align*}
u_{n} (x, y) = \sin \left( \dfrac{n \, \pi \, x}{a} \right) \, \sinh \left[ \dfrac{n \, \pi (b - y)}{a} \right]
\end{align*}
Como la EDP $\laplacian{u} = 0$ es lineal, podemos utilizar el principio de superposición para obtener
\begin{align*}
u (x, y) &= \sum_{n=1}^{\infty} c_{n} \, u_{n} (x, y) = \\
&= \sum_{n=1}^{\infty} c_{n} \, \sin \left( \dfrac{n \, \pi \, x}{a} \right) \left[  \cosh \left( \dfrac{n \, \pi \, y}{a} \right) - \coth \left( \dfrac{n \, \pi \, b}{a} \right) \sinh \left( \dfrac{n \, \pi \, y}{a} \right) \right] \\
&= \sum_{n=1}^{\infty} c_{n} \, \sin \left( \dfrac{n \, \pi \, x}{a} \right) \, \sinh \left[ \dfrac{n \, \pi (b - y)}{a} \right]
\end{align*}
Para especificar las constantes $c_{n}$, tenemos que considerar
\begin{align*}
f_{1} = u(x, 0) &= \sum_{n=1}^{\infty} c_{n} \, u_{n} (x, 0) \\[1em]
&= \sum_{n=1}^{\infty} c_{n} \, \sin \left( \dfrac{n \, \pi \, x}{a} \right) \, \sinh \left[ \dfrac{n \, \pi (b - 0)}{a} \right] \\[1em]
&= \sum_{n=1}^{\infty} c_{n} \, \sin \left( \dfrac{n \, \pi \, x}{a} \right) \, \sinh \left[ \dfrac{n \, \pi \, b}{a} \right]
\end{align*}
Al hacer
\begin{align*}
d_{n} = c_{n} \, \sinh \left[ \dfrac{n \, \pi \, b}{a} \right]
\end{align*}
obtenemos
\begin{align*}
f_{1} = u (x, 0) = \sum_{n=1}^{\infty} d_{n} \, \sin \left( \dfrac{n \, \pi \, x}{a} \right)
\end{align*}
que corresponde a la expansión en series de Fourier de $f_{1}$ en una serie de senos. Los coeficientes están dados entonces por
\begin{align*}
d_{n} = \dfrac{2}{a} \int_{0}^{a} f_{1} \, \sin  \left( \dfrac{n \, \pi \, x}{a} \right) \dd{x}
\end{align*}
por lo tanto
\begin{align*}
c_{n} = \dfrac{d_{n}}{\sinh \left[ \dfrac{n \, \pi \, b}{a} \right]} = \dfrac{\displaystyle \dfrac{2}{a} \int_{0}^{a} f_{1} \, \sin  \left( \dfrac{n \, \pi \, x}{a} \right) \dd{x}}{\sinh \left[ \dfrac{n \, \pi \, b}{a} \right]}
\end{align*}
así
\begin{align*}
u(x,y) &= \sum_{n=1}^{\infty} c_{n} \, u_{n} (x, y) = \\[0.5em]
&= \sum_{n=1}^{\infty} c_{n} \, \sin \left( \dfrac{n \, \pi \, x}{a} \right) \, \sinh \left[ \dfrac{n \, \pi (b - y)}{a} \right] \\[0.5em]
&= \sum_{n=1}^{\infty} \left[ \dfrac{\displaystyle \dfrac{2}{a} \int_{0}^{a} f_{1} \, \sin  \left( \dfrac{n \, \pi \, x}{a} \right) \dd{x}}{\sinh \left[ \dfrac{n \, \pi \, b}{a} \right]} \right] \, \sin \left( \dfrac{n \, \pi \, x}{a} \right) \, \sinh \left[ \dfrac{n \, \pi \, b}{a} \right]
\end{align*}
\textbf{Ejercicio a cuenta: } Demuestra que la solución a
\begin{align*}
\begin{gathered}
\laplacian{u}(x, y) = 0 \\
u(x, 0) = 0, \hspace{0.5cm} 0 \leq x \leq a \hspace{1.75cm} u(a, y) = 0, \hspace{0.5cm} 0 \leq x \leq a \\[0.5em]
u(0, y) = g_{1} (y), \hspace{0.5cm} 0 \leq y \leq b \hspace{1.75cm} u(a, y) = 0, \hspace{0.5cm} 0 \leq y \leq b
\end{gathered}
\end{align*}
es
\begin{align*}
u (x, u) &= \sum_{n=1}^{\infty} \left\{ \left[ \dfrac{2}{b} \int_{0}^{b} g_{1} (y) \, \sin \left( \dfrac{n \, \pi \, y}{b} \right) \dd{y} \right] \, \cosh \left( \dfrac{n \, \pi \, x}{b} \right) + \right. \\[1em]
&- \left. \left[ \dfrac{2}{b} \int_{0}^{b} g_{1} (y) \, \sin \left( \dfrac{n \, \pi \, y}{b} \right) \dd{y} \right] \, \coth \left( \dfrac{n \, \pi \, a}{b} \right) \, \sinh \left( \dfrac{n \, \pi \, x}{b} \right) \right\} \cp \\[1em]
&\cp \sinh \left( \dfrac{n \, \pi \, y}{b} \right)
\end{align*}
\subsection{Problema 2: Resolviendo la ecuación de Laplace en un cilindro.}
En este problema resolveremos la misma ecuación de Laplace en coordenadas polares o cilíndricas. En coordenadas cartesianas, las EDO que surgieron eran fáciles de resolver. Veremos que en las coordenadas cilíndricas y esféricas, no todas las EDO son tan agradables. Las soluciones a estas ODE más difíciles se denominan \emph{funciones de Bessel} y \emph{polinomios de Legendre}, respectivamente.
\par
En coordenadas cilíndricas sólo necesitamos las funciones de Bessel, comenzaremos ésta sección mostrando cómo surgen estas ecuaciones.
\subsection*{Un ejemplo de donde surge las funciones de Bessel.}
Consideremos la ecuación de calor
\begin{align*}
u_{t} = K \, \laplacian{u}
\end{align*}
La razón por la cual las ecuaciones que surgen de la separación de variables en coordenadas cilíndricas no es tan simple como en las coordenadas cartesianas se debe a la forma del laplaciano. En coordenadas cilíndricas, el laplaciano viene dado por
\begin{align*}
\laplacian{u} = u_{r r} + \dfrac{1}{r} \, u_{r} + \dfrac{1}{r^{2}} \, u_{\theta \theta} + u_{z z}
\end{align*}
Para simplificar las cuentas y con ello, demostrar la manera en la que se obtienen las funciones de Bessel, supondremos que $u$ es función sólo de $r, \theta$ y $t$, y no función de $z$.
\par
Entonces podemos suponer que la solución puede escribirse como
\begin{align*}
u (r, \theta, t) = R (r) \, \Theta (\theta) \, T (t)
\end{align*}
por lo que
\begin{align*}
u_{t} = K \, \laplacian{u}
\end{align*}
se puede expresar como
\begin{align*}
R (r) \, \Theta (\theta) \, T^{\prime} (t) = K \left[ R^{\prime \prime} (r) \Theta (\theta) T (t) + \dfrac{1}{r} R^{\prime} (r) \Theta (\theta) T (t) + \dfrac{1}{r^{2}} R (r) \Theta^{\prime \prime} (\theta) T (t) \right]
\end{align*}
dividiendo entre $K \, R (r) \, \Theta (\theta) \, T (t)$ se obtiene
\begin{align}
\dfrac{1}{K} \, \dfrac{T^{\prime} (t)}{T (t)} = \dfrac{R^{\prime \prime} (r)}{R (r)} + \dfrac{1}{r} \dfrac{R^{\prime} (r)}{R(r)} + \dfrac{1}{r^{2}} \dfrac{\Theta^{\prime \prime} (\theta)}{\Theta (\theta)}
\label{eq:ecuacion_008}
\end{align}
El lado izquierdo de la ec. (\ref{eq:ecuacion_008}) es una función sólo de $t$, mientras que el lado derecho es una función de $r$ y $\theta$, por lo que deben ser iguales a una constante: $- \lambda$, por lo que
\begin{align}
\dfrac{1}{K} \, \dfrac{T^{\prime} (t)}{T (t)} = - \lambda \hspace{1cm} \Rightarrow \hspace{1cm} T^{\prime} (t) + \lambda \, K \, T (t) = 0
\label{eq:ecuacion_009}
\end{align}
entonces
\begin{align*}
\dfrac{R^{\prime \prime} (r)}{R (r)} + \dfrac{1}{r} \, \dfrac{R^{\prime} (r)}{R(r)} + \dfrac{1}{r^{2}} \, \dfrac{\Theta^{\prime \prime} (\theta)}{\Theta (\theta)} = - \lambda
\end{align*}
de aquí resulta
\begin{align*}
\dfrac{R^{\prime \prime} (r)}{R (r)} + \dfrac{1}{r} \, \dfrac{R^{\prime} (r)}{R(r)} + \lambda = - \dfrac{1}{r^{2}} \, \dfrac{\Theta^{\prime \prime} (\theta)}{\Theta (\theta)} 
\end{align*}
o de manera equivalente
\begin{align}
r^{2} \, \left[ \dfrac{R^{\prime \prime} (r)}{R (r)} + \dfrac{1}{r} \, \dfrac{R^{\prime} (r)}{R(r)} + \lambda \right] = - \dfrac{\Theta^{\prime \prime} (\theta)}{\Theta (\theta)}
\label{eq:ecuacion_010}
\end{align}
El lado izquierdo de la ec. (\ref{eq:ecuacion_010}) es una función que depende sólo de $r$, mientras que la función del lado derecho es una función de $\theta$, por lo que ambas deben de ser iguales a una constante: $\mu$. Entonces, tenemos que un sistema de dos EDO, la primera:
\begin{align}
\Theta^{\prime \prime} (\theta) + \mu \, \Theta (\theta) = 0
\label{eq:ecuacion_011}
\end{align}
y la segunda:
\begin{align*}
r^{2} &\, \left[ \dfrac{R^{\prime \prime} (r)}{R (r)} + \dfrac{1}{r} \, \dfrac{R^{\prime} (r)}{R(r)} + \lambda \right] = \mu \\[0.5em]
&{} \dfrac{R^{\prime \prime} (r)}{R (r)} + \dfrac{1}{r} \, \dfrac{R^{\prime} (r)}{R(r)} + \lambda = \dfrac{\mu}{r^{2}}
\end{align*}
resulta entonces que
\begin{align}
R^{\prime \prime} (r) + \dfrac{1}{r} \, R^{\prime} (r) + \left( \lambda - \dfrac{\mu}{r^{2}} \right) R (r) = 0
\label{eq:ecuacion_012}
\end{align}
Entonces tenemos que para resolver la ecuación de valor en coordenadas polares, se deben de resolver las ecs. (\ref{eq:ecuacion_009}), (\ref{eq:ecuacion_011}) y (\ref{eq:ecuacion_012}). De éstas ecuaciones, sólo la ec. (\ref{eq:ecuacion_012}) requiere de una atención especial.
\par
La ecuación resultante es una \emph{ecuación de tipo Bessel}, que se obtuvo al utilizar el Laplaciano en coordenadas polares o cilíndricas. Con la ecuación de Laplace veremos que es de la forma
\begin{align*}
R^{\prime \prime} (r) + \dfrac{1}{r} \, R^{\prime} (r) - \left( m^{2} + \dfrac{n^{2}}{r^{2}} \right) \, R (r) = 0
\end{align*}
Cuando consideramos que la función $u$ también depende de la variable $z$ y la solución propuesta es
\begin{align*}
u(r, \theta, z, t) = R(r) \, \Theta (\theta) \, T(t) \, Z (z)
\end{align*}
la ecuación (\ref{eq:ecuacion_012}) habría sido la única EDO complicada que habría surgido.
\par
La ecuación (\ref{eq:ecuacion_012}) es una ecuación similar a la ecuación de Bessel. Con este tipo de expresión encontraremos una solución a tales ecuaciones y luego hacemos una transformación que nos permitirá resolver la ecuación anterior. (Dado que esta es una ecuación diferencial de segundo orden, hay dos soluciones, pero una presenta cierta característica en $r = 0$, en congruencia con la física del problema, ésta será una solución inadmisible.
\par
Una ecuación de Bessel es una ecuación de la forma
\begin{align*}
x^{2} \, y^{\prime \prime} +  x \, y^{\prime} (x) + (x^{2} - \nu^{2}) \, y(x) = 0 \hspace{1cm} 0 \leq x < \infty
\end{align*}
Para resolver este tipo de ecuación usaremos una serie de potencias.
\begin{enumerate}[label=\textbf{Paso \arabic*}.]
\item Suponemos que la ecuación tiene una solución de la forma
\begin{align*}
y = \sum_{n=0}^{\infty} a_{n} \, x^{n+\alpha}
\end{align*}
En el sentido de que la solución esté acotada en $x = 0$, se necesita que $\alpha \geq 0$.
\item Diferenciamos la solución para luego agrupar términos. Se tiene entonces que
\begin{align*}
y^{\prime} = \sum_{n=0}^{\infty} a_{n} \, (n + \alpha) \, x^{n+\alpha-1}
\end{align*}
por lo que
\begin{align*}
x \, y^{\prime} = \sum_{n=0}^{\infty} a_{n} \, (n + \alpha) \, x^{n+\alpha}
\end{align*}
Para la segunda derivada
\begin{align*}
y^{\prime \prime} = \sum_{n=0}^{\infty} a_{n} \, (n + \alpha) \, (n + \alpha - 1) \, x^{n+\alpha-2}
\end{align*}
entonces
\begin{align*}
x^{2} \, y^{\prime \prime} = \sum_{n=0}^{\infty} a_{n} \, (n + \alpha) \, (n + \alpha - 1) \, x^{n + \alpha}
\end{align*}
entonces al sustituir en la EDO2 con las expresiones anteriores, tenemos
\begin{align*}
x^{2} \, y^{\prime \prime} &+  x \, y^{\prime} (x) + (x^{2} - \nu^{2}) \, y(x) = \\
&= \sum_{n=0}^{\infty}  \left[ a_{n} \, (n + \alpha) \, (n + \alpha - 1) \, x^{n + \alpha} \right] + \left[ a_{n} \, (n + \alpha) \, x^{n+\alpha} \right] + \\
&+  \left[ (a_{n} \, x^{n + \alpha + 2}) - \nu^{2} \, a_{n} \, x^{n + \alpha} \right] = 0
\end{align*}
Esta expresión puede escribirse como
\begin{align*}
a_{0} &\left[ \alpha (\alpha - 1) + \alpha - \nu^{2} \right] \, x^{\alpha} + a_{1} \left[ (\alpha + 1) \, \alpha + (\alpha + 1) - \nu^{2} \right] \, x^{\alpha+1} + \\[0.5em]
&+ \sum_{n=2}^{\infty} \left\{ a_{n} \left[ (n + \alpha)((n + \alpha) - 1) + (n + \alpha) - \nu^{2} \right] + a_{n-2} \right\} \, x^{\alpha + n} \\[0.5em]
&= a_{0} (a^{2} - \nu^{2}) \, x^{\alpha} + a_{1} \left[ (\alpha + 1)^{2} - \nu^{2} \right] + \\[0.5em]
&+ \sum_{n=2}^{\infty} \left\{ \left[ (n + \alpha)^{2} - \nu^{2} \right] \, a_{n} + a_{n-2} \right\} \, x^{\alpha + n} = 0
\end{align*}
De acuerdo con el análisis de unicidad de la serie de potencias, los coeficientes de cada potencia de $x$ debe anularse.
\vspace{0.25em}
\hrule
\vspace{0.25em}
\textbf{Teorema de la unicidad. } Establece que la representación de la serie de potencias es \emph{única}.
\par
Si
\begin{align*}
f(x) &= \sum_{n=0}^{\infty} a_{n} \, x^{n}, \hspace{1cm} -R_{a} < x < R_{a} \\[0.5em]
&= \sum_{n=0}^{\infty} b_{n} \, x^{n}, \hspace{1cm} -R_{b} < x < R_{b}
\end{align*}
con intervalos traslapados, incluyendo el origen, de modo que
\begin{align*}
a_{n} = b_{n} \hspace{1.5cm} \forall n
\end{align*}
es decir, se suponen dos representaciones de serie de potencias (distintas) y luego se procede para demostrar que las dos son de hecho iguales.
A partir de la expresión inicial, se tiene que
\begin{align*}
\sum_{n=0}^{\infty} a_{n} \, x^{n} = \sum_{n=0}^{\infty} b_{n} \, x^{n}, \hspace{1cm} -R < x < R
\end{align*}
donde $R$ es el menor radio de convergencia de $R_{a}, R_{b}$. Estableciendo $x=0$ para eliminar todos los términos, exceptos los constantes, se obtiene
\begin{align*}
a_{0} = b_{0}
\end{align*}
Ahora bien, aprovechando la capacidad de diferenciación de la serie de potencias, se procede a diferenciar la expresión anterior, con lo cual se obtiene
\begin{align*}
\sum_{n=0}^{\infty}  n \, a_{n} \, x^{n-1} = \sum_{n=0}^{\infty} n \, b_{n} \, x^{n-1}
\end{align*}
Nuevamente hacemos $x = 0$ para aislar los nuevos términos constantes y se encuentra que
\begin{align*}
a_{1} = b_{1}
\end{align*}
Repetimos este procedimiento $n$ veces, se obtiene
\begin{align*}
a_{n} = b_{n}
\end{align*}
lo cual demuestra que las dos series coinciden. En consecuencia, la presentación de la serie de potencias es única.
\vspace{0.25em}
\hrule
\vspace{0.25em}
Entonces el coeficiente de $x^{\alpha}$ debe de anular, y esto nos devuelve la llamada \emph{ecuación de índices o ecuación indicial}, la cual determina el valor de $\alpha$.
\par
Si $\alpha \neq 0$, se tiene que
\begin{align*}
\alpha^{2} - \nu^{2} = 0
\end{align*}
por lo que $\alpha^{2} = \nu^{2}$. De esta manera
\begin{align*}
a_{1} \left[ (\alpha + 1)^{2} - \nu^{2} \right] &= a_{1} \left[ (\alpha + 1)^{2} - \alpha^{2} \right] =  \\
&= a_{1} \left[ 2 \, \alpha + 1 \right] = 0
\end{align*}
Esta es la solución acotada, entonces $\alpha$ es un valor no negativo y $a_{1} = 0$.
\item La relación de recurrencia es:


\end{enumerate}
\end{document}