\input{../Preambulos/preambulo_materiales}
\usepackage{apacite}
\title{El método de Frobenius \\[0.3em]  \large{Tema 2 - Primeras técnicas de solución}\vspace{-3ex}}
\author{M. en C. Gustavo Contreras Mayén}
\date{ }
\begin{document}
\vspace{-4cm}
\maketitle
\fontsize{14}{14}\selectfont
\tableofcontents
\newpage
\section{Series de potencias.}
\subsection{Introducción.}
%Ref. Bruzzone - Introducción al método de Frobenius

El método propone la búsqueda de soluciones en series de potencias para ecuaciones diferenciales lineales de segundo orden.
\par
Este procedimiento requiere el encontrar relaciones de recurrencia entre los coeficientes de las series buscadas, asumiendo un primer término no nulo.
\subsection{Soluciones analíticas.}

Una clase muy extensa de ecuaciones diferenciales poseen soluciones que se expresan en series de potencias, las cuales son válidas en un dominio determinado. Las funciones que gozan de esta particularidad se les llama \emph{analíticas}.
\par
Las ecuaciones diferenciales más familiares como la ecuación de un oscilador armónico
 \begin{align*}
\ddot{x} + \omega^{2} \, x = 0
 \end{align*}
admite soluciones del tipo
\begin{align*}
x(s) = A_{1} \, \sin( \omega \, s) + A_{2} \, \cos (\omega \, s)
\end{align*}
siendo claro que $\sin( \omega \, s)$ y $\cos( \omega \, s)$ son funciones analiticas.
\par
De igual manera para la ecuación de un oscilador amortiguado, como en un gran número de ecuaciones de la mecánica nos encontraremos que forman parte de este tipo de ecuaciones.
\subsection{Definición.}

Una expresión de la forma:
\begin{align}
a_{0} + a_{1} \, (x - x_{0}) + \ldots + a_{n} \, x^{n} = \sum_{n=0}^{\infty} a_{n} \, (x - x_{0})^{n}
\label{eq:ecuacion_01}    
\end{align}
se llama \textit{serie de potencias}.
\par
La serie puede estar definida por el límite
\begin{align*}
\lim_{N \to \infty} \sum_{n=0}^{N} a_{n} \, (x - x_{0})
\end{align*}
para aquellos valores de $x$ en que exista el límite. En ese caso, se le conoce a la serie como una serie convergente.
\par
Para determinar los valores de $x$ que cumplen la condición de convergencia, se utiiza el criterio del cociente:
\begin{align*}
\lim_{n \to \infty} \dfrac{a_{n+1}}{a_{n}} = \rho \hspace{1.5cm} \begin{cases}
\mbox{Converge si } & \rho < 1 \\
\mbox{Diverge si } & \rho > 1
\end{cases}
\end{align*}
El criterio no clasifica si $\rho = 1$.
\par
Más general es considerar el valor absoluto de dicho cociente, si está acotado por cierto numero $\sigma$ cuando $n \to \infty$, la serie converge cuando $\sigma < 1$. Por lo tanto, tendríamos que
\begin{align*}
\rho = \lim_{n \to \infty} \abs{\dfrac{a_{n+1}}{a_{n}}} \, \abs{x - x_{0}} = L \, \abs{x - x_{0}}
\end{align*}
en donde
\begin{align*}
L = \lim_{n \to \infty} \abs{\dfrac{a_{n+1}}{a_{n}}}
\end{align*}
\par
Si este límite existe, se deduce por la ec. (\ref{eq:ecuacion_01}):
\begin{align}
\begin{aligned}        
\mbox{converge si } &\abs{x - x_{0}} < \dfrac{1}{L} \\[0.5em]
\mbox{diverge si } &\abs{x - x_{0}} > \dfrac{1}{L}
\end{aligned}
\label{eq:ecuacion_02}    
\end{align}
De esta manera tendremos un intervalo de convergencia cuando $L$ existe:
\begin{align*}
\left( x_{0} - \dfrac{1}{L}, x_{0} + \dfrac{1}{L} \right)
\end{align*}
Este intervalo es simétrico respecto de $x_{0}$, de manera tal que \emph{la serie es convergente dentro} de este intervalo y \emph{divergente fuera} del mismo.
\section{Puntos singulares.}
\subsection{Definiciones.}
%Ref. Arfken
Se presenta el concepto de un \emph{punto singular o singularidad} (tal como se aplica a una ecuación diferencial).
\par
El interés en este concepto radica en su utilidad en
\begin{enumerate}
\item Clasificar las ODE.
\item Revisar la viabilidad de una solución en series, esta viabilidad es parte del teorema de Fuchs.
\end{enumerate}
Usando la notación $\displaystyle \dv[2]{y}{x} = y^{\prime \prime}$, tenemos:
\begin{align}
y^{\prime \prime} = f(x, y, y^{\prime})
\label{eq:ecuacion_09_74}
\end{align}
Ahora bien, si en la ec. (\ref{eq:ecuacion_09_74}) $y$ e $y^{\prime}$ pueden tener todos los valores finitos a $x = x_{0}$ e $y^{\prime \prime}$ permanece finita, el punto $x = x_{0}$ es un \emph{punto ordinario}.

Por otra parte, si $y^{\prime \prime}$ se vuelve infinita para cualquier selección finita de $y$ e  $y^{\prime \prime}$, el punto $x = x_{0}$ se denomina \emph{punto singular}.

Si escribimos este EDO2H (en $y$) como
\begin{align}
y^{\prime \prime} + P(x) \: y^{\prime} + Q(x) \: y = 0
\label{eq:ecuacion_09_75}
\end{align}
Ahora bien, si las funciones $P(x)$ y $Q(x)$ permanecen finitas a $x = x_{0}$, el punto $x = x_{0}$ es un \emph{punto ordinario}.

Al contrario, si $P(x)$ y/o $Q(x)$ divergen mientras $x \to x_{0}$, el punto $x_{0}$ es un \emph{punto singular}.

Usando la ecuación (\ref{eq:ecuacion_09_75}) podemos distinguir entre dos tipos de puntos singulares:
\begin{enumerate}
\item Si $P(x)$ y/o $Q(x)$ divergen a medida que $x \to x_{0}$, pero $(x - x_{0}) \: P(x)$ y $(x - x_{0})^{2} \: Q(x)$ permanecen finitas a medida que $x \to x_{0}$, entonces el punto $x = x_{0}$ se llama \textbf{punto singular regular o punto singular no esencial}.
\item Si $P(x)$ diverge más rápidamente que $\dfrac{1}{(x - x_{0})}$, de tal modo que $(x - x_{0}) \: P(x)$ tiene a infinito a medida que $x \to x_{0}$, o cuando $Q(x)$ diverge más rápidamente que $\dfrac{1}{(x - x_{0})^{2}}$, de modo que $(x - x_{0})^{2} \: Q(x)$ tiene a infinito, a medida que $x \to x_{0}$, entonces el punto $x = x_{0}$ se llama \textbf{singularidad esencial o singularidad irregular}.
\end{enumerate}
Estas definiciones son válidas para todos los valores finitos de $x_{0}$. 

El análisis de los puntos al infinito $(x \to \infty)$ es similar al tratamiento que se hace para las funciones en variable compleja.

Hacemos el cambio de variable $x = 1/z$, sustituyendo en la ED y entonces hacemos que $z \to 0$. 

Haciendo el cambio de variable en las derivadas:
\begin{align}
\dv{y(x)}{x} = \dv{y(z^{-1})}{z} \: \dv{z}{x} = - \dfrac{1}{x^{2}} \dv{y(z^{-1})}{z} = -z^{2} \: \dv{y(z^{-1})}{z}
\label{eq:ecuacion_09_76}
\end{align}

Entonces:
\begin{align}
\begin{aligned}
\dv[2]{y(x)}{x} &= \dv{z} \left[ \dv{y(x)}{x} \right] \dv{z}{x} = \\
&= (-z^{2}) \left[ -2 \: z \dv{y(z^{-1})}{z} - z^{2} \: \dv[2]{y(z^{-1})}{z} \right] = \\
&= 2 \: z^{3} \: \dv{y(z^{-1})}{z} + z^{4} \: \dv[2]{y(z^{-1})}{z}
\end{aligned}
\label{eq:ecuacion_09_77}
\end{align}

Usando estos resultados, podemos transformar la ecuación (\ref{eq:ecuacion_09_75}) en
\begin{align}
z^{4} \: \dv[2]{y}{z} + [ 2 \: z^{3} - z^{2} \: P(z^{-1})] \: \dv{y}{z} + Q(z^{-1}) \: y = 0
\label{eq:ecuacion_09_78}
\end{align}

El comportamiento en $x = \infty, (z = 0)$ entonces dependerá del comportamiento de los nuevos coeficientes
\begin{align*}
\dfrac{2 \: z - P(z^{-1})}{z^{2}} \hspace{1cm} \text{ y } \hspace{1cm} \dfrac{Q(z^{-1})}{z^{4}}
\end{align*}
a medida que $z \to 0$.

Si estas dos expresiones se mantienen finitas, el punto $x = \infty$ es un punto ordinario.

Si las expresiones divergen con mayor rapidez que $1/z$ y $1/z^{2}$, respectivamente, el punto $x = \infty$ es un punto regular singular, de otra manera, el punto es irregular singular (una singularidad esencial).

% %Ref. Hassani 2009 Chap. 26
\section{Método de Frobenius.}
\subsection{El método.}

El supuesto básico del método de Frobenius es que la solución de la ED se puede \emph{representar mediante una serie de potencias}.

Esta no es una suposición restrictiva porque todas las funciones encontradas en aplicaciones físicas pueden escribirse como series de potencias siempre que estemos interesados en sus valores que se encuentran en su intervalo de convergencia.

Este intervalo puede ser muy pequeño o puede cubrir toda la línea real.

Una ecuación diferencial de segundo orden homogénea y lineal, se puede escribir como
\begin{align}
p_{2} (x) \, \dv[2]{y}{x} + p_{1} (x) \, \dv{y}{x} + p_{0}(x) \, y = 0
\label{eq:ecuacion_26_07}    
\end{align}

Para casi todas las aplicaciones que se encuentran en física, consideramos que $p_{0}, p_{1}, p_{2}$ son polinomios.

Es posible que la ED no se presenta en la forma que se muestra a partir de, digamos, el método de separación de variables, pero se puede \enquote{llevar} a esa forma.

La forma más complicada de los coeficientes de las derivadas en una ED son típicamente funciones racionales (razones de dos polinomios).

Por lo tanto, multiplicar la ED por el producto de los tres denominadores nos devolverá la ED en la forma dada en la ec. (\ref{eq:ecuacion_26_07}).

El primer paso en el método de Frobenius es \emph{asumir una serie de potencias infinita para y}.

Es común elegir que el punto de expansión sea $x = 0$.

Si $p_{2} (0) \neq 0$, solo es necesario considerar las potencias no negativas de $x$.

Si $p_{2} (0) = 0$, la ED pierde su carácter de \enquote{segundo orden}, y las soluciones no se revisarían en estas notas.

Se tienen dos opciones:
\begin{enumerate}
\item Elegir un punto de expansión diferente a $x_{0} \neq 0$, tal que $p_{2} (x_{0}) \neq 0$.
\item Permitir las potencias no positivas de $x$ en la expansión de $y$.
\end{enumerate}

Rara vez se utiliza la primera opción. Resulta que la forma más económica, pero general, de incorporar la segunda opción es escribir la solución como se muestra a continuación:

La solución que suponemos es del tipo:
\begin{align}
\begin{aligned}
y &= x^{r} \, \sum_{n=0}^{\infty} a_{n} \, x^{n} = \\[0.5em]
&= \sum_{n=0}^{\infty} a_{n} \, x^{n+r} = \\[0.5em]
&= a_{0} \, x^{r} + a_{1} \, x^{r+1} + a_{2} \, x^{r+2} + \ldots
\end{aligned}
\label{eq:ecuacion_26_08}    
\end{align}
donde $r$ es un número real (no necesariamente un entero positivo) que quedará determinado por la ED.

Es habitual elegir $a_{0} = 1$ porque cualquier múltiplo constante de una solución también es una solución.

Si $a_{0} \neq 1$, entonces se multiplica la serie por $1/a_{0}$ y así obtener el valor.

Ya que una serie de potencias es uniformemente convergente (con su radio de convergencia), por lo que se puede diferenciar término a término.

Por lo que al diferenciar la solución en una primera ocasión, tenemos:
\begin{align}
\begin{aligned}
\dv{y}{x} &= \sum_{n=0}^{\infty} a_{n} \, (n + r) \, x^{n+r-1} = \\[0.5em]
&= r \, a_{0} \, x^{r-1} + (r + 1) \, a_{1} \, x^{r} + \ldots
\end{aligned}
\label{eq:ecuacion_26_09a}
\end{align}

Por lo que al diferenciar por segunda vez, tenemos:
\begin{align}
\begin{aligned}
\dv[2]{y}{x} &= \sum_{n=0}^{\infty} a_{n} \, (n + r) \, (n + r - 1) \, x^{n+r-1} = \\[0.5em]
&= r \, (r - 1) \, a_{0} \, x^{r-2} + (r + 1) \, r \, a_{1} \, x^{r}-1 + \ldots
\end{aligned}
\label{eq:ecuacion_26_09b}
\end{align}

Ahora sustituimos las ecuaciones (\ref{eq:ecuacion_26_08}), (\ref{eq:ecuacion_26_09a}) y (\ref{eq:ecuacion_26_09b}) en la ED (\ref{eq:ecuacion_26_07}).

Multiplicamos los polinomios en la serie, agrupamos todas las potencias distintas de $x$ y establecemos el coeficiente de cada término igual a cero. Así obtenemos un conjunto de ecuaciones cuya solución determina el valor de $r$ y las $a_{n}$.

La ecuación que surge de la \emph{potencia más baja de x} involucra solo a $r$, se llama \textbf{ecuación de índices}.

Esta suele ser una ecuación cuadrática en $r$ que se puede resolver para obtener el(los) posible(s) valor(es) de $r$, cada uno de los cuales conduce generalmente a una solución diferente.

Las otras ecuaciones que provienen de potencias superiores de $x$ permiten establecer \emph{relaciones de recurrencia}, es decir, ecuaciones que dan $a_{n}$ en términos de $a_{n-1}$ y $a_{n-2}$. Al iterar esta relación, se pueden obtener todos los $a_{n}$ en términos de solo dos coeficientes.

\subsection{Ejercicio}
% %Ref. Zill ED pág. 279

Resuelve la siguiente EDO2H mediante el método de Frobenius:
\begin{align}
3 \, x \, y^{\prime \prime} + y^{\prime} - y = 0
\label{eq:ecuacion_04}    
\end{align}

Se propone una solución del tipo:
\begin{align*}
y = \sum_{n=0}^{\infty} a_{n} \, x^{n+r}
\end{align*}

Así se tiene que:
\begin{align*}
y^{\prime} &= \sum_{n=0}^{\infty} (n + r) \, a_{n} \, x^{n+r-1} \\[0.5em]
y^{\prime \prime} &= \sum_{n=0}^{\infty} (n + r) \, (n + r - 1) \, a_{n} \, x^{n+r-2}
\end{align*}

De modo que:
\begin{align*}
3 \, x \, y^{\prime \prime} + y^{\prime} - y &= 3 \, \sum_{n=0}^{\infty} (n + r) \, (n + r - 1) \, a_{n} \, x^{n+r-1} + \\[0.5em]
&+ \sum_{n=0}^{\infty} (n + r) \, a_{n} \, x^{n+r-1} + \\[0.5em]
&- \sum_{n=0}^{\infty} a_{n} \, x^{n+r} =
\end{align*}

Haciendo álgebra:
\begin{align*}
&= x^{r} \, \bigg[ r (3 \, r - 2) \, a_{0} \, x^{-1} +  \\[0.5em]
&+ \underbrace{\sum_{n=1} (n + r)\,(3 \, n + 3 \, r - 2) \, a_{n} \, x^{n-1}}_{k=n-1} + \\[0.5em]
&- \underbrace{\sum_{n=0} a_{n} \, x^{n}}_{k=n} \bigg] =
\end{align*}

Llegamos entonces a:
\begin{align*}
&= x^{r} \, \bigg[ r \, (3 \, r - 2) \, a_{0} \, x^{-1} + \\[0.5em]
&+ \sum_{k=0}^{\infty} \left[ (k + r + 1)(3 \, k + 3 \, r + 1) \, a_{k+1} - a_{k} \right] \, x^{k} \bigg] = 0
\end{align*}

Tenemos dos resultados importantes, el primero de ellos lo consideramos de la expresión con la potencia más pequeña del desarrollo:
\begin{align*}
r \, (3 \, r - 2) \, a_{0} = 0
\end{align*}
que se le conoce como \textbf{ecuación de índices}.

El segundo resultado es la \textbf{relación de recurrencia}:
\begin{align*}
(k + r + 1)(3 \, k + 3 \, r + 1) \, a_{k+1} - a_{k} = 0
\end{align*}

Entonces:
\begin{align}
a_{k+1} = \dfrac{a_{k}}{(k + r + 1)(3 \, k + 3 \, r + 1)}
\label{eq:ecuacion_07}
\end{align}

De la ecuación de índices, sabemos desde el inicio que $a_{0} \neq 0$, por lo que
\begin{align}
r (3 \, r - 2) = 0
\label{eq:ecuacion_06}
\end{align}

Que tiene por raíces
\begin{align*}
r_{1} = \dfrac{2}{3} \hspace{1.5cm} r_{2} = 0
\end{align*}

Ocupamos la primera raíz $r_{1} = 2/3$ en la relación de recurrencia (\ref{eq:ecuacion_07}):
\begin{align}
a_{k+1} = \dfrac{a_{k}}{(3 \, k + 5)(k + 1)} \hspace{1.5cm} k = 0, 1, 2, \ldots
\label{eq:ecuacion_08}    
\end{align}

Entonces:
\begin{align*}
a_{1} &= \dfrac{a_{0}}{5 \cdot 1} \\[0.5em]
a_{2} &= \dfrac{a_{1}}{8 \cdot 2} = \dfrac{a_{0}}{2! \, 5 \cdot 8} \\[0.5em]
a_{3} &= \dfrac{a_{2}}{11 \cdot 3} = \dfrac{a_{0}}{3! \, 5 \cdot 8 \cdot 11} \\
\vdots \\[0.5em]
a_{n} &= \dfrac{a_{0}}{n! \, 5 \cdot 8 \cdot 11 \ldots (3\, n + 2)} \hspace{1cm} n = 1, 2, 3, \ldots
\end{align*}

Hemos obtenido la primera solución $y_{1}$ ocupando la raíz $r_{1}$:
\begin{align}
y_{1} = a_{0} \, x^{2/3} \left[ 1 + \sum_{n=1}^{\infty} \dfrac{a_{0}}{n! \, 5 \cdot 8 \cdot 11 \ldots (3\, n + 2)} \, x^{n} \right]
\label{eq:ecuacion_10}    
\end{align}

La segunda raíz de la ecuación de índices: $r_{2} = 0$ nos genera una regla de recurrencia distinta:
\begin{align}
a_{k+1} = \dfrac{a_{k}}{(k+1)(3 \, k +1)} \hspace{1.5cm} k = 0, 1, 2, \ldots
\label{eq:ecuacion_09}    
\end{align}

Los coeficientes que se obtienen son:
\begin{align*}
a_{1} &= \dfrac{a_{0}}{1 \cdot 1} \\[0.5em]
a_{2} &= \dfrac{a_{1}}{2 \cdot 4} = \dfrac{a_{0}}{2! \, 1 \cdot 4}  \\[0.5em]
a_{3} &= \dfrac{a_{2}}{3 \cdot 7} = \dfrac{a_{0}}{3! \, 4 \cdot 7}  \\[0.5em]
\vdots \\
a_{n} &= \dfrac{a_{0}}{n! \, 1 \cdot 4 \cdot 7 \ldots (3 \, n - 2)} \hspace{1cm} n = 1, 2, 3, \ldots
\end{align*}

La segunda solución que obtenemos es:
\begin{align}
y_{2} = a_{0} \, x^{0} \left[ 1 + \sum_{n=1}^{\infty} \dfrac{1}{n! \, 1 \cdot 4 \cdot 7 \ldots (3\, n - 2)} \, x^{n} \right]
\label{eq:ecuacion_11}
\end{align}    

Se puede demostrar que las soluciones (\ref{eq:ecuacion_10}) y (\ref{eq:ecuacion_11}) convergen ambas para todos los valores finitos de $x$.

También es posible ver que las soluciones no es múltiplo de la otra, por lo que $y_{1}(x)$ y $y_{2}(x)$ son linealmente independientes con respecto a $x$.

Por el principio de superposición, tenemos que:

\begin{align*}
y &= C_{1} \, y_{1} (x) + C_{2} \, y_{2} = \\[0.5em]
&= C_{1} \, \left[ x^{2/3} + \sum_{n=1}^{\infty} \dfrac{a_{0}}{n! \, 5 \cdot 8 \cdot 11 \ldots (3\, n + 2)} \, x^{n} \right] + \\[0.5em]
&+ C_{2} \, \left[ 1 + \sum_{n=1}^{\infty} \dfrac{1}{n! \, 1 \cdot 4 \cdot 7 \ldots (3\, n - 2)} \, x^{n} \right]
\end{align*}

\subsection{Casos de las raíces}

Al ocupar el método de Frobenius se pueden presentar tres casos, que corresponden a la naturaleza de las raíces de la ecuación de índices.

Haremos la suposición ie $r_{1}$ y $r_{2}$ son las soluciones \emph{reales} de la ecuación de índices, que cuando son distintas, $r_{1}$ representa la raíz mayor.

\subsection*{Caso 1.}

\textbf{Las raíces no difieren un entero}. Si $r_{1}$ y $r_{2}$ son distintas, pero no difieren  en un entero, entonces existen dos soluciones linealmente independientes de la ED, cuya forma es:
\begin{subequations}
\begin{align}
y_{1} &= \sum_{n=0}^{\infty} a_{n} \, x^{n+r_{1}} \hspace{0.5cm} a_{0} \neq 0 \label{eq:ecuacion_14a} \\[0.5em]
y_{2} &= \sum_{n=0}^{\infty} b_{n} \, x^{n+r_{2}} \hspace{0.5cm} b_{0} \neq 0 \label{eq:ecuacion_14b}
\end{align}
\end{subequations}

\subsection*{Caso 2.}

\textbf{Las raíces difieren en un entero positivo.} Si $r_{1} - r_{2} = N$, donde $N$ es un entero positivo, entonces existe dos soluciones linealmente independientes de la ED, de la forma:
\begin{subequations}
\begin{align}
y_{1} &= \sum_{n=0}^{\infty} a_{n} \, x^{n+r_{1}} \hspace{0.5cm} a_{0} \neq 0 \label{eq:ecuacion_20a} \\[0.5em]
y_{2} &= C \, y_{1} (x) \ln x + \sum_{n=0}^{\infty} b_{n} \, x^{n+r_{2}} \hspace{0.5cm} b_{0} \neq 0 \label{eq:ecuacion_20b}
\end{align}
\end{subequations}

\subsection*{Caso 3.}

\textbf{Las raíces son iguales.} Si $r_{1} = r_{2}$, siempre existen dos soluciones linealmente independientes de la ED, de la forma:
\begin{subequations}
\begin{align}
y_{1} &= \sum_{n=0}^{\infty} a_{n} \, x^{n+r_{1}} \hspace{0.5cm} a_{0} \neq 0 \label{eq:ecuacion_21a} \\[0.5em]
y_{2} &= y_{1} (x) \ln x + \sum_{n=0}^{\infty} b_{n} \, x^{n+r_{1}} \hspace{0.5cm} b_{0} \neq 0 \label{eq:ecuacion_21b}
\end{align}
\end{subequations}

\textbf{Ejercicios a cuenta:}
Determina los puntos singulares de las siguientes ED, clasifica cada punto singular en regular o irregular.
\begin{enumerate}
\item $x^{3} \, y^{\prime \prime} + 4 \, x^{2} \, y^{\prime} + 3 \, y = 0$
\item $x \, y^{\prime \prime} - (x + 3)^{-2} \, y = 0$
\item $(x^{2} - 9)^{2} \, y^{\prime \prime} + (x + 3) \, y^{\prime} + 2 \, y = 0$
\item $y^{\prime \prime} - \dfrac{1}{x} \, y^{\prime} + \dfrac{1}{(x - 1)^{3}} \, y = 0$
\end{enumerate}

\textbf{Ejercicios a cuenta:}
Resuelve las siguientes ED con el método de Frobenius:
\begin{enumerate}
\item $2 \, x \, y^{\prime \prime} - y^{\prime} + 2 \, y = 0$
\item $2 \, x \, y^{\prime \prime} + 5 \, y^{\prime} + x \, y = 0$
\item $x (x - 1) \, y^{\prime \prime} + 3 \, y^{\prime} - 2 \, y = 0$
\item $y^{\prime \prime} - \dfrac{3}{x} \, y^{\prime} - 2 \, y = 0$
\end{enumerate}

% Ref Kirkwood
\section{Ecuación de calor.}
\subsection{Problema completo.}
Considera la ecuación de calor:
\begin{align*}
u_{t} =  \alpha^{2} \,  \laplacian{u}
\end{align*}
La razón por la que las ecuaciones que se obtienen por el método de separación de variables en coordenadas cilíndricas no es tan simple como en coordenadas cartesianas, se debe a la forma del Laplaciano. 

En coordenadas cilíndricas, el laplaciano está dado por
\begin{align*}
u_{xx} = u_{rr} + \dfrac{1}{r} \, u_{r} + \dfrac{1}{r^{2}} \, u_{\theta \theta} + u_{zz}
\end{align*}

Vamos a simplifcar nuestros cálculos y nos permitirá demostrar cómo surgen las funciones de Bessel si suponemos que $u$ es una función de $r$, $\theta$ y $t$, pero no una función de $z$.

\subsection{Separación de variables.}

Ocupando el método de separación de variables, suponemos que existe una solución para $u$, tal que:
\begin{align*}
u_{t} = \alpha^{2} \, \laplacian{u}
\end{align*}

Puede expresarse como:
\begin{align*}
R(r) \, \Theta (\theta) \, T^{\prime} &= \alpha^{2} \bigg[ \stilde{T} (r) \, \Theta (\theta) \, T(t) + \\[0.5em]
&+ \dfrac{1}{r} \ptilde{R} (r) \, \Theta(\theta) \, T(t) + \dfrac{1}{r^{2}} \, R(r) \, \stilde{\Theta} \, T(t) \bigg]
\end{align*}

Dividiendo entre $\alpha^{2} R(r) \, \Theta (\theta) \, T(t)$, tenemos que:
\begin{align}
\dfrac{1}{K} \, \dfrac{\ptilde{T} (t)}{T (t)} = \dfrac{\stilde{R} (r)}{R (r)} + \dfrac{1}{r} \, \dfrac{\ptilde{R} (t)}{R (t)} + \dfrac{1}{r^{2}} \, \dfrac{\stilde{\Theta} (\theta)}{\Theta (\theta)}
\label{eq:ecuacion_K01}
\end{align}

El lado izquierdo de la ecuación es función sólo de $t$. Mientras que el lado derecho de la ecuación es función de $r$ y $\theta$, por lo que deben ser igual a una constante.
\par
En este caso, corresponde a la primera constante de separación: $- \lambda$. Entonces tenemos que:
\begin{align*}
\dfrac{1}{\alpha^{2}} \, \dfrac{\ptilde{T} (t)}{T (t)} = - \lambda
\end{align*}
o de manera equivalente
\begin{align}
\ptilde{T}(t) + \lambda \, \alpha^{2} \, T(t) = 0
\label{eq:ecuacion_K02}    
\end{align}

También tenemos que:
\begin{align*}
\dfrac{\stilde{R} (r)}{R (r)} + \dfrac{1}{r} \, \dfrac{\ptilde{R} (r)}{R (r)} + \dfrac{1}{r^{2}} \, \dfrac{\stilde{\Theta} (\theta)}{\Theta (\theta)} = - \lambda
\end{align*}

Separando nuevamente las funciones
\begin{align*}
\dfrac{\stilde{R} (r)}{R (r)} + \dfrac{1}{r} \, \dfrac{\ptilde{R} (r)}{R (r)} + \lambda = - \dfrac{1}{r^{2}} \, \dfrac{\stilde{\Theta} (\theta)}{\Theta (\theta)}
\end{align*}

Así tenemos:
\begin{align}
r^{2} \left[ \dfrac{\stilde{R} (r)}{R (r)} + \dfrac{1}{r} \, \dfrac{\ptilde{R} (r)}{R (r)} + \lambda \right] = - \dfrac{\stilde{\Theta} (\theta)}{\Theta (\theta)}
\label{eq:ecuacion_K03}    
\end{align}

El lado izquierdo de esta ecuación es función solo de $r$ y el lado derecho es una función de $\theta$, por lo que debe ser igual a una constante: $\mu$, la segunda constante de separación.

\begin{align}
\stilde{\Theta} (\theta) + \mu \, \Theta (\theta) = 0
\label{eq:ecuacion_K04}    
\end{align}

Entonces hacemos:
\begin{align*}
r^{2} \left[ \dfrac{\stilde{R} (r)}{R (r)} + \dfrac{1}{r} \, \dfrac{\ptilde{R} (r)}{R (r)} + \lambda \right] = \mu
\end{align*}

Que al acomodar los términos:
\begin{align*}
\dfrac{\stilde{R} (r)}{R (r)} + \dfrac{1}{r} \, \dfrac{\ptilde{R} (r)}{R (r)} + \lambda = \dfrac{\mu}{r^{2}}
\end{align*}

La ecuación a la que llegamos es:
\begin{align}
\stilde{R} (r) + \dfrac{1}{r} \, \ptilde{R} (r) + \left( \lambda - \dfrac{\mu}{r^{2}} \right) \, R(r) = 0
\label{eq:ecuacion_K05}    
\end{align}

Por lo tanto, para resolver la ecuación de calor en coordenadas polares, necesitamos resolver las ecuaciones (\ref{eq:ecuacion_K02}), (\ref{eq:ecuacion_K04}) y (\ref{eq:ecuacion_K05}). De éstas, solo la ecuación (\ref{eq:ecuacion_K05}) requiere atención adicional.

La ecuación (\ref{eq:ecuacion_K05}) es (como) una \emph{ecuación de Bessel}, es decir, presenta la forma de la ED de Bessel, que es una ecuación que como veremos más adelante, va a definir un conjunto de ecuaciones diferenciales de la física matemática que nos llevan a un conjunto de \emph{funciones especiales}.

La ecuación que obtuvimos, se presenta cuando usamos el Laplaciano en coordenadas polares o cilíndricas en la ecuación de onda o la ecuación de calor.

Como punto importante hay que señalar que a partir de una ecuación inicial, bajo cierta geometría encontramos una ED resultante, para obtener su solución. Este modo de trabajo lo retomaremos en el Tema 5 - Funciones Especiales.

En la ecuación de Laplace, veremos que la ecuación tiene la forma
\begin{align*}
\stilde{R} (r) + \dfrac{1}{r} \, \ptilde{R} (r) + \left( m^{2} - \dfrac{n^{2}}{r^{2}} \right) \, R(r) = 0
\end{align*}

y tendrá que manejarse de manera diferente.

Si hubiéramos asumido que la función $u$ también dependía de $z$ y que la solución propuesta fuese:
\begin{align*}
u(r, \theta, z, t) =  R(r) \, \Theta (\theta) \, T(t) \, Z(z)
\end{align*}
la ec. (\ref{eq:ecuacion_K05}) todavía habría sido la única EDO complicada que habría surgido.

\subsection{Solución en series.}

La ecuación (\ref{eq:ecuacion_K05}) es una ecuación tipo Bessel.

A continuación, definimos una ecuación de Bessel, demostraremos una solución a tales ecuaciones y luego haremos una transformación que nos permitirá resolver la ecuación anterior

Dado que esta es una ED de segundo orden, hay dos soluciones pero una no está acotada en $r=0$. Debido a consideraciones físicas, esta será una solución inadmisible para nuestros problemas.

Una ecuación de Bessel es una ecuación de la forma
\begin{align*}
x^{2} \, \stilde{y} (x) + x \,\ptilde{y} (x) + (x^{2} - \nu^{2}) \, y(x) = 0 \hspace{1cm} 0 \leq x < \infty
\end{align*}

El método de solución que usaremos es mediante una serie de potencias.

Proponemos una solución de la forma:
\begin{align*}
y = \sum_{n=0}^{\infty} \, a_{n} \, x^{n+r}
\end{align*}
Para que la solución esté acotada en $x = 0$, se necesita que $r \geq 0$.

Procedemos a diferenciar y agrupamos los términos, así tenemos que:
\begin{align*}
\ptilde{y} = \sum_{n=0}^{\infty} \, a_{n} \, (n + r) \, x^{n+r-1}
\end{align*}

Por lo que:
\begin{align*}
x \, \ptilde{y} = \sum_{n=0}^{\infty} \, a_{n} \, (n + r) \, x^{n+r}
\end{align*}

La segunda derivada es:
\begin{align*}
\stilde{y} = \sum_{n=0}^{\infty} \, a_{n} \, (n + r) \, (n + r - 1) \, x^{n+r-2}
\end{align*}
Por tanto:
\begin{align*}
x^{2} \, \stilde{y} = \sum_{n=0}^{\infty} \, a_{n} \, (n + r) \, (n + r - 1) \, x^{n+r}
\end{align*}

Al sustituir en la ec. de tipo Bessel, se obtiene
\begin{align*}
&x^{2} \, \stilde{y} (x) + x \,\ptilde{y} (x) + (x^{2} - \nu^{2}) \, y(x) = \\[0.5em]
&= \sum_{n=0}^{\infty} \, \bigg[ \left[ a_{n} \, (n + r) (n + r -1) \, x^{n+r} \right] + a_{n} \, (n + r) \, x^{n+r} + \\[0.5em]
&+ \left[ (a_{n} \, x^{n+r+2} ) - \nu \, a_{n} \, x^{n+r} \right] \bigg] = 0
\end{align*}

Como nos interesa identificar el coeficiente de la potencia menor de $x$, arreglamos la ecuación anterior para ordenar los coeficientes de menor potencia a los de mayor potencia, como veremos a continuación:

\begin{align*}
&a_{0} \bigg[ r (r - 1) + r - \nu^{2} \bigg] \, x^{r} + a_{1} \bigg[ (r + 1) r + (r + 1) - \nu^{2} \bigg] \, x^{r+1} + \\[0.5em]
&+ \sum_{n=2}^{\infty} \left\{ a_{n} \bigg[ (n + r) \left[ (n + r) - 1 \right] + (n + r) - \nu^{2} \bigg] + a_{n-2} \right\} \, x^{r+n} =
\end{align*}
En donde vemos que los dos primeros términos los hemos dejado fuera de la suma. Volvemos a reducir la expresión, para obtener:

\begin{align*}
&= a_{0} (r^{2} - \nu^{2}) \, x^{r} + a_{1} \bigg[ (r + 1)^{2} - \nu^{2} \bigg] + \\[0.5em]
&+ \sum_{n=2}^{\infty} \left\{ \bigg[ (n + r)^{2} - \nu^{2} \bigg] \, a_{n} + a_{n-2} \right\} \, x^{r+n} = 0
\end{align*}

Recordemos que el coeficiente de cada potencia de $x$ debe de anularse.

El coeficiente de $x^{r}$ debe ser igual a cero, lo que nos devuelve la ecuación de índices que nos determina el valor de $r$.

Si $a_{0} \neq 0$, se tiene que
\begin{align*}
r^{2} - \nu^{2} = 0
\end{align*}

Por lo tanto:
\begin{align*}
r^{2} = \nu^{2}
\end{align*}

Entonces ocurre:
\begin{align*}
a_{1} \big[ (r + 1)^{2} - \nu^{2} \big] &= a_{1} \big[ (r + 1)^{2} - r^{2} \big] = \\[0.5em]
&= a_{1} \, \big[ 2 \, r + 1 \big] = 0
\end{align*}

Si la solución está acotada, entonces $r$ debe de ser un valor no negativo, por tanto $a_{1} = 0$.

La regla de recurrencia es:
\begin{align*}
a_{n} \big[ (n + r) \left[ (n + r) - 1 \right] + (n + r) - \nu^{2} \big] + a_{n-2} = 0
\end{align*}

que de manera equivalente, tenemos:
\begin{align*}
&a_{n} \big[ (n + r) \left( (n + r) - 1 \right) + (n + r) - \nu^{2} \big] = \\[0.5em]
&= a_{n} \, \big[ (n + r)^{2} - \nu^{2} \big] + a_{n-2} = 0
\end{align*}

Al sustiruir $\nu$ para $r$
\begin{align*}
a_{n} \, \big[ (n + r)^{2} - \nu^{2} \big] = a_{n} \, n \, (n + 2 \, \nu) = - a_{n-2}
\end{align*}

Es decir:
\begin{align*}
a_{n} = \dfrac{- a_{n-2}}{n (n + 2 \, \nu)}
\end{align*}
Como $a_{1} = 0$, entonces $a_{k} = 0$ para todo entero impar $k$.

Los coeficientes que se mantienen son los $a_{2 k}$, entonces se tiene que:
\begin{align*}
a_{2} &= - \dfrac{a_{0}}{2 (2 + 2 \, \nu)} \\[0.5em]
a_{4} &= - \dfrac{a_{2}}{4 (4 + 2 \, \nu)} = \dfrac{(-1)}{4 (4 + 2 \nu)} \, \dfrac{(-1)a_{0}}{2 (2 + 2 \nu)} \\[0.5em]
a_{6} &= - \dfrac{a_{4}}{6 (6 + 2 \, \nu)} = - \dfrac{a_{0}}{2^{3} \, (1 \cdot 2 \cdot 3) (3 + \nu)(2 + 2 \nu)(1 + \nu)}\\
&\ldots&
\end{align*}

Entonces para el $k$-ésimo coeficiente, tendremos que:
\begin{align*}
a_{2k} = \dfrac{(-1)^{k} \, a_{0}}{2^{2 k} \, (k!) \, (k + \nu) \, (k - 1 + \nu) \ldots (1 + \nu)}
\end{align*}

Entonces podemos presentar una solución a la ecuación diferencial de Bessel:

Tenemos que una de las soluciones a la ecuación de Bessel es:

\begin{align*}
y_{1}(x) = a_{0} \, x^{\nu} \left[ 1 + \sum_{k=1}^{\infty} \dfrac{(-1)^{k} \, a_{0} \, k}{2^{2 k} \, (k!) \, (k + \nu) \, (k -1 + \nu)\ldots (1 + \nu)} \right]
\end{align*}

Que es una solución para cualquier valor de $a_{0}$. Hagamos notar que no se han impuesto condiciones de frontera alguna.

La solución obtenida se le conoce como \emph{función de Bessel de primera clase de orden $\nu$}. Se le representa como $J_{\nu} (x)$.

Si hacemos lo siguiente (que es una norma común en física matemática):
\begin{align*}
a_{0} = \dfrac{1}{\nu!} \, 2^{\nu}
\end{align*}

Se puede expresar $J_{\nu}(x)$ como:
\begin{align*}
J_{\nu}(x) &= \sum_{k=0}^{\infty} \dfrac{(-1)^{k} \, x^{2k+\nu}}{2^{2k+\nu} \, (k!) \, (k + \nu)!} = \\[1em]
&= \sum_{k=0}^{\infty} \dfrac{(-1)^{k} \, \left( \dfrac{x}{2}\right)^{2k+\nu}}{(k!) \, (k + \nu)!}
\end{align*}

Aplicando la prueba del cociente (razón), la serie converge para todos los valores de $x$.

En el caso de que la ecuación de estudio sea de la forma:
\begin{align*}
\stilde{R} (r) + \dfrac{1}{r} \, \ptilde{R} (r) + \left( m^{2} - \dfrac{n^{2}}{r^{2}} \right) \, R(r) = 0
\end{align*}

que sería el caso de la ecuación de Laplace, la solución sería una \emph{función de Bessel modificada}. A esta función de Bessel modificada, se le conoce también como función de Bessel con argumento imaginario. Se le denota como $I_{\nu}(x)$

La función es:
\begin{align*}
I_{\nu}(x) = \dfrac{x^{\nu}}{2^{\nu} \, \nu!} \left[ 1 + \sum_{n=1}^{\infty} \dfrac{x^{2n}}{2^{2n} \, n! \, (1 + \nu) \ldots (n + \nu)} \right]
\end{align*}

La función modificada de Bessel se obtiene al sustituir $x$ por $i \, x$ en la ecuación de Bessel.

\subsection*{Conclusiones.}

La ecuación de Bessel es una EDO2, por lo que debería de tener dos soluciones linealmente independientes.

Haremos de manera conveniente una pausa con la segunda solución, ya que ésta diverge en $x=0$.

La ecuación mostrada en este ejercicio es de la forma:
\begin{align*}
\stilde{y}(r) + \dfrac{d - 1}{r} \, \ptilde{y}(r) + \left( \lambda - \dfrac{\mu}{r^{2}} \right) \, y(r) = 0
\end{align*}
En coord. cilíndricas $d = 2$ y $\mu$ normalmente es $m^{2}$. En coord. esféricas: $d = 3$ y $\mu$ es $k(k+1)$.

\subsection{El teorema de Fuchs.}
El teorema nos dice que se obtendrá al menos una solución en serie de potencias al aplicar el método de Frobenius si el punto de expansión es un punto singular ordinario o regular. 

\textbf{Ejercicio a cuenta:}
Para repasar lo que hemos desarrollado hasta el momento, con la siguente ecuación:
\begin{align*}
x^{2} \, \stilde{y}(x) + x \, \ptilde{y}(x) + (x^{2} - 4) \, y(x) = 0
\end{align*}
Determina:
\begin{enumerate}
\item La ecuación de índices.
\item La regla de recurrencia.
\item La(s) solución(es) en series de potencias.
\end{enumerate}
\end{document}