\input{../Preambulos/preambulo_presentacion_CambridgeUS_beaver}
\title{\large{Segunda solución linealmente independiente}}
\subtitle{Tema 2 - Primeras técnicas de solución}
\author{M. en C. Gustavo Contreras Mayén}
\date{}
\institute{Facultad de Ciencias - UNAM}
\titlegraphic{\includegraphics[width=1.75cm]{../Imagenes/escudo-facultad-ciencias}\hspace*{4.75cm}~%
   \includegraphics[width=1.75cm]{../Imagenes/escudo-unam}
}
\setbeamertemplate{navigation symbols}{}
\begin{document}
\maketitle
\fontsize{14}{14}\selectfont
\spanishdecimal{.}
\section*{Contenido}
\frame{\tableofcontents[currentsection, hideallsubsections]}
%Referencia Arfken - 9.6 A Second Solution
\section{Una segunda solución}
\frame{\tableofcontents[currentsection, hideothersubsections]}
\subsection{Introducción}
\begin{frame}
\frametitle{Introducción}
Con el método de Frobenius se obtuvo una solución de una EDO2H a partir de la sustitución en una serie de potencias.
\\
\bigskip
Esto es posible por el teorema de Fuchs, siempre que la serie de potencias se haga alrededor de un punto ordinario o un punto singular no esencial.
\end{frame}
\begin{frame}
\frametitle{Introducción}
No hay garantía de que este enfoque devuelva dos soluciones independientes que esperamos de una EDO lineal de segundo orden.
\\
\bigskip
Vamos a demostrar que una EDO de este tipo tiene como máximo dos soluciones linealmente independientes. 
\end{frame}
\begin{frame}
\frametitle{Dos métodos }
Presentaremos dos métodos para obtener una segunda solución independiente:
\setbeamercolor{item projected}{bg=blue!70!black,fg=yellow}
\setbeamertemplate{enumerate items}[circle]
\begin{enumerate}[<+->]
\item Un método integral.
\item Una serie de potencias que contiene un término logarítmico.
\end{enumerate}
\end{frame}
\section{Independencia lineal}
\frame[allowframebreaks]{\tableofcontents[currentsection, hideothersubsections]}
\subsection{Independencia lineal de las soluciones}
\begin{frame}
\frametitle{Independencia lineal en funciones}
En primer lugar, sin embargo, consideramos la independencia de un conjunto de funciones.
\\
\bigskip
Dado un conjunto de funciones $\varphi_{\lambda}$, el criterio de dependencia lineal es la existencia de una relación de la forma
{\fontsize{12}{12}\selectfont
\begin{align}
\sum_{\lambda} k_{\lambda} \: \varphi_{\lambda} = 0 
\label{eq:ecuacion_09_111}
\end{align}
}
en la cual, no necesariamente todos los coeficientes de $k_{\lambda}$ son cero.
\end{frame}
\begin{frame}
\frametitle{Independencia lineal en funciones}
Dicho de otra forma, si la única solución de la ecuación (\ref{eq:ecuacion_09_111}) es $k_{\lambda} = 0$, para toda $\lambda$, el conjunto de funciones $\varphi_{\lambda}$ se dice que es \emph{linealmente independiente}.
\end{frame}
% \par
% Pensemos en la dependencia lineal entre vectores. Consideremos $\vb{A}$, $\vb{B}$, y $\vb{C}$, en el espacio 3D, con $\vb{A} \cdot \vb{B} \cp \vb{C} \neq 0$. Entonces la relación no trivial de la forma
% \begin{align}
% a \: \vb{A} + b \: \vb{B} + c \: \vb{C} = 0
% \label{eq:ecuacion_09_112}
% \end{align}
% no existe. Por lo que vemos que $\vb{A}$, $\vb{B}$, y $\vb{C}$ son linealmente independientes.
% \par
% En el caso de que un cuarto vector $\vb{D}$, se puede expresar como una combinación lineal de $\vb{A}$, $\vb{B}$, y $\vb{C}$, podemos escribir una ecuación de la forma
% \begin{align}
% \vb{D} -  a \: \vb{A} - b \: \vb{B} - c \: \vb{C} = 0
% \label{eq:ecuacion_09_113}
% \end{align}
% y los cuatro vectores no son linealmente independientes. Si un conjunto de vectores o funciones son mutuamente ortogonales, entonces sabemos que son linealmente independientes. La ortogonalidad implica independencia lineal.
\begin{frame}
\frametitle{Independencia de funciones}
Supongamos que las funciones $\varphi_{\lambda}$ son diferenciables según se requiera, por tanto, podemos diferenciar la expresión (\ref{eq:ecuacion_09_111}) repetidamente, donde obtenemos el conjunto de ecuaciones:
\end{frame}
\begin{frame}
\frametitle{Independencia de funciones}
\begin{align}
\sum_{\lambda} k_{\lambda} \: \varphi^{\prime}_{\lambda} &= 0 \label{eq:ecuacion_09_114} \\[0.5em]
\sum_{\lambda} k_{\lambda} \: \varphi^{\prime \prime}_{\lambda} &= 0 \label{eq:ecuacion_09_115} \\[0.5em]
&\vdots \nonumber
\end{align}
y así, sucesivamente.
\end{frame}
\begin{frame}
\frametitle{Independencia de funciones}
Lo que nos proporciona un conjunto de ecuaciones lineales homogéneas, en donde los coeficientes $k_{\lambda}$ con cantidades desconocidas. 
\\
\bigskip
Sabemos que existe una solución $k_{\lambda} \neq 0$, sólo si el determinante de los coeficientes de las $k_{\lambda}$ se anula, esto implica que:
\end{frame}
\begin{frame}
\frametitle{Determinante de coeficientes}
\begin{align}
\mdet{
\varphi_{1} & \varphi_{2} & \ldots & \varphi_{n} \\[0.5em]
\varphi^{\prime}_{1} & \varphi^{\prime}_{2} & \ldots & \varphi^{\prime}_{n} \\[0.5em]
\ldots & \ldots & \ldots & \ldots \\[0.5em]
\varphi^{(n-1)}_{1} & \varphi^{(n-1)}_{2} & \ldots & \varphi^{(n-1)}_{n} \\
} = 0
\label{eq:ecuacion_09_116}
\end{align}
A este determinante se le llama \emph{Wronskiano}:
\end{frame}
\begin{frame}
\frametitle{Propiedades del Wronskiano}
\setbeamercolor{item projected}{bg=blue!70!black,fg=yellow}
\setbeamertemplate{enumerate items}[circle]
\fontsize{12}{12}\selectfont
\begin{enumerate}[<+->]
\item Si el Wronkiano no es cero, entonces la ecuación (\ref{eq:ecuacion_09_111}) no tiene solución más que $k_{\lambda}=0$. El conjunto de funciones es por tanto, independiente.
\item Si el Wronskiano se anula en ciertos valores aislados del argumento, esto no prueba necesariamente la dependencia lineal (a menos que el conjunto de funciones sea de dos funciones). De cualquier manera, si el Wronskiano es cero en un rango amplio de la variable, las funciones $\varphi_{\lambda}$ son linealmente dependientes dentro de ese rango.
\end{enumerate}
\end{frame}
\subsection{Independencia lineal}
\begin{frame}
\frametitle{Ejemplo del oscilador armónico}
Las soluciones de la ecuación del oscilador lineal que conocemos de la mecánica, son $\varphi_{1} = \sin \: \omega x$ y $\varphi_{2} = \cos \: \omega x$.
\end{frame}
\begin{frame}
\frametitle{Ejemplo del oscilador armónico}
Por lo que el Wronskiano resulta ser
\begin{align*}
\mdet{
\sin \omega x & \cos \omega x \\
\omega \: \cos \omega x & - \omega \: \sin \omega x
} = -\omega \neq 0
\end{align*}
\end{frame}
\begin{frame}
\frametitle{Resultado del Wronskiano}
 Estas dos soluciones $\varphi_{1}$ y $\varphi_{2}$ son por tanto linealmente independientes. Para estas dos funciones, esto significa que una no es múltiplo de la otra, lo cual es cierto.
\end{frame}
\begin{frame}
\frametitle{Observación}
Sabemos que
\begin{align*}
\sin \omega x = \pm (1 - \cos^{2} \: \omega x)^{1/2}
\end{align*}
pero ésta no es una relación lineal de la forma que muestra la ec. (\ref{eq:ecuacion_09_111}).
\end{frame}
\subsection{Dependencia lineal}
\begin{frame}
\frametitle{Ejemplo con la ec. de difusión}
Consideremos ahora las soluciones de la ecuación de difusión unidimensional, tales que $\varphi_{1} = e^{x}$ y $\varphi_{2} = e^{-x}$, y agreguemos $\varphi_{3} = \cosh x$ que también es una solución. 
\end{frame}
\begin{frame}
\frametitle{El Wronskiano}
El Wronskiano es:
\begin{align*}
\mdet{
e^{x}  & e^{-x} & \cosh x \\
e^{x}  & -e^{-x} & \sinh x \\
e^{x}  & e^{-x} & \cosh x
} = 0
\end{align*}
\end{frame}
\begin{frame}
\frametitle{El Wronskiano}
El determinante se anula para todos los valores de $x$, ya que el primer y tercer renglón son iguales.
\\
\bigskip
Por tanto $e^{x}$, $e^{-x}$ y $\cosh x$ son linealmente dependientes.
\end{frame}
\begin{frame}
\frametitle{Resultado}
Tenemos pues una relación de la forma (\ref{eq:ecuacion_09_111}):
\begin{align*}
e^{x} + e^{-x} - 2 \: \cosh x = 0 \hspace{1.5cm} \text{con } k_{\lambda} \neq 0
\end{align*}
\end{frame}
\section{Solución integral}
\frame{\tableofcontents[currentsection, hideothersubsections]}
\subsection{Construcción}
\begin{frame}
\frametitle{Construcción}
Regresando a la ecuación diferencial lineal de segundo orden y homogénea de la forma
\begin{align}
\stilde{y} + P(x) \, \ptilde{y} + Q(x) \: y = 0
\label{eq:ecuacion_09_118}
\end{align}
sean $y_{1}$ y $y_{2}$ dos soluciones independientes.
\end{frame}
\begin{frame}
\frametitle{El Wronskiano}
El Wronskiano por definición es:
\begin{align}
W = y_{1} \: \ptilde{y}_{2} - \ptilde{y}_{1} \: y_{2}
\label{eq:ecuacion_09_119}
\end{align}
\end{frame}
\begin{frame}
\frametitle{Diferenciando el Wronskiano}
Diferenciando el Wronksiano, obtenemos
\begin{align*}
\ptilde{W} &= \ptilde{y}_{1} \: \ptilde{y}_{2} + y_{1} \: \stilde{y}_{2} - \stilde{y}_{1} \: y_{2} - \ptilde{y}_{1} \: \ptilde{y}_{2} = \\
&= y_{1} \bigg[ - P(x) \: \ptilde{y}_{2} - Q(x) \: y_{2} \bigg] + \\
&- y_{2} \bigg[ - P(x) \: \ptilde{y}_{1} - Q(x)  \: y_{1} \bigg] = \\
&= - P(x) \: \bigg[ y_{1} \: \ptilde{y}_{2} - \ptilde{y}_{1} \: y_{2} \bigg]
\end{align*}
\end{frame}
\begin{frame}
\frametitle{Resultado}
Donde la expresión entre corchetes es el Wronskiano mismo, por tanto
\begin{align}
\ptilde{W} = - P(x) \: W
\label{eq:ecuacion_09_120}
\end{align}
\end{frame}
\begin{frame}
\frametitle{Caso especial}
En el caso especial con $P(x) = 0$, entonces
\begin{align}
\stilde{y} + Q(x) \: y = 0
\label{eq:ecuacion_09_121}
\end{align}
el Wronskiano
\begin{align}
W = y_{1} \: \ptilde{y}_{2} - \ptilde{y}_{1} \: y_{2} = \mbox{ constante}
\label{eq:ecuacion_09_1202}
\end{align}
\end{frame}
\begin{frame}
\frametitle{Normalización del Wronkiano}
Ya que nuestra ecuación diferencial es homogénea, podemos multiplicar las soluciones $y_{1}$ e $y_{2}$ por cualesquiera constantes, para ajustar que el valor del Wronskiano sea uno (ó $-1$).
\end{frame}
\begin{frame}
\frametitle{Caso especial}
El caso $P(x) = 0$ aparece más frecuentemente de lo esperado:
\begin{itemize}
\item El laplaciano $\laplacian$ en coordenadas cartesianas no contiene la primera derivada.
\item La dependencia radial de $\laplacian (\dfrac{\psi}{r})$ en coordenadas esféricas polares carece de la primera derivada radial.
\end{itemize}
\end{frame}
\begin{frame}
\frametitle{Transformación de la EDO}
Cualquier EDO2 lineal puede transformarse en una ecuación de la forma (ec. \ref{eq:ecuacion_09_121}).
\\
\bigskip
Para el caso general, vamos a suponer que tenemos una solución para la ecuación (\ref{eq:ecuacion_09_118}) sustituyendo una serie (o por medio de una suposición). 
\end{frame}
\begin{frame}
\frametitle{Segunda solución}
Desarrollamos una segunda solución independiente para la cual $W \neq 0$, reescribimos la ecuación (\ref{eq:ecuacion_09_120}) como
\begin{align*}
\dfrac{\dd{W}}{W} = - P(x) \: \dd{x_{1}}
\end{align*}
\end{frame}
\begin{frame}
\frametitle{Segunda solución}
Integramos con respecto a $x$, desde $a$ hasta $x$ de donde obtenemos
\begin{align*}
\ln \dfrac{W(x)}{W(a)} = - \int_{a}^{x} P(x_{1}) \: \dd{x_{1}}
\end{align*}
\pause
que es lo mismo
\begin{align}
\setlength{\fboxsep}{2\fboxsep}\boxed{W(x) = W(a) \: \exp \left[ - \int_{a}^{x} P(x_{1}) \: \dd{x_{1}} \right]}
\label{eq:ecuacion_09_123}
\end{align}
\end{frame}
\begin{frame}
\frametitle{Observación}
Pero
\begin{align}
W(x) = y_{1} \: \ptilde{y}_{2} - \ptilde{y}_{1} \: y_{2} = y_{1}^{2} \: \dv{x} \left( \dfrac{y_{2}}{y_{1}} \right)
\label{eq:ecuacion_09_124}
\end{align}
Combinando las ecuaciones (\ref{eq:ecuacion_09_123}) y (\ref{eq:ecuacion_09_124}), tenemos que
\end{frame}
\begin{frame}
\frametitle{Resultado}
Tenemos que:
\begin{align}
\dv{x} \left( \dfrac{y_{2}}{y_{1}} \right) =  W(a) \: \dfrac{\exp \left[\displaystyle - \int_{a}^{x} \: P(x_{1}) \: \dd{x_{1}} \right]}{y^{2}_{1}}
\label{eq:ecuacion_09_125}
\end{align}
\end{frame}
\begin{frame}
\frametitle{Resultado}
Finalmente integramos la ecuación (\ref{eq:ecuacion_09_125}) de $x_{2} = b$ a $x_{2} = x$, para obtener
\begin{align}
y_{2} = y_{1} \: W(a) \: \int_{b}^{x} \dfrac{\exp \left[ \displaystyle - \int_{a}^{x_{2}} P(x_{1}) \dd{x_{1}} \right]}{[y_{1}(x_{2})]^{2}} \dd{x_{2}}
\label{eq:ecuacion_09_126}
\end{align}
Donde $a$ y $b$ son constantes arbitrarias, los términos $y_{1}(x)y_{2}(b)/y_{1}(b)$ se han omitido, ya que no conducen a algo.
\end{frame}
\begin{frame}
\frametitle{Segunda solución}
Para $W(a)$, el Wronskiano evaluado en $x=a$, es una constante y las soluciones de la ecuación diferencial homogénea siempre contienen un factor de normalización desconocido, hacemos $W(a)=1$ y escribimos
\end{frame}
\begin{frame}
\frametitle{Segunda solución}
Escribimos
\begin{align}
\setlength{\fboxsep}{2\fboxsep}\boxed{y_{2}(x) =  y_{1} \: (x) \int^{x} \dfrac{\exp \left[ \displaystyle - \int^{x_{2}} P(x_{1}) \: \dd{x_{1}} \right]}{[y_{1}(x_{2})]^{2}} \dd{x_{2}}}
\label{eq:ecuacion_09_127}
\end{align}
en donde se han omitido los límites inferiores de integración $x_{1} = a$ y $x_{2}=b$.
\end{frame}
\begin{frame}
\frametitle{Segunda solución}
En caso contrario, simplemente originan una contribución igual a una constante multiplicada por al primera solución conocida $y_{1}(x)$ lo cual consecuentemente no agrega nada nuevo.
\end{frame}
\begin{frame}
\frametitle{Caso especial}
Si tenemos el caso especial e importante, cuando $P(x) = 0$, la ecuación (\ref{eq:ecuacion_09_127}), toma la forma:
\begin{align}
y_{2}(x) =  y_{1}(x) \: \int^{x} \dfrac{\dd{x_{2}}}{[y_{1}(x_{2})]^{2}}
\label{eq:ecuacion_09_128}
\end{align}
\end{frame}
\begin{frame}
\frametitle{Caso especial}
Lo que significa que usando ya sea (\ref{eq:ecuacion_09_127}) o (\ref{eq:ecuacion_09_128}), podemos tomar una solución conocida y luego integrando, podemos generar una segunda solución independiente.
\end{frame}
\begin{frame}
\frametitle{Ejemplo}
De la ecuación
\begin{align*}
\dv[2]{y}{x} + y = 0 \hspace{1cm} \mbox{con } P(x) = 0
\end{align*}
hacemos una solución tipo $y_{1} = \sin x$, aplicando la solución (\ref{eq:ecuacion_09_128}), resulta
\end{frame}
\begin{frame}
\frametitle{Ejemplo}
Resulta
\begin{align*}
y_{2}(x) &= \sin x \int^{x} \dfrac{\dd{x_{2}}}{\sin^{2} x_{2}} \\
&= \sin x (-\cot x) = - \cos x
\end{align*}
La cual es obviamente independiente (y no un múltiplo lineal) de $\sin x$.
\end{frame}
\section{Segunda solución en series}
\frame{\tableofcontents[currentsection, hideothersubsections]}
\subsection{Construcción}
\begin{frame}
\frametitle{Secuencia de pasos}
Un análisis más profundo de la naturaleza de la segunda solución de la ecuación diferencial se puede lograr mediante la siguiente secuencia de pasos:
\setbeamercolor{item projected}{bg=blue!70!black,fg=yellow}
\setbeamertemplate{enumerate items}[circle]
\begin{enumerate}
\item Expresamos $P(x)$ y $Q(x)$ en la ecuación (\ref{eq:ecuacion_09_118}) como
\begin{align}
P(x) = \sum_{i=-1}^{\infty} p_{i} \: x^{i} \hspace{2cm} Q(x) = \sum_{j=-2}^{\infty} q_{j} \: x^{j}
\label{eq:ecuacion_09_129}
\end{align}
Los límites inferiores de las sumas se eligen justamente para satisface el teorema de Fuchs ( para crear una potencial singularidad regular en el origen).
\seti
\end{enumerate}
\end{frame}
\begin{frame}
\frametitle{Secuencia de pasos}
\setbeamercolor{item projected}{bg=blue!70!black,fg=yellow}
\setbeamertemplate{enumerate items}[circle]
\begin{enumerate}[<+->]
\conti
\item Desarrollamos los primeros términos de la solución en series de potencias.
\item Usamos la solución obtenida como $y_{1}$, obtenemos una segunda solución en tipo de series $y_{2}$, con la ecuación (\ref{eq:ecuacion_09_127}) integramos término a término.
\end{enumerate}
\end{frame}
\begin{frame}
\frametitle{Desarrollo}
Siguiendo el paso 1, tenemos
\begin{align}
\begin{aligned}[b]
\stilde{y} &+ (p_{-1} \, x^{-1} + p_{0} + p_{1} \, x + \ldots) \, \ptilde{y} + \\[0.5em]
&+(q_{-2} \, x^{-2} + q_{-1} \, x^{-1} + \ldots) \, y = 0
\end{aligned}
\label{eq:ecuacion_09_130}
\end{align}
en donde el punto $x = 0$ es en el peor de los casos un punto singular regular.
\\
\bigskip
Si $p_{-1} = q_{-1} = q_{-2} = 0$, se reduce a un punto ordinario.
\end{frame}
\begin{frame}
\frametitle{Desarrollo}
Sustituimos
{\fontsize{12}{12}\selectfont
\begin{align*}
y = \sum_{\lambda = 0}^{\infty} a_{\lambda} \: x^{k + \lambda}
\end{align*}}
\pause
Obtenemos (paso 2)
\fontsize{12}{12}\selectfont
\begin{align}
\begin{aligned}[b]
\sum_{\lambda=0}^{\infty} (k &+ \lambda)(k + \lambda - 1) \: a_{\lambda} \, x^{k + \lambda - 2} + \\
&+ \sum_{i=-1}^{\infty} p_{i} \, x^{i} \sum_{\lambda=0}^{\infty} (k + \lambda) \,  a_{\lambda} x^{k + \lambda - 1} + \\
&+ \sum_{j=-2}^{\infty} q_{j} \, x^{j} \: \sum_{\lambda=0}^{\infty} a_{\lambda} \, x^{k + \lambda} = 0
\end{aligned}
\label{eq:ecuacion_09_131}
\end{align}
\end{frame}
\begin{frame}
\frametitle{Desarrollo}
Suponiendo que $p_{-1} \neq 0, q_{-2} \neq 0$, la ecuación de índices es
\begin{align*}
k \, (k - 1) + p_{-1} \, k + q_{-2} = 0
\end{align*}
lo que hace que el coeficiente neto de $x^{k-2}$ sea igual a cero, por lo que se reduce a
\pause
\begin{align}
k^{2} + (p_{-1} - 1) \, k + q_{-2} = 0
\label{eq:ecuacion_09_132}
\end{align}
\end{frame}
\begin{frame}
\frametitle{Ecuación de índices}
Escribimos las raíces de la ecuación de índices como $k = \alpha$ y $k= \alpha - n$ donde $n$ es cero o un entero positivo (si $n$ es no entero, esperamos dos soluciones independientes en series).
\end{frame}
\begin{frame}
\frametitle{Ecuación de índices}
Por lo que
\begin{align}
(k - \alpha)(k - \alpha + n) = 0
\label{eq:ecuacion_09_133}
\end{align}
\pause
que es lo mismo
\begin{align*}
k^{2} + (n - 2 \, \alpha) \, k + \alpha \, (\alpha - n) = 0
\end{align*}
\end{frame}
\begin{frame}
\frametitle{Índices obtenidos}
Igualando los coeficientes de $k$ en las ecuaciones (\ref{eq:ecuacion_09_132}) y (\ref{eq:ecuacion_09_133}), tenemos
\begin{align}
p_{-1} -1 = n - 2 \: \alpha
\label{eq:ecuacion_09_134}
\end{align}
\end{frame}
\begin{frame}
\frametitle{Solución en series}
La solución en series conocida corresponde al valor más grande de la raíz $k = \alpha$, que se escribe como
\begin{align*}
y_{1} =  x^{\alpha} \, \sum_{\lambda=0}^{\infty} a_{\lambda} \: x^{\lambda}
\end{align*}
\end{frame}
\begin{frame}
\frametitle{Solución en series}
Sustituimos la solución en series en la ecuación (\ref{eq:ecuacion_09_127}) (Paso 3) y vemos que
\fontsize{12}{12}\selectfont
\begin{align}
y_{2}(x) = y_{1} (x) \: \int^{x} \dfrac{\exp \left[ \displaystyle - \int_{a}^{x_{2}} \sum_{i=-1}^{\infty} p_{i} \: x^{i}_{1} \: \dd{x_{1}} \right] }{x_{2}^{2 \, \alpha} \left( \displaystyle \sum_{\lambda=0}^\infty a_{\lambda} \: x_{2}^{\lambda} \right)^{2} } \dd{x_{2}}
\label{eq:ecuacion_09_135}
\end{align}
Donde las soluciones $y_{1}$ y $y_{2}$ se han normalizado de modo que el Wronskiano $W(a) = 1$.
\end{frame}
\begin{frame}
\frametitle{Estudiando la solución}
Mirando primero el argumento del factor exponencial
{\fontsize{12}{12}\selectfont
\begin{align}
\int_{a}^{x_{2}} \sum_{i=-1}^{\infty} p_{i} \: x_{1}^{i} \: \dd{x_{1}} = p_{-1} \: \ln x_{2} + \sum_{k=0}^{\infty} \dfrac{p_{k}}{k + 1} \: x_{2}^{k + 1} + f(a)
\label{eq:ecuacion_09_136}
\end{align}}
donde $f(a)$ es una constante de integración que depende de $a$.
\end{frame}
\begin{frame}
\frametitle{Estudiando la solución}
De aquí resulta:
\fontsize{10}{10}\selectfont
\begin{align}
\begin{aligned}[b]
&{}\exp \left( - \int_{a}^{x_{2}} \sum_{i} p_{i} \: x_{1}^{i} \dd{x_{1}} \right) =  \\
&= \exp [ - f(a) ] \: x_{2}^{-p_{-1}} \exp \left( - \sum_{k=0}^{\infty} \dfrac{p_{k}}{k+1} \: x_{2}^{k+1} \right) = \\
&= \exp [ - f(a) ] \: x_{2}^{-p_{-1}} \left[ 1 - \sum_{k=0}^{\infty} \dfrac{p_{k}}{k+1} \: x_{2}^{k+1} + \dfrac{1}{2!} \left( \sum_{k=0}^{\infty} \dfrac{p_{k}}{k+1} \: x_{2}^{k+1} \right)^{2} + \ldots \right]
\end{aligned}
\label{eq:ecuacion_09_137}
\end{align}
\end{frame}
\begin{frame}
\frametitle{Estudiando la solución}
Esta expansión en serie de la exponencial ciertamente converge, si la expansión original del coeficiente $P(x)$ converge uniformemente.
\end{frame}
\begin{frame}
\frametitle{Estudiando la solución}
El denominador en la ecuación (\ref{eq:ecuacion_09_135}) puede manejarse como
\begin{align}
\begin{aligned}[b]
\left[ x_{2}^{2 \, \alpha} \left( \sum_{\lambda=0}^{\infty} a_{\lambda} \: x_{2}^{\lambda} \right)^{2} \right]^{-1} &= x_{2}^{-2 \, \alpha} \left( \sum_{\lambda=0}^{\infty} a_{\lambda} \: x_{2}^{\lambda} \right)^{2}  \\
&= x_{2}^{-2 \, \alpha} \sum_{\lambda=0}^{\infty} b_{\lambda} \: x_{2}^{\lambda}
\end{aligned}
\label{eq:ecuacion_09_138}
\end{align}
\end{frame}
\begin{frame}
\frametitle{Estudiando la solución}
Haciendo a un lado los factores constantes considerando que podemos tener $W(a) = 1$, para obtener
\begin{align}
y_{2}(x) =  y_{1}(x) = \int^{x} x_{2}^{-p_{-1}-2 \alpha} \left( \sum_{\lambda=0}^{\infty} c_{\lambda} \: x_{2}^{\lambda} \right) \dd{x_{2}} 
\label{eq:ecuacion_09_139}
\end{align}
\end{frame}
\begin{frame}
\frametitle{Estudiando la solución}
De las raíces de la ecuación de índices (ec. \ref{eq:ecuacion_09_134})
\begin{align}
x_{2}^{-p_{-1} - 2 \, \alpha} = x_{2}^{-n-1}
\end{align}
si suponemos que $n$ es entero, al sustituir el resultado en ec. (\ref{eq:ecuacion_09_139}) obtenemos:
\end{frame}
\begin{frame}
\frametitle{Estudiando la solución}
Obtenemos:
\fontsize{12}{12}\selectfont
\begin{align}
\begin{aligned}[b]
y_{2}(x) &= y_{1}(x) \int^{x} (c_{0} \, x_{2}^{-n-1} + c_{1} \, x_{2}^{-n} + c_{2} \, x_{2}^{-n+1} + \ldots + \\
&+ c_{n} \, x^{-1} + \ldots ) \dd{x_{2}}
\end{aligned}
\label{eq:ecuacion_09_141}
\end{align}
\end{frame}
\begin{frame}
\frametitle{Segunda solución independiente}
La integración anterior nos devuelve un coeficiente de $y_{1}(x)$ formado de dos partes:
\setbeamercolor{item projected}{bg=blue!70!black,fg=yellow}
\setbeamertemplate{enumerate items}[circle]
\begin{enumerate}[<+->]
\item Una serie de potencias que inicia en $x^{-n}$
\item Un término logarítmico de la integración de $x^{-1}$ (cuando $\lambda=n$). Este término siempre aparecerá cuando $n$ sea un entero, a menos de que $c_{n}$ fortuitamente se anule.
\end{enumerate}
\end{frame}
\subsection{Ejemplo: Ecuación de Bessel}
\begin{frame}
\frametitle{Ecuación de Bessel}
De acuerdo con la ec. de Bessel 
\begin{align}
x^{2} \: y^{\prime \prime} + x \: y^{\prime} + (x^{2} - n^{2}) \: y = 0
\label{eq:ecuacion_09_100}
\end{align}
(dividida entre $x^{2}$ para concondar con la ec. (\ref{eq:ecuacion_09_118})), se tiene
\end{frame}
\begin{frame}
\frametitle{Ecuación de Bessel}
Tenemos que:
\begin{align*}
P(x) = x^{-1} \hspace{1.5cm} Q(x) = 1 \hspace{1.5cm} \text{con } n = 0
\end{align*}
 En consecuencia $p_{-1} = 1, q_{0} = 1$, todas las otras $p_{i}$ y $q_{j}$ se anulan.
\end{frame}
\begin{frame}
\frametitle{Ecuación de índices}
La ecuación de índices de Bessel es
\begin{align*}
k^{2} = 0
\end{align*}
que es la ecuación $k^{2} - n^{2} = 0$ con $n = 0$.
\\
\bigskip
\pause
En consecuencia, se verifican las ecs. (\ref{eq:ecuacion_09_132}) a la (\ref{eq:ecuacion_09_134}) con $n$ y $\alpha = 0$.
\end{frame}
\begin{frame}
\frametitle{Primera solución}
Nuestra primera solución queda disponible de la ecuación
\begin{align}
y(x) = a_{0} \, 2^{n} \, n! \, \sum_{j=0}^{\infty} (-1)^{j} \, \dfrac{1}{j! \, (n + j)!} \left( \dfrac{x}{2} \right)^{n +2j}
\label{eq:ecuacion_09_108}
\end{align}
\end{frame}
\begin{frame}
\frametitle{Primera solución a la ec. de Bessel}
Hacemos un etiquetado para concordar con la función de Bessel de orden $0$ (y haciendo $a_{0} = 1)$, obtenemos
% \begin{subequations}
\begin{align}
y_{1} (x) = J_{0} (x) =  1 - \dfrac{x^{2}}{4} + \dfrac{x^{4}}{64} - \order{x^{6}}
\label{eq:ecuacion_09_142a}
\end{align}
\end{frame}
\begin{frame}
\frametitle{La segunda solución}
Ahora, sustituyendo todo esto en la ec. (\ref{eq:ecuacion_09_127}), se tiene el caso específico a la ec. (\ref{eq:ecuacion_09_135}):
\begin{align}
y_{2} (x) = J_{0} (x) \; \int^{x} \dfrac{\exp(\displaystyle - \int^{x^{2}} x_{1}^{-1} \dd{x_{1}})}{\left[ 1 - \dfrac{x^{2}}{4} + \dfrac{x^{4}}{64} - \ldots\right]^{2}} \dd{x_{2}}
\label{eq:ecuacion_09_142b}
\end{align}
\end{frame}
\begin{frame}
\frametitle{La segunda solución}
Del numerador del integrando
\begin{align*}
\exp \left[ - \int^{x^{2}} \dfrac{\dd{x_{1}}}{x_{1}} \right]= \exp (\ln x_{2}) = \dfrac{1}{x_{2}} 
\end{align*}
Esto corresponde a $x_{2}^{p-1}$ en la ec. (\ref{eq:ecuacion_09_137}).
\end{frame}
\begin{frame}
\frametitle{La segunda solución}
Del denominador del integrando, usando la expansión binomial, obtenemos
\begin{align*}
\left[ 1 - \dfrac{x^{2}}{4} + \dfrac{x^{4}}{64} - \ldots \right]^{-2} = 1 + \dfrac{x_{2}^{2}}{2} + \dfrac{5 \, x_{2}^{4}}{32} + \ldots
\end{align*}
\end{frame}
\begin{frame}
\frametitle{La segunda solución}
Correspondiente a la ec. (\ref{eq:ecuacion_09_139}), se tiene
\begin{align}
y_{2} (x) &= J_{0} (x) \, \int^{x} \dfrac{1}{x_{2}} \, \left[ 1 + \dfrac{x_{2}^{2}}{2} + \dfrac{5 \, x_{2}^{4}}{32} + \ldots \right] \dd{x_{2}} \nonumber \\[0.5em]
&= J_{0} (x) \, \left\{ \ln x + \dfrac{x^{2}}{4} + \dfrac{5 \, x^{4}}{128} + \ldots  \right\}
\label{eq:ecuacion_09_142c}
\end{align}
\end{frame}
\begin{frame}
\frametitle{La segunda solución}
Comprobemos este resultado. Como veremos en el Tema de Funciones Especiales, la segunda solución a la ecuación de Bessel está dada por la función de Neumann de orden $0$, $N_{0}(x)$:
\begin{align}
\begin{aligned}
N_{0}(x) &= \dfrac{2}{\pi} (\ln x + \gamma - \ln 2) \,J_{0} (x) + \\
&+ \dfrac{2}{\pi} \left\{ \dfrac{x^{2}}{4} + \dfrac{3 \, x^{4}}{128} + \ldots   \right\}
\end{aligned}
\label{eq:ecuacion_09_142d}
\end{align}
\end{frame}
\begin{frame}
\frametitle{Dos conceptos}
Se originan dos conceptos:
\setbeamercolor{item projected}{bg=blue!70!black,fg=yellow}
\setbeamertemplate{enumerate items}[circle]
\begin{enumerate}
\item Ya que la ecuación de Bessel es homogénea, podemos multiplicar $y_{2}$ por cualquier constante. 
\\
\bigskip
Para igualar con $N_{0}(x)$ simplemente se multiplica $y_{2}(x)$ por $\dfrac{2}{\pi}$.
\seti
\end{enumerate}
\end{frame}
\begin{frame}
\frametitle{Dos conceptos}
\setbeamercolor{item projected}{bg=blue!70!black,fg=yellow}
\setbeamertemplate{enumerate items}[circle]
\begin{enumerate}
\conti    
\item Para la segunda solución $\bigg( \dfrac{2}{\pi} \bigg) \, y_{2}$, se puede agregar cualquier constante múltiplo de la primera solución. Nuevamente, para igualar $N_{0}(x)$ se agrega
\begin{align*}
\dfrac{2}{\pi} [- \ln 2 + \gamma] \, J_{0} (x)
\end{align*}
donde $\gamma$ es la constante de Euler-Mascheroni.
\end{enumerate}
\end{frame}
\begin{frame}
\frametitle{Segunda solución modificada}
Nuestra segunda solución modificada es
\begin{align}
y_{2} = \dfrac{2}{\pi} [- \ln 2 + \gamma] \, J_{0} (x) + \dfrac{2}{\pi} \, J_{0} (x) \, \left\{ \dfrac{x^{2}}{4} + \dfrac{5 \, x^{4}}{128} + \ldots   \right\}
\label{eq:ecuacion_09_142e}
\end{align}
\end{frame}
\begin{frame}
\frametitle{Comparación entre resultados}
Ahora, la comparación con $N_{0}(x)$ se transforma en una multiplicación de $J_{0}(x)$ de la ec. (\ref{eq:ecuacion_09_142a}) y el paréntesis curvado de la ec. (\ref{eq:ecuacion_09_142c}).
\\
\bigskip
La multiplicación se comprueba a través de los términos de orden $x^{2}$ y $x^{4}$, la cual hemos llevamos para todo. 
\end{frame}
\begin{frame}
\frametitle{Comparación entre resultados}
Nuestra segunda solución de las ecs. (\ref{eq:ecuacion_09_127}) y (\ref{eq:ecuacion_09_135}) concuerda con la segunda solución estándar, la función de Neumann de orden $0$, $N_{0}(x)$.
\end{frame}
\begin{frame}
\frametitle{Expresión para la segunda suma}
De acuerdo con el análisis predecente, la segunda solución de la ec. (\ref{eq:ecuacion_09_118}), $y_{2}(x)$, se puede escribir de la forma
\begin{align}
y_{2}(x) = y_{1} (x) \, \ln x + \sum_{j=-n}^{\infty} d_{j} \, x^{j+\alpha}
\label{eq:ecuacion_09_142f}
\end{align}
\end{frame}
\begin{frame}
\frametitle{Expresión para la segunda suma}
Es decir, la primera solución multiplicada por $\ln x$ y otra serie de potencias, ésta última comenzando con $x^{\alpha - n}$, lo cual significa que podemos buscar un término logarítmico cuando la ecuación de índices proporciona tan sólo una solución en serie.
\end{frame}
\begin{frame}
\frametitle{Segunda solución en series}
Con la forma de la segunda solución dada por la ec. (\ref{eq:ecuacion_09_142f}), podemos sustituir la ec. (\ref{eq:ecuacion_09_142f}) en la ecuación diferencial original y determinar los coeficientes $d_{j}$
\end{frame}
\begin{frame}
\frametitle{Segunda solución regular}
La segunda solución normalmente será divergente en el origen debido al factor logarítmico y las potencias negativas de la serie. 
\\
\bigskip
Debido a esto, es que $y_{2}(x)$ se denomina frecuentemente \textbf{solución irregular}. La primera solución en serie $y_{1}(x)$, que normalmente converge en el origen, se denomina \textbf{solución regular}.
\end{frame}
\begin{frame}
\frametitle{Resumen}
Las dos soluciones vistas en este apartado, proporciona una solución completa de la EDO2H lineal, suponiendo que el punto de desarrollo no es peor que una singularidad regular. 
\end{frame}
\begin{frame}
\frametitle{Resumen}
Al menos se puede obtener una solución mediante la sustitución en series de potencias.
\\
\bigskip
Una segunda solución linealmente independiente se puede construir por medio de la doble integral Wronskiana. Esto es lo único posible: \emph{no hay una tercera solución linealmente independiente}.
\end{frame}
\begin{frame}
\frametitle{Resumen}
La ED2 lineal y \textit{no homogénea} tendrá una solución adicional: la \emph{solución particular}.
\\
\bigskip
Esta solución particular se puede obtener por el método de variación de parámetros, o por medio de técnicas tales como las funciones de Green.
\end{frame}
\section{Ejercicios a cuenta}
\frame{\tableofcontents[currentsection, hideothersubsections]}
\subsection{Independencia lineal}
\begin{frame}
\frametitle{Ejercicio 1}
\setbeamercolor{item projected}{bg=blue!70!black,fg=yellow}
\setbeamertemplate{enumerate items}[circle]
\begin{enumerate}
\item Si el Wronskiano de dos funciones $y_{1}$ e $y_{2}$ es igual a cero, demuestra mediante integración directa que:
\begin{align*}
y_{1} = c \, y_{2}
\end{align*}
Considera la suposición de que las funciones tienen derivadas continuas y que al menos una de las funciones no desaparece en e intervalo bajo consideración.
\seti
\end{enumerate}
\end{frame}
\begin{frame}
\frametitle{Ejercicio 2}
\setbeamercolor{item projected}{bg=blue!70!black,fg=yellow}
\setbeamertemplate{enumerate items}[circle]
\begin{enumerate}
\conti    
\item Considera las siguientes funciones:
\begin{align*}
\varphi_{1} =  x \hspace{2cm} \varphi_{2} = \abs{x} = x \, \, \mbox{sgn} \, x
\end{align*}
Donde la función \textit{sgn} es precisamente el signo de $x$. Como 
\begin{align*}
\ptilde{\varphi}_{1} &=  1 \hspace{2cm} \ptilde{\varphi}_{2} = \mbox{sgn} \, x \\
&\Rightarrow W(\varphi_{1}, \varphi_{2}) = 0
\end{align*}
para cualquier intervalo, incluyendo $[-1, +1]$.
\seti
\end{enumerate}
\end{frame}
\begin{frame}
\frametitle{Ejercicio 2}
Comprueba si la cancelación del Wronskiano en $[-1, +1]$ demustra que $\varphi_{1}$ y $\varphi_{2}$ son linealmente independientes.
\\
\bigskip
Evidentemente que no lo son. ¿En dónde está el error? (Tip: gráfica las dos funciones en el intervalo para visualizar las funciones)
\end{frame}

\begin{frame}
\frametitle{Ejercicio a cuenta - 5}
% \setbeamercolor{item projected}{bg=blue!70!black,fg=yellow}
% \setbeamertemplate{enumerate items}[circle]
% \begin{enumerate}
% \conti
Considerando que una solución de
\begin{align*}
\stilde{R} + \dfrac{1}{r} \, \ptilde{R} - \dfrac{m^{2}}{r^{2}} \, R = 0
\end{align*}
es $R = r^{m}$. Demuestra que la ecuación (\ref{eq:ecuacion_09_127}) predice una segunda solución: $R = r^{-m}$
% \seti
% \end{enumerate}
\end{frame}
% \begin{frame}
% \frametitle{Ejercicio 4}
% \setbeamercolor{item projected}{bg=blue!70!black,fg=yellow}
% \setbeamertemplate{enumerate items}[circle]
% \begin{enumerate}
% \conti
% \item Una solución para la ecuación diferencial de Hermite
% \begin{align*}
% \stilde{y} - 2 \, x \, y + 2 \, \alpha \, y = 0
% \end{align*}
% para $\alpha = 0$ es $y_{1} = 1$. Encuentra una segunda solución $y_{2}(x)$, usando la ecuación (\ref{eq:ecuacion_09_127})
% \end{enumerate}
% \end{frame}

%referencia 8.7 Obtención de una segunda solución linealmente independiente. Fundamentos de
%Ecuaciones Diferenciales. Nagle y Saff. Addison-Wesley.
% Encuentra los primeros términos del desarrollo en series de potencias en torno al punto regular singular $x = 0$ de la solución general de
% \begin{equation}
% x^{2} \doblederivaday  - x \derivaday + (1 -x) y = 0, \hspace{1cm} x > 0
% \label{eq:ecuacion_8_7_12}
% \end{equation} 
% Usando el método de Frobenius para obtener una solución en series de potencias de la ecuación anterior, la ecuación indicial es:
% \[ r^{2} - 2r + 1 = 0 \]
% cuyas raíces son: $r_{1} = r_{2} = 1$. Usando $r_{1} = 1$, se obtiene la solución en series de potencias
% \begin{equation}
% y_{1}(x) = \sum_{k=0}^{\infty} \dfrac{1}{(k!)^{2}} \; x^{k+1}
% \label{eq:ecuacion_8_7_13}
% \end{equation}
% Dado que $p(x) = - x^{-1}$ para la ecuación (\ref{eq:ecuacion_8_7_12}), se puede sustituir $f(x) = y_{1}(x)$ y $p(x) = - x^{-1}$ en la fórmula de reducción de orden:
% \begin{equation}
% \begin{split}
% y_{2}(x) &= y_{1}(x) \int \dfrac{exp(\int x^{-1} dx)}{[y_{1}(x)]^{2}}dx \\
% &= y_{1}(x) \int \dfrac{exp(\ln x)}{[y_{1}(x)]^{2}} dx \\
% &= y_{1}(x) \int \dfrac{x}{[x + x^{2} + \frac{1}{4} x^{3} + \frac{1}{36} x^{4} + \ldots]^{2}} dx
% \end{split}
% \label{eq:ecuacion_8_7_14}
% \end{equation}
% utilizando el producto de Cauchy para elevar al cuadrado la serie del denominador y cancelando un factor $x$, resulta
% \begin{equation}
% \begin{split}
% y_{2} &=  y_{1}(x) \int \dfrac{x}{[ x^{2} + 2 x^{3} + \frac{3}{2} x^{4} + \ldots]} dx \\
% &= y_{1}(x) \int \left\lbrace \dfrac{1}{x + 2 x^{2} + \frac{3}{2} x^{3} + \ldots } \right\rbrace dx
% \end{split}
% \label{eq:ecuacion_8_7_15}
% \end{equation}
% Usando la división larga para calcular la serie de potencias del cociente que se encuentra dentro de las llaves, se obtiene
% \begin{equation}
% y_{2}(x) = y_{1}(x) \int \left\lbrace \dfrac{1}{x} - 2 + \dfrac{5x}{2} - \dfrac{23x^{2}}{9} + \ldots \right\rbrace
% \label{eq:ecuacion_8_7_16}
% \end{equation}
% integrando término a término, resulta
% \begin{equation}
% \begin{split}
% y_{2}(x) &= y_{1}(x) [ \ln x - 2x + \frac{5}{4} x^{2} - \frac{23}{27} x^{2} + \ldots ] \\
% &= y_{1} \ln x + y_{1}(-2x +  \frac{5}{4} x^{2} - \frac{23}{27} x^{2} + \ldots)
% \end{split}
% \label{eq:ecuacion_8_7_17}
% \end{equation}
% sustituimos la serie de $y_{1}(x)$ dada por la expresión (\ref{eq:ecuacion_8_7_13}) y se utiliza el producto de Cauchy para obtener
% \begin{equation}
% \begin{split}
% y_{2}(x) &= y_{1}(x) \ln x + (x + x^{2} + \frac{1}{4} x^{3} + \ldots)(-2x + \frac{5}{4} x^{2} - \frac{23}{27} x^{3} + \ldots) \\
% &= y_{1} \ln x + (-2x^{2} - \frac{3}{4} x^{3} - \frac{11}{108} x^{4} + \ldots)
% \end{split}
% \label{eq:ecuacion_8_7_18}
% \end{equation}
% La solución general de la ecuación (\ref{eq:ecuacion_8_7_12}) es
% \begin{equation}
% y(x) = c_{1} y_{1}(x) + c_{2} y_{2}(x) \hspace{1cm} x > 0
% \label{eq:ecuacion_8_7_19}
% \end{equation}
% donde $c_{1}$ y $c_{2}$ son constantes arbitrarias.
% \section{Forma de una segunda solución linealmente independiente.}
% Sea $x_{0}$ un punto singular regular de
% \[ \doblederivaday + p \derivaday  +  q y = 0 \]
% y sean $r_{1}$ y $r_{2}$ las raíces de la ecuación indicial asociada, donde $r_{1} \geq r_{2}, \; Re(r_{1}) \geq Re(r_{2})$, se tiene que
% \begin{enumerate}[label=\alph*)]
% \item Si $r_{1} - r_{2}$ no es entero, entonces existen dos soluciones linelmente independientes de la forma:
% \begin{eqnarray}
% y_{1}(x) = \sum_{n=0}^{\infty} a_{n} (x - x_{0})^{n + r_{1}}, \hspace{1cm} a_{0} \neq 0 \label{eq:ecuacion_8_7_20} \\
% y_{2}(x) = \sum_{n=0}^{\infty} b_{n} (x - x_{0})^{n + r_{2}}, \hspace{1cm} b_{0} \neq 0 
% \label{eq:ecuacion_8_7_21}
% \end{eqnarray}
% \item Si $r_{1} = r_{2}$, entonces existen dos soluciones linealmente independientes de la forma:
% \begin{eqnarray}
% y_{1}(x) &=& \sum_{n=0}^{\infty} a_{n} (x - x_{0})^{n + r_{1}}, \hspace{1cm} a_{0} \neq 0 \label{eq:ecuacion_8_7_22} \\
% y_{2}(x) &=& y_{1}(x) \ln(x - x_{0}) + \sum_{n=1}^{\infty} b_{n} (x - x_{0})^{n + r_{1}} 
% \label{eq:ecuacion_8_7_23}
% \end{eqnarray}
% \item Si $r_{1} - r_{2}$ es un entero positivo, entonces existen dos soluciones linealmente independientes de la forma
% \begin{eqnarray}
% y_{1}(x) &=& \sum_{n=0}^{\infty} a_{n} (x - x_{0})^{n + r_{1}}, \hspace{1cm} a_{0} \neq 0 \label{eq:ecuacion_8_7_24} \\
% y_{2}(x) &=& C\; y_{1}(x) \ln(x - x_{0}) + \sum_{n=1}^{\infty} b_{n} (x - x_{0})^{n + r_{2}} 
% \label{eq:ecuacion_8_7_25}
% \end{eqnarray}
% donde $C$ es una constante que puede ser cero.
% \end{enumerate}
% De la ecuación de Bessel
% \[ x^{2} \: y^{\prime \prime} + x \: y^{\prime} + (x^{2} - n^{2}) \: y = 0
% \]
% dividimos entre $x^{2}$ para dejar la expresión en términos de la ecuación (\ref{eq:ecuacion_09_118})
% \[ y^{\prime \prime} + P(x) \: y^{\prime} + Q(x) \: y = 0 \]
% tenemos que
% \[ P(x) = \dfrac{1}{x} \hspace{1cm} Q(x) = 1 \hspace{0.5cm} \mbox{para $n=0$}\]
% por tanto $p_{-1}=1$, $q_{0}=1$; los demás términos $p_{i}$ y $q_{j}$ se anulan. La ecuación de índices para la ecuación de Bessel es:
% \[ k^{2} = 0 \]
\end{document}
